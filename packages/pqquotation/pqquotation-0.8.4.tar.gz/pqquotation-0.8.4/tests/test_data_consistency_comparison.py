# coding: utf8
"""
æµ‹è¯•sinaã€qqã€dcä¸‰ä¸ªæ•°æ®æºçš„æ•°æ®ä¸€è‡´æ€§å¯¹æ¯”
é‡‡ç”¨å¹¶å‘è·å–å’Œæ™ºèƒ½å®¹å·®å¯¹æ¯”ç­–ç•¥
"""

import time
import threading
import logging
from typing import List, Dict, Any, Tuple, Optional
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed
import json
import sys
import os
from datetime import datetime
import statistics
import random

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import pqquotation

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('data_consistency_test.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class DataConsistencyChecker:
    """æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å™¨"""
    
    def __init__(self):
        self.sources = ['sina', 'qq', 'dc']
        self.quotation_apis = {}
        
        # å­—æ®µæ˜ å°„ - ç»Ÿä¸€ä¸åŒæ•°æ®æºçš„å­—æ®µå
        self.field_mapping = {
            'sina': {
                'name': 'name', 'now': 'now', 'close': 'close', 'open': 'open',
                'high': 'high', 'low': 'low', 'volume': 'volume'
            },
            'qq': {
                'name': 'name', 'now': 'now', 'close': 'close', 'open': 'open',
                'high': 'high', 'low': 'low', 'volume': 'volume'
            },
            'dc': {
                'name': 'name', 'now': 'now', 'close': 'close', 'open': 'open',
                'high': 'high', 'low': 'low', 'volume': 'volume'
            }
        }
        
        # å®¹å·®è®¾ç½®
        self.tolerance = {
            'price_percent': 0.1,    # ä»·æ ¼å®¹å·®0.1%
            'volume_percent': 50.0,  # æˆäº¤é‡å®¹å·®50%ï¼ˆQQä¸Sina/DCå­˜åœ¨å·²çŸ¥å·®å¼‚ï¼‰
            'name_similarity': 0.8   # åç§°ç›¸ä¼¼åº¦80%
        }
        
        # æ‰¹é‡å¤§å°é™åˆ¶ï¼ˆå–æœ€å°å€¼ç¡®ä¿å…¼å®¹ï¼‰
        self.batch_size = 50  # qqé™åˆ¶60ï¼Œä½†ä¸ºå®‰å…¨èµ·è§ç”¨50
        
        # åˆå§‹åŒ–æ•°æ®æº
        self.init_data_sources()
        
        # ç»“æœç»Ÿè®¡
        self.results = {
            'total_tested': 0,
            'successful_comparisons': 0,
            'consistency_stats': {},
            'inconsistent_stocks': [],
            'error_stocks': [],
            'field_consistency': defaultdict(lambda: defaultdict(int)),
            'source_availability': defaultdict(int),
            'code_format_issues': [],  # æ–°å¢ï¼šè‚¡ç¥¨ä»£ç æ ¼å¼é—®é¢˜ç»Ÿè®¡
            'code_format_stats': defaultdict(int)  # æ–°å¢ï¼šå„æ•°æ®æºä»£ç æ ¼å¼ç»Ÿè®¡
        }
    
    def init_data_sources(self):
        """åˆå§‹åŒ–æ•°æ®æº"""
        for source in self.sources:
            try:
                self.quotation_apis[source] = pqquotation.use(source)
                logger.info(f"åˆå§‹åŒ–æ•°æ®æº {source} æˆåŠŸ")
            except Exception as e:
                logger.error(f"åˆå§‹åŒ–æ•°æ®æº {source} å¤±è´¥: {e}")
    
    def load_test_codes(self, sample_size: int = 100) -> List[str]:
        """åŠ è½½æµ‹è¯•ç”¨çš„è‚¡ç¥¨ä»£ç ï¼Œç¡®ä¿ä¸ºå›½æ ‡æ ¼å¼"""
        codes_file = os.path.join(os.path.dirname(__file__), 'all_codes.txt')
        try:
            with open(codes_file, 'r', encoding='utf-8') as f:
                all_codes = [line.strip() for line in f if line.strip()]
            
            # è¿‡æ»¤å’Œè½¬æ¢ä¸ºå›½æ ‡æ ¼å¼
            national_codes = []
            from pqquotation import helpers
            
            for code in all_codes:
                try:
                    if helpers.validate_stock_code(code):
                        # å¦‚æœä¸æ˜¯å›½æ ‡æ ¼å¼ï¼Œè½¬æ¢ä¸ºå›½æ ‡æ ¼å¼
                        if not self.is_national_format(code):
                            # æ ‡å‡†åŒ–ä¸º6ä½æ•°å­—ï¼Œç„¶åè½¬æ¢ä¸ºå›½æ ‡æ ¼å¼
                            digit_code = helpers.normalize_stock_code(code)
                            national_code = helpers.convert_to_national_format(digit_code)
                            national_codes.append(national_code)
                        else:
                            # å·²ç»æ˜¯å›½æ ‡æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
                            national_codes.append(code)
                except Exception as e:
                    logger.warning(f"è·³è¿‡æ— æ•ˆè‚¡ç¥¨ä»£ç  {code}: {e}")
                    continue
            
            # å»é‡
            national_codes = list(set(national_codes))
            
            # éšæœºé‡‡æ ·
            if len(national_codes) > sample_size:
                test_codes = random.sample(national_codes, sample_size)
            else:
                test_codes = national_codes
                
            logger.info(f"åŠ è½½å›½æ ‡æ ¼å¼æµ‹è¯•è‚¡ç¥¨ä»£ç  {len(test_codes)} ä¸ª")
            return test_codes
            
        except Exception as e:
            logger.error(f"åŠ è½½è‚¡ç¥¨ä»£ç å¤±è´¥: {e}")
            return []
    
    def fetch_data_concurrent(self, codes: List[str]) -> Dict[str, Dict[str, Any]]:
        """å¹¶å‘è·å–å¤šä¸ªæ•°æ®æºçš„æ•°æ®"""
        results = {}
        
        def fetch_single_source(source: str) -> Tuple[str, Dict[str, Any]]:
            """è·å–å•ä¸ªæ•°æ®æºçš„æ•°æ®"""
            try:
                if source not in self.quotation_apis:
                    return source, {}
                
                api = self.quotation_apis[source]
                # å¼ºåˆ¶ä½¿ç”¨å›½æ ‡æ ¼å¼ï¼Œç¡®ä¿è¾“å…¥è¾“å‡ºä»£ç æ ¼å¼ä¸€è‡´
                data = api.real(codes, return_format='national')
                
                # è®°å½•æˆåŠŸè·å–çš„è‚¡ç¥¨æ•°é‡
                if data:
                    self.results['source_availability'][source] += len(data)
                
                return source, data if data else {}
                
            except Exception as e:
                logger.warning(f"è·å– {source} æ•°æ®å¤±è´¥: {e}")
                return source, {}
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘è·å–
        with ThreadPoolExecutor(max_workers=len(self.sources)) as executor:
            future_to_source = {
                executor.submit(fetch_single_source, source): source 
                for source in self.sources
            }
            
            for future in as_completed(future_to_source):
                source, data = future.result()
                results[source] = data
                logger.info(f"{source} è·å–åˆ° {len(data)} ä¸ªè‚¡ç¥¨æ•°æ®")
        
        return results
    
    def normalize_data(self, data: Dict[str, Any], source: str) -> Dict[str, Any]:
        """æ ‡å‡†åŒ–æ•°æ®æ ¼å¼"""
        normalized = {}
        field_map = self.field_mapping.get(source, {})
        
        for field, mapped_field in field_map.items():
            if mapped_field in data:
                value = data[mapped_field]
                # æ•°å€¼ç±»å‹è½¬æ¢
                if field in ['now', 'close', 'open', 'high', 'low'] and value is not None:
                    try:
                        normalized[field] = float(value)
                    except (ValueError, TypeError):
                        normalized[field] = None
                elif field == 'volume' and value is not None:
                    try:
                        normalized[field] = int(float(value))
                    except (ValueError, TypeError):
                        normalized[field] = None
                else:
                    normalized[field] = value
        
        return normalized
    
    def compare_values(self, field: str, val1: Any, val2: Any) -> Tuple[bool, str]:
        """æ¯”è¾ƒä¸¤ä¸ªå€¼æ˜¯å¦ä¸€è‡´"""
        if val1 is None or val2 is None:
            return val1 == val2, "ç©ºå€¼æ¯”è¾ƒ"
        
        if field == 'name':
            # åç§°æ¯”è¾ƒï¼šè®¡ç®—ç›¸ä¼¼åº¦
            similarity = self.calculate_similarity(str(val1), str(val2))
            consistent = similarity >= self.tolerance['name_similarity']
            return consistent, f"ç›¸ä¼¼åº¦: {similarity:.2f}"
        
        elif field in ['now', 'close', 'open', 'high', 'low']:
            # ä»·æ ¼æ¯”è¾ƒï¼šä½¿ç”¨ç™¾åˆ†æ¯”å®¹å·®
            if val1 == 0 or val2 == 0:
                return val1 == val2, "é›¶å€¼æ¯”è¾ƒ"
            
            diff_percent = abs(val1 - val2) / max(abs(val1), abs(val2)) * 100
            consistent = diff_percent <= self.tolerance['price_percent']
            return consistent, f"å·®å¼‚: {diff_percent:.3f}%"
        
        elif field == 'volume':
            # æˆäº¤é‡æ¯”è¾ƒï¼šè€ƒè™‘å·²çŸ¥çš„æ•°æ®æºå·®å¼‚
            if val1 == 0 or val2 == 0:
                return val1 == val2, "é›¶æˆäº¤é‡æ¯”è¾ƒ"
            
            diff_percent = abs(val1 - val2) / max(abs(val1), abs(val2)) * 100
            consistent = diff_percent <= self.tolerance['volume_percent']
            
            # å¦‚æœå·®å¼‚å¾ˆå¤§ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯QQæ•°æ®æºçš„å·²çŸ¥é—®é¢˜
            if not consistent and diff_percent > 80:
                # QQçš„æˆäº¤é‡å¯èƒ½æ˜¯æ‰‹æ•°ï¼Œå°è¯•è½¬æ¢éªŒè¯
                ratio = max(val1, val2) / min(val1, val2)
                if 1.5 < ratio < 100:  # QQä¸Sina/DCçš„æˆäº¤é‡æ¯”ä¾‹èŒƒå›´ï¼ˆè¦†ç›–æ‰€æœ‰å·²çŸ¥å·®å¼‚ï¼‰
                    return True, f"æ•°æ®æºå·®å¼‚(æ¯”ä¾‹:{ratio:.1f}å€,å·²çŸ¥QQæˆäº¤é‡è®¡ç®—å·®å¼‚)"
            
            return consistent, f"å·®å¼‚: {diff_percent:.1f}%"
        
        else:
            # å…¶ä»–å­—æ®µç²¾ç¡®æ¯”è¾ƒ
            return val1 == val2, "ç²¾ç¡®æ¯”è¾ƒ"
    
    def validate_stock_code_format(self, input_code: str, returned_codes: List[str], source: str) -> bool:
        """éªŒè¯è¿”å›çš„è‚¡ç¥¨ä»£ç æ ¼å¼æ˜¯å¦ä¸è¾“å…¥ä¸€è‡´
        :param input_code: è¾“å…¥çš„å›½æ ‡æ ¼å¼è‚¡ç¥¨ä»£ç  (å¦‚: 000001.SZ)
        :param returned_codes: æ•°æ®æºè¿”å›çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨
        :param source: æ•°æ®æºåç§°
        :return: Trueè¡¨ç¤ºæ ¼å¼æ­£ç¡®ï¼ŒFalseè¡¨ç¤ºæ ¼å¼ä¸ä¸€è‡´
        """
        if not returned_codes:
            return False
            
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¸è¾“å…¥ä»£ç å®Œå…¨åŒ¹é…çš„è¿”å›ä»£ç 
        if input_code in returned_codes:
            return True
        
        # æ£€æŸ¥è¿”å›çš„ä»£ç æ ¼å¼æ˜¯å¦éƒ½æ˜¯å›½æ ‡æ ¼å¼
        for returned_code in returned_codes:
            if not self.is_national_format(returned_code):
                logger.warning(f"{source}è¿”å›éå›½æ ‡æ ¼å¼ä»£ç : {returned_code} (è¾“å…¥: {input_code})")
                return False
        
        # å¦‚æœè¿”å›ä»£ç ä¸åŒ…å«è¾“å…¥ä»£ç ï¼Œä½†æ ¼å¼éƒ½æ­£ç¡®ï¼Œå¯èƒ½æ˜¯ä»£ç æ˜ å°„é—®é¢˜
        # æå–6ä½æ•°å­—éƒ¨åˆ†è¿›è¡Œæ¯”è¾ƒ
        input_digits = self.extract_digits_from_code(input_code)
        if input_digits:
            for returned_code in returned_codes:
                returned_digits = self.extract_digits_from_code(returned_code)
                if returned_digits == input_digits:
                    logger.info(f"{source}ä»£ç æ˜ å°„: {input_code} -> {returned_code}")
                    return True
        
        return False
    
    def is_national_format(self, code: str) -> bool:
        """æ£€æŸ¥è‚¡ç¥¨ä»£ç æ˜¯å¦ä¸ºå›½æ ‡æ ¼å¼ (000001.SZ)"""
        import re
        return bool(re.match(r'^\d{6}\.(SH|SZ|BJ)$', code))
    
    def extract_digits_from_code(self, code: str) -> str:
        """ä»è‚¡ç¥¨ä»£ç ä¸­æå–6ä½æ•°å­—éƒ¨åˆ†"""
        import re
        match = re.search(r'(\d{6})', code)
        return match.group(1) if match else ""
    
    def find_matching_code(self, input_code: str, returned_codes: List[str]) -> Optional[str]:
        """åœ¨è¿”å›çš„ä»£ç åˆ—è¡¨ä¸­æŸ¥æ‰¾ä¸è¾“å…¥ä»£ç åŒ¹é…çš„ä»£ç 
        æ”¯æŒä¸åŒæ ¼å¼ä¹‹é—´çš„åŒ¹é…
        """
        if not returned_codes:
            return None
            
        input_digits = self.extract_digits_from_code(input_code)
        if not input_digits:
            return None
            
        # æŸ¥æ‰¾ç›¸åŒæ•°å­—éƒ¨åˆ†çš„ä»£ç 
        for returned_code in returned_codes:
            returned_digits = self.extract_digits_from_code(returned_code)
            if returned_digits == input_digits:
                return returned_code
        
        return None

    def calculate_similarity(self, str1: str, str2: str) -> float:
        """è®¡ç®—å­—ç¬¦ä¸²ç›¸ä¼¼åº¦ï¼ˆç®€å•å®ç°ï¼‰"""
        if not str1 or not str2:
            return 0.0
        
        # å»é™¤ç©ºæ ¼ç­‰å­—ç¬¦
        str1 = str1.replace(' ', '').replace('*', '')
        str2 = str2.replace(' ', '').replace('*', '')
        
        if str1 == str2:
            return 1.0
        
        # ç®€å•çš„ç¼–è¾‘è·ç¦»ç®—æ³•
        len1, len2 = len(str1), len(str2)
        dp = [[0] * (len2 + 1) for _ in range(len1 + 1)]
        
        for i in range(len1 + 1):
            dp[i][0] = i
        for j in range(len2 + 1):
            dp[0][j] = j
        
        for i in range(1, len1 + 1):
            for j in range(1, len2 + 1):
                if str1[i-1] == str2[j-1]:
                    dp[i][j] = dp[i-1][j-1]
                else:
                    dp[i][j] = min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1]) + 1
        
        max_len = max(len1, len2)
        similarity = (max_len - dp[len1][len2]) / max_len if max_len > 0 else 0.0
        return similarity
    
    def compare_stock_data(self, code: str, source_data: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """æ¯”è¾ƒå•ä¸ªè‚¡ç¥¨åœ¨ä¸åŒæ•°æ®æºçš„æ•°æ®"""
        comparison = {
            'code': code,
            'timestamp': datetime.now().isoformat(),
            'sources': {},
            'consistency': {},
            'overall_consistent': True,
            'notes': [],
            'code_format_issues': []  # æ–°å¢ï¼šè®°å½•è‚¡ç¥¨ä»£ç æ ¼å¼é—®é¢˜
        }
        
        # æ ‡å‡†åŒ–å„æ•°æ®æºçš„æ•°æ®å¹¶éªŒè¯è‚¡ç¥¨ä»£ç æ ¼å¼
        normalized_data = {}
        for source, data in source_data.items():
            # æ£€æŸ¥è¿”å›çš„è‚¡ç¥¨ä»£ç æ ¼å¼æ˜¯å¦ä¸è¾“å…¥ä¸€è‡´
            returned_codes = list(data.keys()) if data else []
            code_format_ok = self.validate_stock_code_format(code, returned_codes, source)
            if not code_format_ok:
                comparison['code_format_issues'].append(
                    f"{source}è¿”å›çš„è‚¡ç¥¨ä»£ç æ ¼å¼ä¸æ­£ç¡®: è¾“å…¥{code}, è¿”å›{returned_codes}"
                )
            
            if code in data:
                normalized_data[source] = self.normalize_data(data[code], source)
                comparison['sources'][source] = data[code]
            else:
                # å¦‚æœç›´æ¥åŒ¹é…ä¸åˆ°ï¼Œå°è¯•æŸ¥æ‰¾ç›¸ä¼¼çš„ä»£ç 
                matched_code = self.find_matching_code(code, returned_codes)
                if matched_code:
                    normalized_data[source] = self.normalize_data(data[matched_code], source)
                    comparison['sources'][source] = data[matched_code]
                    comparison['notes'].append(f"{source}ä»£ç æ˜ å°„: {code} -> {matched_code}")
                else:
                    normalized_data[source] = {}
                    comparison['notes'].append(f"{source}æœªè¿”å›æ•°æ®")
        
        # å¦‚æœå°‘äº2ä¸ªæ•°æ®æºæœ‰æ•°æ®ï¼Œè·³è¿‡æ¯”è¾ƒ
        available_sources = [s for s, d in normalized_data.items() if d]
        if len(available_sources) < 2:
            comparison['overall_consistent'] = False
            comparison['notes'].append("å¯ç”¨æ•°æ®æºä¸è¶³2ä¸ª")
            return comparison
        
        # æ¯”è¾ƒæ¯ä¸ªå­—æ®µ
        fields_to_compare = ['name', 'now', 'close', 'open', 'high', 'low', 'volume']
        
        for field in fields_to_compare:
            field_consistent = True
            field_details = {}
            
            # è·å–æ‰€æœ‰æ•°æ®æºåœ¨è¯¥å­—æ®µçš„å€¼
            field_values = {}
            for source in available_sources:
                field_values[source] = normalized_data[source].get(field)
            
            # ä¸¤ä¸¤æ¯”è¾ƒ
            sources_list = list(field_values.keys())
            for i in range(len(sources_list)):
                for j in range(i + 1, len(sources_list)):
                    source1, source2 = sources_list[i], sources_list[j]
                    val1, val2 = field_values[source1], field_values[source2]
                    
                    consistent, detail = self.compare_values(field, val1, val2)
                    
                    pair_key = f"{source1}_vs_{source2}"
                    field_details[pair_key] = {
                        'consistent': consistent,
                        'detail': detail,
                        'values': {source1: val1, source2: val2}
                    }
                    
                    if not consistent:
                        field_consistent = False
                    
                    # æ›´æ–°ç»Ÿè®¡
                    self.results['field_consistency'][field][f"{source1}_{source2}"] += 1 if consistent else 0
            
            comparison['consistency'][field] = {
                'consistent': field_consistent,
                'details': field_details
            }
            
            if not field_consistent:
                comparison['overall_consistent'] = False
        
        return comparison
    
    def test_batch_consistency(self, codes: List[str]) -> List[Dict[str, Any]]:
        """æµ‹è¯•ä¸€æ‰¹è‚¡ç¥¨çš„æ•°æ®ä¸€è‡´æ€§"""
        logger.info(f"å¼€å§‹æµ‹è¯• {len(codes)} ä¸ªè‚¡ç¥¨çš„æ•°æ®ä¸€è‡´æ€§")
        
        # å¹¶å‘è·å–æ•°æ®
        source_data = self.fetch_data_concurrent(codes)
        
        # æ¯”è¾ƒæ¯ä¸ªè‚¡ç¥¨çš„æ•°æ®
        batch_results = []
        for code in codes:
            try:
                comparison = self.compare_stock_data(code, source_data)
                batch_results.append(comparison)
                
                # æ›´æ–°ç»Ÿè®¡
                self.results['total_tested'] += 1
                
                # ç»Ÿè®¡ä»£ç æ ¼å¼é—®é¢˜
                if comparison['code_format_issues']:
                    self.results['code_format_issues'].extend(comparison['code_format_issues'])
                    for issue in comparison['code_format_issues']:
                        for source in self.sources:
                            if source in issue:
                                self.results['code_format_stats'][f"{source}_format_error"] += 1
                else:
                    # è®°å½•æ ¼å¼æ­£ç¡®çš„æ•°æ®æº
                    for source in self.sources:
                        if source in source_data and code in source_data[source]:
                            self.results['code_format_stats'][f"{source}_format_ok"] += 1
                
                if comparison['overall_consistent']:
                    self.results['successful_comparisons'] += 1
                else:
                    # æ”¶é›†è¯¦ç»†çš„ä¸ä¸€è‡´ä¿¡æ¯
                    inconsistency_details = self._extract_inconsistency_details(comparison)
                    self.results['inconsistent_stocks'].append({
                        'code': code,
                        'issues': comparison['notes'] + inconsistency_details['summary'],
                        'detailed_issues': inconsistency_details['details'],
                        'code_format_issues': comparison['code_format_issues'],
                        'timestamp': comparison['timestamp']
                    })
                    
            except Exception as e:
                logger.error(f"æ¯”è¾ƒè‚¡ç¥¨ {code} æ•°æ®æ—¶å‡ºé”™: {e}")
                self.results['error_stocks'].append({
                    'code': code,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                })
        
        return batch_results
    
    def run_consistency_test(self, sample_size: int = 100) -> None:
        """è¿è¡Œä¸€è‡´æ€§æµ‹è¯•"""
        logger.info("=" * 60)
        logger.info("å¼€å§‹æ•°æ®ä¸€è‡´æ€§æµ‹è¯•")
        logger.info("=" * 60)
        
        # åŠ è½½æµ‹è¯•è‚¡ç¥¨ä»£ç 
        test_codes = self.load_test_codes(sample_size)
        if not test_codes:
            logger.error("æ— æ³•åŠ è½½æµ‹è¯•è‚¡ç¥¨ä»£ç ")
            return
        
        # åˆ†æ‰¹æµ‹è¯•
        all_results = []
        batches = [test_codes[i:i + self.batch_size] for i in range(0, len(test_codes), self.batch_size)]
        
        for i, batch in enumerate(batches):
            logger.info(f"å¤„ç†æ‰¹æ¬¡ {i+1}/{len(batches)}")
            batch_results = self.test_batch_consistency(batch)
            all_results.extend(batch_results)
            
            # æ‰¹æ¬¡é—´ç­‰å¾…
            if i < len(batches) - 1:
                time.sleep(2)
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report(all_results)
        self.save_detailed_results(all_results)
    
    def generate_report(self, results: List[Dict[str, Any]]) -> None:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        logger.info("\n" + "=" * 60)
        logger.info("æ•°æ®ä¸€è‡´æ€§æµ‹è¯•æŠ¥å‘Š")
        logger.info("=" * 60)
        
        total = self.results['total_tested']
        consistent = self.results['successful_comparisons']
        consistency_rate = (consistent / total * 100) if total > 0 else 0
        
        print(f"\næ€»ä½“ç»Ÿè®¡:")
        print(f"  æµ‹è¯•è‚¡ç¥¨æ•°é‡: {total}")
        print(f"  ä¸€è‡´æ€§é€šè¿‡: {consistent}")
        print(f"  ä¸€è‡´æ€§æ¯”ä¾‹: {consistency_rate:.1f}%")
        print(f"  ä¸ä¸€è‡´è‚¡ç¥¨: {len(self.results['inconsistent_stocks'])}")
        print(f"  é”™è¯¯è‚¡ç¥¨æ•°: {len(self.results['error_stocks'])}")
        
        print(f"\næ•°æ®æºå¯ç”¨æ€§:")
        for source in self.sources:
            available = self.results['source_availability'].get(source, 0)
            availability_rate = (available / total * 100) if total > 0 else 0
            print(f"  {source}: {available}/{total} ({availability_rate:.1f}%)")
        
        print(f"\nè‚¡ç¥¨ä»£ç æ ¼å¼ä¸€è‡´æ€§:")
        for source in self.sources:
            format_ok = self.results['code_format_stats'].get(f"{source}_format_ok", 0)
            format_error = self.results['code_format_stats'].get(f"{source}_format_error", 0)
            total_checked = format_ok + format_error
            if total_checked > 0:
                format_rate = (format_ok / total_checked * 100)
                print(f"  {source}: {format_ok}/{total_checked} æ ¼å¼æ­£ç¡® ({format_rate:.1f}%)")
            else:
                print(f"  {source}: æ— æ•°æ®æ£€æŸ¥")
        
        # æ˜¾ç¤ºä»£ç æ ¼å¼é—®é¢˜æ±‡æ€»
        if self.results['code_format_issues']:
            print(f"\nä»£ç æ ¼å¼é—®é¢˜æ±‡æ€» (å‰10ä¸ª):")
            for issue in self.results['code_format_issues'][:10]:
                print(f"  {issue}")
        
        print(f"\nå­—æ®µä¸€è‡´æ€§ç»Ÿè®¡:")
        # è®¡ç®—å„å­—æ®µçš„ä¸€è‡´æ€§æ¯”ä¾‹
        field_consistency_summary = {}
        for field, source_pairs in self.results['field_consistency'].items():
            total_comparisons = 0
            consistent_comparisons = 0
            
            for pair, count in source_pairs.items():
                if '_vs_' in pair:
                    total_comparisons += 1
                    if count > 0:
                        consistent_comparisons += 1
            
            if total_comparisons > 0:
                consistency_pct = (consistent_comparisons / total_comparisons) * 100
                field_consistency_summary[field] = (consistent_comparisons, total_comparisons, consistency_pct)
        
        for field, (consistent_pairs, total_pairs, rate) in field_consistency_summary.items():
            print(f"  {field}: {consistent_pairs}/{total_pairs} æ•°æ®æºå¯¹ä¸€è‡´ ({rate:.1f}%)")
        
        # æ˜¾ç¤ºä¸»è¦ä¸ä¸€è‡´é—®é¢˜
        if self.results['inconsistent_stocks']:
            print(f"\nä¸»è¦ä¸ä¸€è‡´é—®é¢˜ (å‰10ä¸ª):")
            for issue in self.results['inconsistent_stocks'][:10]:
                print(f"  {issue['code']}: {', '.join(issue['issues'])}")
                
                # æ˜¾ç¤ºè¯¦ç»†çš„ä¸ä¸€è‡´åŸå› 
                if 'detailed_issues' in issue:
                    for field, field_issues in issue['detailed_issues'].items():
                        for detail in field_issues[:2]:  # æ¯ä¸ªå­—æ®µæœ€å¤šæ˜¾ç¤º2ä¸ªè¯¦ç»†é—®é¢˜
                            print(f"    - {detail}")
                        if len(field_issues) > 2:
                            print(f"    - ...è¿˜æœ‰{len(field_issues)-2}ä¸ª{field}é—®é¢˜")
    
    def _extract_inconsistency_details(self, comparison: Dict[str, Any]) -> Dict[str, Any]:
        """æå–è¯¦ç»†çš„ä¸ä¸€è‡´ä¿¡æ¯"""
        details = {
            'summary': [],
            'details': {}
        }
        
        # åˆ†æå„å­—æ®µçš„ä¸ä¸€è‡´æƒ…å†µ
        for field, field_data in comparison.get('consistency', {}).items():
            if not field_data.get('consistent', True):
                field_issues = []
                field_details = field_data.get('details', {})
                
                for pair_key, pair_data in field_details.items():
                    if not pair_data.get('consistent', True):
                        source1, source2 = pair_key.split('_vs_')
                        val1 = pair_data['values'][source1]
                        val2 = pair_data['values'][source2]
                        detail = pair_data.get('detail', '')
                        
                        issue_desc = f"{source1}({val1}) vs {source2}({val2}): {detail}"
                        field_issues.append(issue_desc)
                
                if field_issues:
                    summary_desc = f"{field}å­—æ®µä¸ä¸€è‡´"
                    details['summary'].append(summary_desc)
                    details['details'][field] = field_issues
        
        return details
    
    def save_detailed_results(self, results: List[Dict[str, Any]]) -> None:
        """ä¿å­˜è¯¦ç»†ç»“æœ"""
        timestamp = int(time.time())
        
        # ä¿å­˜å®Œæ•´çš„æ¯”è¾ƒç»“æœ
        detailed_file = f"consistency_test_detailed_{timestamp}.json"
        try:
            # å¤„ç†datetimeåºåˆ—åŒ–é—®é¢˜
            def json_serializer(obj):
                if isinstance(obj, datetime):
                    return obj.isoformat()
                raise TypeError(f"Object {obj} is not JSON serializable")
            
            with open(detailed_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'test_info': {
                        'timestamp': datetime.now().isoformat(),
                        'total_tested': self.results['total_tested'],
                        'batch_size': self.batch_size,
                        'tolerance': self.tolerance
                    },
                    'summary': self.results,
                    'detailed_results': results
                }, f, ensure_ascii=False, indent=2, default=json_serializer)
            
            logger.info(f"è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {detailed_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜è¯¦ç»†ç»“æœå¤±è´¥: {e}")
        
        # ä¿å­˜ç®€åŒ–æŠ¥å‘Š
        summary_file = f"consistency_test_summary_{timestamp}.txt"
        try:
            with open(summary_file, 'w', encoding='utf-8') as f:
                f.write("æ•°æ®ä¸€è‡´æ€§æµ‹è¯•æ‘˜è¦æŠ¥å‘Š\n")
                f.write("=" * 50 + "\n\n")
                f.write(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æµ‹è¯•è‚¡ç¥¨: {self.results['total_tested']} ä¸ª\n")
                f.write(f"ä¸€è‡´æ€§é€šè¿‡: {self.results['successful_comparisons']} ä¸ª\n")
                f.write(f"ä¸€è‡´æ€§æ¯”ä¾‹: {self.results['successful_comparisons']/self.results['total_tested']*100:.1f}%\n\n")
                
                f.write("æ•°æ®æºå¯ç”¨æ€§:\n")
                for source in self.sources:
                    available = self.results['source_availability'].get(source, 0)
                    f.write(f"  {source}: {available}/{self.results['total_tested']}\n")
                
                f.write("\nä¸ä¸€è‡´è‚¡ç¥¨åˆ—è¡¨:\n")
                for issue in self.results['inconsistent_stocks']:
                    f.write(f"  {issue['code']}: {', '.join(issue['issues'])}\n")
                    
                    # å†™å…¥è¯¦ç»†çš„ä¸ä¸€è‡´åŸå› 
                    if 'detailed_issues' in issue:
                        for field, field_issues in issue['detailed_issues'].items():
                            f.write(f"    {field}é—®é¢˜:\n")
                            for detail in field_issues:
                                f.write(f"      - {detail}\n")
            
            logger.info(f"æ‘˜è¦æŠ¥å‘Šå·²ä¿å­˜åˆ°: {summary_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜æ‘˜è¦æŠ¥å‘Šå¤±è´¥: {e}")


def test_code_format_specifically():
    """ä¸“é—¨æµ‹è¯•è‚¡ç¥¨ä»£ç æ ¼å¼ä¸€è‡´æ€§"""
    print("\n" + "=" * 80)
    print("è‚¡ç¥¨ä»£ç æ ¼å¼ä¸€è‡´æ€§ä¸“é¡¹æµ‹è¯•")
    print("=" * 80)
    
    # æµ‹è¯•ç‰¹å®šçš„å›½æ ‡æ ¼å¼è‚¡ç¥¨ä»£ç 
    test_codes = [
        '000001.SZ',  # å¹³å®‰é“¶è¡Œ
        '600000.SH',  # æµ¦å‘é“¶è¡Œ  
        '002004.SZ',  # åé‚¦å¥åº·
        '300001.SZ',  # ç‰¹é”å¾·
        '000300.SH',  # æ²ªæ·±300
    ]
    
    sources = ['sina', 'qq', 'dc']
    
    for code in test_codes:
        print(f"\nã€æµ‹è¯•è‚¡ç¥¨: {code}ã€‘")
        print("-" * 50)
        
        for source in sources:
            try:
                api = pqquotation.use(source)
                data = api.real([code], return_format='national')
                
                if data:
                    returned_codes = list(data.keys())
                    print(f"  {source:>6}: è¾“å…¥ {code} -> è¿”å› {returned_codes}")
                    
                    # éªŒè¯æ ¼å¼
                    if code in returned_codes:
                        print(f"         âœ“ ä»£ç æ ¼å¼ä¸€è‡´")
                    else:
                        print(f"         âŒ ä»£ç æ ¼å¼ä¸ä¸€è‡´")
                        
                        # å°è¯•æ‰¾åˆ°å¯¹åº”çš„ä»£ç 
                        checker = DataConsistencyChecker()
                        matched = checker.find_matching_code(code, returned_codes)
                        if matched:
                            print(f"         ğŸ’¡ æ‰¾åˆ°åŒ¹é…ä»£ç : {matched}")
                else:
                    print(f"  {source:>6}: æ— æ•°æ®è¿”å›")
                    
            except Exception as e:
                print(f"  {source:>6}: é”™è¯¯ - {str(e)}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æµ‹è¯•æ•°æ®æºä¸€è‡´æ€§')
    parser.add_argument('--sample-size', type=int, default=100, help='æµ‹è¯•æ ·æœ¬å¤§å° (é»˜è®¤: 100)')
    parser.add_argument('--price-tolerance', type=float, default=0.1, help='ä»·æ ¼å®¹å·®ç™¾åˆ†æ¯” (é»˜è®¤: 0.1)')
    parser.add_argument('--volume-tolerance', type=float, default=5.0, help='æˆäº¤é‡å®¹å·®ç™¾åˆ†æ¯” (é»˜è®¤: 5.0)')
    parser.add_argument('--code-format-test', action='store_true', help='åªè¿è¡Œè‚¡ç¥¨ä»£ç æ ¼å¼æµ‹è¯•')
    
    args = parser.parse_args()
    
    # å¦‚æœåªè¿è¡Œä»£ç æ ¼å¼æµ‹è¯•
    if args.code_format_test:
        test_code_format_specifically()
        return
    
    # åˆ›å»ºæµ‹è¯•å™¨
    checker = DataConsistencyChecker()
    checker.tolerance['price_percent'] = args.price_tolerance
    checker.tolerance['volume_percent'] = args.volume_tolerance
    
    try:
        # é¦–å…ˆè¿è¡Œä»£ç æ ¼å¼æµ‹è¯•
        test_code_format_specifically()
        
        # ç„¶åè¿è¡Œå®Œæ•´çš„ä¸€è‡´æ€§æµ‹è¯•
        checker.run_consistency_test(sample_size=args.sample_size)
        
    except KeyboardInterrupt:
        logger.info("\næµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
    finally:
        logger.info("æµ‹è¯•ç»“æŸ")


if __name__ == '__main__':
    main()