# -*- coding: utf-8 -*-
# @version        : 1.0
# @Create Time    : 2025/5/9 20:30
# @File           : example
# @IDE            : PyCharm
# @desc           : RabbitMQ-ARQ ä½¿ç”¨ç¤ºä¾‹

import asyncio
import logging
import os
import sys
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ï¼ˆç”¨äºå¼€å‘ç¯å¢ƒï¼‰
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from rabbitmq_arq import (
    Worker,
    WorkerSettings,
    RabbitMQClient,
    RabbitMQSettings,
    JobContext,
    Retry,
    default_queue_name
)

# é…ç½®ä¸­æ–‡æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
    ]
)

# åˆ›å»ºä¸“é—¨çš„æ—¥å¿—å¯¹è±¡
logger = logging.getLogger('rabbitmq_arq.example')
worker_logger = logging.getLogger('rabbitmq_arq.worker')
task_logger = logging.getLogger('rabbitmq_arq.task')
stats_logger = logging.getLogger('rabbitmq_arq.stats')

# è®¾ç½®æ—¥å¿—çº§åˆ«
logger.setLevel(logging.INFO)
worker_logger.setLevel(logging.INFO)
task_logger.setLevel(logging.INFO)
stats_logger.setLevel(logging.INFO)

# RabbitMQ è¿æ¥é…ç½®ï¼ˆä»…è¿æ¥ç›¸å…³ï¼‰
rabbitmq_settings = RabbitMQSettings(
    rabbitmq_url="amqp://guest:guest@localhost:5672/",
    prefetch_count=100,
    connection_timeout=30,
)


# === ä»»åŠ¡å‡½æ•°å®šä¹‰ ===

async def process_user_data(ctx: JobContext, user_id: int, data: Dict[str, Any], *args, **kwargs):
    """
    å¤„ç†ç”¨æˆ·æ•°æ®çš„å¼‚æ­¥ä»»åŠ¡å‡½æ•°
    
    Args:
        ctx: ä»»åŠ¡ä¸Šä¸‹æ–‡
        user_id: ç”¨æˆ·ID
        data: ç”¨æˆ·æ•°æ®
    """
    task_logger.info(f"ğŸ“Š å¼€å§‹å¤„ç†ç”¨æˆ· {user_id} çš„æ•°æ®")
    task_logger.info(f"ä»»åŠ¡ID: {ctx.job_id}")
    task_logger.info(f"ä»»åŠ¡å°è¯•æ¬¡æ•°: {ctx.job_try}")

    try:
        # æ¨¡æ‹Ÿæ•°æ®å¤„ç†é€»è¾‘
        task_logger.info(f"æ­£åœ¨éªŒè¯ç”¨æˆ·æ•°æ®...")
        await asyncio.sleep(1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´

        # æ¨¡æ‹Ÿä¸€äº›å¯èƒ½å¤±è´¥çš„æ“ä½œ
        if data.get('should_fail', False):
            raise Exception("æ¨¡æ‹Ÿçš„å¤„ç†å¤±è´¥")

        task_logger.info(f"æ­£åœ¨ä¿å­˜å¤„ç†ç»“æœ...")
        await asyncio.sleep(0.5)

        result = {
            'user_id': user_id,
            'processed_at': asyncio.get_event_loop().time(),
            'data_size': len(str(data)),
            'status': 'completed'
        }

        task_logger.info(f"âœ… ç”¨æˆ· {user_id} çš„æ•°æ®å¤„ç†å®Œæˆ")
        return result

    except Exception as e:
        task_logger.error(f"âŒ ç”¨æˆ· {user_id} çš„æ•°æ®å¤„ç†å¤±è´¥: {e}")

        # å¦‚æœæ˜¯ç¬¬1æ¬¡å°è¯•ï¼Œæˆ‘ä»¬å¯ä»¥é‡è¯•
        if ctx.job_try <= 2:
            task_logger.info(f"ğŸ”„ å‡†å¤‡é‡è¯•ä»»åŠ¡ (å°è¯•æ¬¡æ•°: {ctx.job_try})")
            raise Retry(defer=5)  # 5ç§’åé‡è¯•
        else:
            task_logger.error(f"ğŸ’¥ ä»»åŠ¡å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
            raise


async def send_email(ctx: JobContext, to: str, subject: str, body: str):
    """
    å‘é€é‚®ä»¶çš„å¼‚æ­¥ä»»åŠ¡å‡½æ•°
    
    Args:
        ctx: ä»»åŠ¡ä¸Šä¸‹æ–‡
        to: æ”¶ä»¶äºº
        subject: é‚®ä»¶ä¸»é¢˜
        body: é‚®ä»¶å†…å®¹
    """
    task_logger.info(f"ğŸ“§ å‡†å¤‡å‘é€é‚®ä»¶åˆ° {to}")
    task_logger.info(f"ä»»åŠ¡ID: {ctx.job_id}")
    task_logger.info(f"ä¸»é¢˜: {subject}")

    try:
        # æ¨¡æ‹Ÿé‚®ä»¶å‘é€é€»è¾‘
        task_logger.info("æ­£åœ¨è¿æ¥é‚®ä»¶æœåŠ¡å™¨...")
        await asyncio.sleep(1)

        task_logger.info("æ­£åœ¨å‘é€é‚®ä»¶...")
        await asyncio.sleep(5)

        # æ¨¡æ‹Ÿä¸€äº›å¯èƒ½å¤±è´¥çš„æƒ…å†µ
        if "fail" in to.lower():
            raise Exception("é‚®ä»¶æœåŠ¡å™¨è¿æ¥å¤±è´¥")

        task_logger.info(f"âœ… é‚®ä»¶å·²æˆåŠŸå‘é€åˆ° {to}")
        return {
            'to': to,
            'subject': subject,
            'sent_at': asyncio.get_event_loop().time(),
            'status': 'sent'
        }

    except Exception as e:
        task_logger.error(f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {e}")

        # é‚®ä»¶å‘é€å¤±è´¥æ—¶çš„é‡è¯•é€»è¾‘
        if ctx.job_try <= 3:
            task_logger.info(f"ğŸ”„ é‚®ä»¶å°†åœ¨ 10 ç§’åé‡è¯• (å°è¯•æ¬¡æ•°: {ctx.job_try})")
            raise Retry(defer=10)
        else:
            task_logger.error("ğŸ’¥ é‚®ä»¶å‘é€æœ€ç»ˆå¤±è´¥")
            raise


# === ç”Ÿå‘½å‘¨æœŸé’©å­å‡½æ•° ===

async def startup(ctx: dict):
    """Worker å¯åŠ¨æ—¶çš„é’©å­å‡½æ•°"""
    worker_logger.info("ğŸš€ Worker æ­£åœ¨å¯åŠ¨...")
    worker_logger.info("åˆå§‹åŒ–æ•°æ®åº“è¿æ¥...")
    worker_logger.info("åˆå§‹åŒ–ç¼“å­˜è¿æ¥...")

    # åœ¨ä¸Šä¸‹æ–‡ä¸­è®¾ç½®ç»Ÿè®¡ä¿¡æ¯
    ctx['worker_stats'] = {
        'jobs_complete': 0,
        'jobs_failed': 0,
        'jobs_retried': 0,
        'start_time': asyncio.get_event_loop().time()
    }

    worker_logger.info("âœ… Worker å¯åŠ¨å®Œæˆ")


async def shutdown(ctx: dict):
    """Worker å…³é—­æ—¶çš„é’©å­å‡½æ•°"""
    worker_logger.info("ğŸ›‘ Worker æ­£åœ¨å…³é—­...")

    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = ctx.get('worker_stats', {})
    start_time = stats.get('start_time', 0)
    current_time = asyncio.get_event_loop().time()
    running_time = current_time - start_time if start_time else 0

    stats_logger.info("ğŸ“Š Worker è¿è¡Œç»Ÿè®¡:")
    stats_logger.info(f"   è¿è¡Œæ—¶é—´: {running_time:.1f} ç§’")
    stats_logger.info(f"   å®Œæˆä»»åŠ¡: {stats.get('jobs_complete', 0)} ä¸ª")
    stats_logger.info(f"   å¤±è´¥ä»»åŠ¡: {stats.get('jobs_failed', 0)} ä¸ª")
    stats_logger.info(f"   é‡è¯•ä»»åŠ¡: {stats.get('jobs_retried', 0)} ä¸ª")

    worker_logger.info("æ¸…ç†æ•°æ®åº“è¿æ¥...")
    worker_logger.info("æ¸…ç†ç¼“å­˜è¿æ¥...")
    worker_logger.info("âœ… Worker å…³é—­å®Œæˆ")


async def job_start(ctx: dict):
    """æ¯ä¸ªä»»åŠ¡å¼€å§‹å‰çš„é’©å­å‡½æ•°"""
    job_id = ctx.get('job_id', 'unknown')
    task_logger.info(f"â–¶ï¸ ä»»åŠ¡ {job_id} å¼€å§‹æ‰§è¡Œ")


async def job_end(ctx: dict):
    """æ¯ä¸ªä»»åŠ¡ç»“æŸåçš„é’©å­å‡½æ•°"""
    job_id = ctx.get('job_id', 'unknown')
    task_logger.info(f"â¹ï¸ ä»»åŠ¡ {job_id} æ‰§è¡Œç»“æŸ")

    # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
    stats = ctx.get('worker_stats', {})
    if ctx.get('job_status') == 'completed':
        stats['jobs_complete'] = stats.get('jobs_complete', 0) + 1
    elif ctx.get('job_status') == 'failed':
        stats['jobs_failed'] = stats.get('jobs_failed', 0) + 1
    elif ctx.get('job_status') == 'retried':
        stats['jobs_retried'] = stats.get('jobs_retried', 0) + 1


# === Worker é…ç½® ===

# å¸¸è§„æ¨¡å¼ Worker é…ç½®
worker_settings = WorkerSettings(
    rabbitmq_settings=rabbitmq_settings,
    functions=[process_user_data, send_email],
    worker_name="demo_worker",

    # é˜Ÿåˆ—é…ç½®
    queue_name=default_queue_name,
    dlq_name=f"{default_queue_name}.dlq",

    # ä»»åŠ¡å¤„ç†é…ç½®
    max_retries=3,
    retry_backoff=5.0,
    job_timeout=300,
    max_concurrent_jobs=5,

    # ç”Ÿå‘½å‘¨æœŸé’©å­
    on_startup=startup,
    on_shutdown=shutdown,
    on_job_start=job_start,
    on_job_end=job_end,

    # æ—¥å¿—é…ç½®
    log_level="INFO",
)

# Burst æ¨¡å¼ Worker é…ç½®
burst_worker_settings = WorkerSettings(
    rabbitmq_settings=rabbitmq_settings,
    functions=[process_user_data, send_email],
    worker_name="demo_burst_worker",

    # é˜Ÿåˆ—é…ç½®
    queue_name=default_queue_name,
    dlq_name=f"{default_queue_name}.dlq",

    # ä»»åŠ¡å¤„ç†é…ç½®
    max_retries=3,
    retry_backoff=5.0,
    job_timeout=300,
    max_concurrent_jobs=3,

    # Burst æ¨¡å¼é…ç½®
    burst_mode=True,
    burst_timeout=300,
    burst_check_interval=1.0,
    burst_wait_for_tasks=True,

    # ç”Ÿå‘½å‘¨æœŸé’©å­
    on_startup=startup,
    on_shutdown=shutdown,
    on_job_start=job_start,
    on_job_end=job_end,

    # æ—¥å¿—é…ç½®
    log_level="INFO",
)


# === ä¸»å‡½æ•°ï¼šæäº¤ä»»åŠ¡ ===

async def main():
    """æäº¤ä¸€äº›ç¤ºä¾‹ä»»åŠ¡"""
    logger.info("ğŸš€ å¼€å§‹ä»»åŠ¡æäº¤ç¤ºä¾‹")

    # åˆ›å»ºå®¢æˆ·ç«¯
    client = RabbitMQClient(rabbitmq_settings)

    try:
        # è¿æ¥åˆ° RabbitMQ
        await client.connect()
        logger.info("âœ… å·²è¿æ¥åˆ° RabbitMQ")

        # æäº¤æ•°æ®å¤„ç†ä»»åŠ¡
        logger.info("ğŸ“¤ æäº¤ç”¨æˆ·æ•°æ®å¤„ç†ä»»åŠ¡...")

        user_data_jobs = []
        # for i in range(3):
        #     job = await client.enqueue_job(
        #         "process_user_data",
        #         user_id=1000 + i,
        #         data={
        #             "name": f"ç”¨æˆ·{i}",
        #             "email": f"user{i}@example.com",
        #             "age": 20 + i,
        #             "should_fail": i == 1  # è®©ç¬¬äºŒä¸ªä»»åŠ¡å¤±è´¥ï¼Œæµ‹è¯•é‡è¯•æœºåˆ¶
        #         },
        #         queue_name=default_queue_name
        #     )
        #     user_data_jobs.append(job)
        #     logger.info(f"   ä»»åŠ¡ {job.job_id} å·²æäº¤ (ç”¨æˆ·{i})")

        # æäº¤é‚®ä»¶å‘é€ä»»åŠ¡
        logger.info("ğŸ“¤ æäº¤é‚®ä»¶å‘é€ä»»åŠ¡...")

        email_jobs = []
        emails = [
            ("user1@example.com", "æ¬¢è¿ä½¿ç”¨ RabbitMQ-ARQ", "è¿™æ˜¯ä¸€ä¸ªæ¬¢è¿é‚®ä»¶"),
            ("user2@example.com", "ç³»ç»Ÿé€šçŸ¥", "æ‚¨çš„è´¦æˆ·ä¿¡æ¯å·²æ›´æ–°"),
            # ("fail@example.com", "æµ‹è¯•å¤±è´¥", "è¿™å°é‚®ä»¶ä¼šå‘é€å¤±è´¥"),  # æµ‹è¯•å¤±è´¥é‡è¯•
        ]

        for to, subject, body in emails:
            job = await client.enqueue_job(
                "send_email",
                to=to,
                subject=subject,
                body=body,
                queue_name=default_queue_name
            )
            email_jobs.append(job)
            logger.info(f"   é‚®ä»¶ä»»åŠ¡ {job.job_id} å·²æäº¤ (å‘é€åˆ° {to})")
        # å‚æ•°é”™è¯¯
        # job = await client.enqueue_job(
        #     "send_email",
        #     aaa="123",
        #     queue_name=default_queue_name
        # )
        # email_jobs.append(job)
        # # æäº¤ä¸€äº›å»¶è¿Ÿä»»åŠ¡
        # logger.info("ğŸ“¤ æäº¤å»¶è¿Ÿä»»åŠ¡...")
        #
        # delayed_job = await client.enqueue_job(
        #     "send_email",
        #     to="delayed@example.com",
        #     subject="å»¶è¿Ÿé‚®ä»¶",
        #     body="è¿™æ˜¯ä¸€å°å»¶è¿Ÿ 10 ç§’å‘é€çš„é‚®ä»¶",
        #     queue_name=default_queue_name,
        #     _defer_by=10
        # )
        # logger.info(f"   å»¶è¿Ÿä»»åŠ¡ {delayed_job.job_id} å·²æäº¤ (10ç§’åæ‰§è¡Œ)")

        logger.info("âœ… æ‰€æœ‰ä»»åŠ¡å·²æäº¤å®Œæˆ")
        logger.info(f"   æ•°æ®å¤„ç†ä»»åŠ¡: {len(user_data_jobs)} ä¸ª")
        logger.info(f"   é‚®ä»¶å‘é€ä»»åŠ¡: {len(email_jobs)} ä¸ª")
        logger.info(f"   å»¶è¿Ÿä»»åŠ¡: 1 ä¸ª")
        logger.info("")
        logger.info("ğŸ’¡ æ¥ä¸‹æ¥ä½ å¯ä»¥:")
        logger.info("   python example.py worker       # å¯åŠ¨å¸¸è§„æ¨¡å¼ Worker")
        logger.info("   python example.py burst-worker # å¯åŠ¨ Burst æ¨¡å¼ Worker")

    except Exception as e:
        logger.error(f"âŒ ä»»åŠ¡æäº¤å¤±è´¥: {e}")
        raise
    finally:
        logger.info("æ­£åœ¨å…³é—­å®¢æˆ·ç«¯è¿æ¥...")
        await client.close()
        logger.info("å®¢æˆ·ç«¯è¿æ¥å·²å…³é—­")


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1:
        command = sys.argv[1]

        if command == "worker":
            # è¿è¡Œå¸¸è§„æ¨¡å¼ Worker
            logger.info("å¯åŠ¨å¸¸è§„æ¨¡å¼ Worker...")
            worker = Worker(worker_settings)
            asyncio.run(worker.main())

        elif command == "burst-worker":
            # è¿è¡Œ Burst æ¨¡å¼ Worker
            logger.info("å¯åŠ¨ Burst æ¨¡å¼ Worker...")
            logger.info("ğŸš€ Burst æ¨¡å¼: å¤„ç†å®Œé˜Ÿåˆ—ä¸­çš„æ‰€æœ‰ä»»åŠ¡åè‡ªåŠ¨é€€å‡º")
            worker = Worker(burst_worker_settings)
            asyncio.run(worker.main())

        else:
            logger.error(f"âŒ æœªçŸ¥å‘½ä»¤: {command}")
            logger.info("ğŸ’¡ å¯ç”¨å‘½ä»¤:")
            logger.info("  python example.py              # æäº¤ä»»åŠ¡")
            logger.info("  python example.py worker       # å¯åŠ¨å¸¸è§„æ¨¡å¼ Worker")
            logger.info("  python example.py burst-worker # å¯åŠ¨ Burst æ¨¡å¼ Worker")
    else:
        # æäº¤ä»»åŠ¡
        logger.info("å¯åŠ¨ä»»åŠ¡æäº¤æ¨¡å¼...")
        asyncio.run(main())
