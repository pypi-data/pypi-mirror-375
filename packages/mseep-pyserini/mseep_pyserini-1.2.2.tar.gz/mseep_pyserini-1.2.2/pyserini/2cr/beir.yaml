conditions:
  - name: bm25-flat
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index beir-v1.0.0-${dataset}.flat --topics beir-v1.0.0-${dataset}-test --output $output --output-format trec --hits 1000 --bm25 --remove-query
    datasets:
      - dataset: trec-covid
        scores:
          - nDCG@10: 0.5947
            R@100: 0.1091
            R@1000: 0.3955
      - dataset: bioasq
        scores:
          - nDCG@10: 0.5225
            R@100: 0.7687
            R@1000: 0.9030
      - dataset: nfcorpus
        scores:
          - nDCG@10: 0.3218
            R@100: 0.2457
            R@1000: 0.3704
      - dataset: nq
        scores:
          - nDCG@10: 0.3055
            R@100: 0.7513
            R@1000: 0.8958
      - dataset: hotpotqa
        scores:
          - nDCG@10: 0.6330
            R@100: 0.7957
            R@1000: 0.8820
      - dataset: fiqa
        scores:
          - nDCG@10: 0.2361
            R@100: 0.5395
            R@1000: 0.7393
      - dataset: signal1m
        scores:
          - nDCG@10: 0.3304
            R@100: 0.3703
            R@1000: 0.5642
      - dataset: trec-news
        scores:
          - nDCG@10: 0.3952
            R@100: 0.4469
            R@1000: 0.7051
      - dataset: robust04
        scores:
          - nDCG@10: 0.4070
            R@100: 0.3746
            R@1000: 0.6345
      - dataset: arguana
        scores:
          - nDCG@10: 0.3970
            R@100: 0.9324
            R@1000: 0.9872
      - dataset: webis-touche2020
        scores:
          - nDCG@10: 0.4422
            R@100: 0.5822
            R@1000: 0.8621
      - dataset: cqadupstack-android
        scores:
          - nDCG@10: 0.3801
            R@100: 0.6829
            R@1000: 0.8632
      - dataset: cqadupstack-english
        scores:
          - nDCG@10: 0.3453
            R@100: 0.5757
            R@1000: 0.7323
      - dataset: cqadupstack-gaming
        scores:
          - nDCG@10: 0.4822
            R@100: 0.7651
            R@1000: 0.8945
      - dataset: cqadupstack-gis
        scores:
          - nDCG@10: 0.2901
            R@100: 0.6119
            R@1000: 0.8174
      - dataset: cqadupstack-mathematica
        scores:
          - nDCG@10: 0.2015
            R@100: 0.4877
            R@1000: 0.7221
      - dataset: cqadupstack-physics
        scores:
          - nDCG@10: 0.3214
            R@100: 0.6326
            R@1000: 0.8340
      - dataset: cqadupstack-programmers
        scores:
          - nDCG@10: 0.2802
            R@100: 0.5588
            R@1000: 0.7734
      - dataset: cqadupstack-stats
        scores:
          - nDCG@10: 0.2711
            R@100: 0.5338
            R@1000: 0.7310
      - dataset: cqadupstack-tex
        scores:
          - nDCG@10: 0.2244
            R@100: 0.4686
            R@1000: 0.6907
      - dataset: cqadupstack-unix
        scores:
          - nDCG@10: 0.2749
            R@100: 0.5417
            R@1000: 0.7616
      - dataset: cqadupstack-webmasters
        scores:
          - nDCG@10: 0.3059
            R@100: 0.5820
            R@1000: 0.8066
      - dataset: cqadupstack-wordpress
        scores:
          - nDCG@10: 0.2483
            R@100: 0.5152
            R@1000: 0.7552
      - dataset: quora
        scores:
          - nDCG@10: 0.7886
            R@100: 0.9733
            R@1000: 0.9950
      - dataset: dbpedia-entity
        scores:
          - nDCG@10: 0.3180
            R@100: 0.4682
            R@1000: 0.6760
      - dataset: scidocs
        scores:
          - nDCG@10: 0.1490
            R@100: 0.3477
            R@1000: 0.5638
      - dataset: fever
        scores:
          - nDCG@10: 0.6513
            R@100: 0.9185
            R@1000: 0.9589
      - dataset: climate-fever
        scores:
          - nDCG@10: 0.1651
            R@100: 0.4249
            R@1000: 0.6324
      - dataset: scifact
        scores:
          - nDCG@10: 0.6789
            R@100: 0.9253
            R@1000: 0.9767
  - name: bm25-multifield
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index beir-v1.0.0-${dataset}.multifield --topics beir-v1.0.0-${dataset}-test --output $output --output-format trec --hits 1000 --bm25 --remove-query --fields contents=1.0 title=1.0
    datasets:
      - dataset: trec-covid
        scores:
          - nDCG@10: 0.6559
            R@100: 0.1141
            R@1000: 0.3891
      - dataset: bioasq
        scores:
          - nDCG@10: 0.4646
            R@100: 0.7145
            R@1000: 0.8428
      - dataset: nfcorpus
        scores:
          - nDCG@10: 0.3254
            R@100: 0.2500
            R@1000: 0.3718
      - dataset: nq
        scores:
          - nDCG@10: 0.3285
            R@100: 0.7597
            R@1000: 0.9019
      - dataset: hotpotqa
        scores:
          - nDCG@10: 0.6027
            R@100: 0.7400
            R@1000: 0.8405
      - dataset: fiqa
        scores:
          - nDCG@10: 0.2361
            R@100: 0.5395
            R@1000: 0.7393
      - dataset: signal1m
        scores:
          - nDCG@10: 0.3304
            R@100: 0.3703
            R@1000: 0.5642
      - dataset: trec-news
        scores:
          - nDCG@10: 0.3977
            R@100: 0.4216
            R@1000: 0.6993
      - dataset: robust04
        scores:
          - nDCG@10: 0.4070
            R@100: 0.3746
            R@1000: 0.6345
      - dataset: arguana
        scores:
          - nDCG@10: 0.4142
            R@100: 0.9431
            R@1000: 0.9893
      - dataset: webis-touche2020
        scores:
          - nDCG@10: 0.3673
            R@100: 0.5376
            R@1000: 0.8668
      - dataset: cqadupstack-android
        scores:
          - nDCG@10: 0.3709
            R@100: 0.6889
            R@1000: 0.8712
      - dataset: cqadupstack-english
        scores:
          - nDCG@10: 0.3321
            R@100: 0.5842
            R@1000: 0.7574
      - dataset: cqadupstack-gaming
        scores:
          - nDCG@10: 0.4418
            R@100: 0.7571
            R@1000: 0.8882
      - dataset: cqadupstack-gis
        scores:
          - nDCG@10: 0.2904
            R@100: 0.6458
            R@1000: 0.8248
      - dataset: cqadupstack-mathematica
        scores:
          - nDCG@10: 0.2046
            R@100: 0.5215
            R@1000: 0.7559
      - dataset: cqadupstack-physics
        scores:
          - nDCG@10: 0.3248
            R@100: 0.6486
            R@1000: 0.8506
      - dataset: cqadupstack-programmers
        scores:
          - nDCG@10: 0.2963
            R@100: 0.6194
            R@1000: 0.8096
      - dataset: cqadupstack-stats
        scores:
          - nDCG@10: 0.2790
            R@100: 0.5719
            R@1000: 0.7619
      - dataset: cqadupstack-tex
        scores:
          - nDCG@10: 0.2086
            R@100: 0.4954
            R@1000: 0.7222
      - dataset: cqadupstack-unix
        scores:
          - nDCG@10: 0.2788
            R@100: 0.5721
            R@1000: 0.7783
      - dataset: cqadupstack-webmasters
        scores:
          - nDCG@10: 0.3008
            R@100: 0.6100
            R@1000: 0.8226
      - dataset: cqadupstack-wordpress
        scores:
          - nDCG@10: 0.2562
            R@100: 0.5526
            R@1000: 0.7848
      - dataset: quora
        scores:
          - nDCG@10: 0.7886
            R@100: 0.9733
            R@1000: 0.9950
      - dataset: dbpedia-entity
        scores:
          - nDCG@10: 0.3128
            R@100: 0.3981
            R@1000: 0.5848
      - dataset: scidocs
        scores:
          - nDCG@10: 0.1581
            R@100: 0.3561
            R@1000: 0.5599
      - dataset: fever
        scores:
          - nDCG@10: 0.7530
            R@100: 0.9309
            R@1000: 0.9599
      - dataset: climate-fever
        scores:
          - nDCG@10: 0.2129
            R@100: 0.4357
            R@1000: 0.6099
      - dataset: scifact
        scores:
          - nDCG@10: 0.6647
            R@100: 0.9076
            R@1000: 0.9800
  - name: splade-pp-ed
    command: python -m pyserini.search.lucene --threads ${sparse_threads} --batch-size ${sparse_batch_size} --index beir-v1.0.0-${dataset}.splade-pp-ed --topics beir-v1.0.0-${dataset}.test.splade-pp-ed --output $output --output-format trec --hits 1000 --impact --remove-query
    datasets:
      - dataset: trec-covid
        scores:
          - nDCG@10: 0.7274
            R@100: 0.1282
            R@1000: 0.4441
      - dataset: bioasq
        scores:
          - nDCG@10: 0.4980
            R@100: 0.7385
            R@1000: 0.8757
      - dataset: nfcorpus
        scores:
          - nDCG@10: 0.3470
            R@100: 0.2844
            R@1000: 0.5925
      - dataset: nq
        scores:
          - nDCG@10: 0.5378
            R@100: 0.9296
            R@1000: 0.9839
      - dataset: hotpotqa
        scores:
          - nDCG@10: 0.6868
            R@100: 0.8177
            R@1000: 0.8952
      - dataset: fiqa
        scores:
          - nDCG@10: 0.3475
            R@100: 0.6314
            R@1000: 0.8392
      - dataset: signal1m
        scores:
          - nDCG@10: 0.3008
            R@100: 0.3398
            R@1000: 0.5492
      - dataset: trec-news
        scores:
          - nDCG@10: 0.4152
            R@100: 0.4414
            R@1000: 0.7060
      - dataset: robust04
        scores:
          - nDCG@10: 0.4679
            R@100: 0.3850
            R@1000: 0.6228
      - dataset: arguana
        scores:
          - nDCG@10: 0.5203
            R@100: 0.9744
            R@1000: 0.9950
      - dataset: webis-touche2020
        scores:
          - nDCG@10: 0.2468
            R@100: 0.4715
            R@1000: 0.8191
      - dataset: cqadupstack-android
        scores:
          - nDCG@10: 0.3904
            R@100: 0.7404
            R@1000: 0.9064
      - dataset: cqadupstack-english
        scores:
          - nDCG@10: 0.4079
            R@100: 0.6946
            R@1000: 0.8454
      - dataset: cqadupstack-gaming
        scores:
          - nDCG@10: 0.4957
            R@100: 0.8131
            R@1000: 0.9221
      - dataset: cqadupstack-gis
        scores:
          - nDCG@10: 0.3150
            R@100: 0.6320
            R@1000: 0.8325
      - dataset: cqadupstack-mathematica
        scores:
          - nDCG@10: 0.2377
            R@100: 0.5797
            R@1000: 0.8007
      - dataset: cqadupstack-physics
        scores:
          - nDCG@10: 0.3599
            R@100: 0.7196
            R@1000: 0.9010
      - dataset: cqadupstack-programmers
        scores:
          - nDCG@10: 0.3401
            R@100: 0.6585
            R@1000: 0.8603
      - dataset: cqadupstack-stats
        scores:
          - nDCG@10: 0.2990
            R@100: 0.5894
            R@1000: 0.7776
      - dataset: cqadupstack-tex
        scores:
          - nDCG@10: 0.2530
            R@100: 0.5161
            R@1000: 0.7341
      - dataset: cqadupstack-unix
        scores:
          - nDCG@10: 0.3167
            R@100: 0.6214
            R@1000: 0.8257
      - dataset: cqadupstack-webmasters
        scores:
          - nDCG@10: 0.3167
            R@100: 0.6360
            R@1000: 0.8710
      - dataset: cqadupstack-wordpress
        scores:
          - nDCG@10: 0.2733
            R@100: 0.5945
            R@1000: 0.7924
      - dataset: quora
        scores:
          - nDCG@10: 0.8343
            R@100: 0.9863
            R@1000: 0.9989
      - dataset: dbpedia-entity
        scores:
          - nDCG@10: 0.4366
            R@100: 0.5624
            R@1000: 0.7838
      - dataset: scidocs
        scores:
          - nDCG@10: 0.1591
            R@100: 0.3730
            R@1000: 0.6016
      - dataset: fever
        scores:
          - nDCG@10: 0.7882
            R@100: 0.9459
            R@1000: 0.9660
      - dataset: climate-fever
        scores:
          - nDCG@10: 0.2297
            R@100: 0.5211
            R@1000: 0.7183
      - dataset: scifact
        scores:
          - nDCG@10: 0.7041
            R@100: 0.9353
            R@1000: 0.9867
  - name: contriever
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --encoder-class contriever --encoder facebook/contriever --index beir-v1.0.0-${dataset}.contriever --topics beir-v1.0.0-${dataset}-test --output $output --hits 1000 --remove-query
    datasets:
      - dataset: trec-covid
        scores:
          - nDCG@10: 0.2732
            R@100: 0.0368
            R@1000: 0.1675
      - dataset: bioasq
        scores:
          - nDCG@10: 0.3016
            R@100: 0.5412
            R@1000: 0.7396
      - dataset: nfcorpus
        scores:
          - nDCG@10: 0.3173
            R@100: 0.2943
            R@1000: 0.6232
      - dataset: nq
        scores:
          - nDCG@10: 0.2536
            R@100: 0.7712
            R@1000: 0.9286
      - dataset: hotpotqa
        scores:
          - nDCG@10: 0.4807
            R@100: 0.7046
            R@1000: 0.8294
      - dataset: fiqa
        scores:
          - nDCG@10: 0.2449
            R@100: 0.5619
            R@1000: 0.8215
      - dataset: signal1m
        scores:
          - nDCG@10: 0.2338
            R@100: 0.2568
            R@1000: 0.4757
      - dataset: trec-news
        scores:
          - nDCG@10: 0.3484
            R@100: 0.4234
            R@1000: 0.7389
      - dataset: robust04
        scores:
          - nDCG@10: 0.3155
            R@100: 0.2757
            R@1000: 0.5097
      - dataset: arguana
        scores:
          - nDCG@10: 0.3791
            R@100: 0.9011
            R@1000: 0.9851
      - dataset: webis-touche2020
        scores:
          - nDCG@10: 0.1668
            R@100: 0.3736
            R@1000: 0.7144
      - dataset: cqadupstack-android
        scores:
          - nDCG@10: 0.3771
            R@100: 0.7436
            R@1000: 0.9173
      - dataset: cqadupstack-english
        scores:
          - nDCG@10: 0.3571
            R@100: 0.6442
            R@1000: 0.8042
      - dataset: cqadupstack-gaming
        scores:
          - nDCG@10: 0.4597
            R@100: 0.8092
            R@1000: 0.9354
      - dataset: cqadupstack-gis
        scores:
          - nDCG@10: 0.2411
            R@100: 0.5792
            R@1000: 0.8018
      - dataset: cqadupstack-mathematica
        scores:
          - nDCG@10: 0.1841
            R@100: 0.5127
            R@1000: 0.7757
      - dataset: cqadupstack-physics
        scores:
          - nDCG@10: 0.3430
            R@100: 0.7013
            R@1000: 0.8980
      - dataset: cqadupstack-programmers
        scores:
          - nDCG@10: 0.3029
            R@100: 0.6402
            R@1000: 0.8434
      - dataset: cqadupstack-stats
        scores:
          - nDCG@10: 0.2483
            R@100: 0.5269
            R@1000: 0.7417
      - dataset: cqadupstack-tex
        scores:
          - nDCG@10: 0.1540
            R@100: 0.4333
            R@1000: 0.6870
      - dataset: cqadupstack-unix
        scores:
          - nDCG@10: 0.2636
            R@100: 0.5879
            R@1000: 0.8212
      - dataset: cqadupstack-webmasters
        scores:
          - nDCG@10: 0.2878
            R@100: 0.6485
            R@1000: 0.8800
      - dataset: cqadupstack-wordpress
        scores:
          - nDCG@10: 0.1914
            R@100: 0.5364
            R@1000: 0.7551
      - dataset: quora
        scores:
          - nDCG@10: 0.8349
            R@100: 0.9871
            R@1000: 0.9981
      - dataset: dbpedia-entity
        scores:
          - nDCG@10: 0.2916
            R@100: 0.4529
            R@1000: 0.7142
      - dataset: scidocs
        scores:
          - nDCG@10: 0.1491
            R@100: 0.3601
            R@1000: 0.6105
      - dataset: fever
        scores:
          - nDCG@10: 0.6821
            R@100: 0.9356
            R@1000: 0.9655
      - dataset: climate-fever
        scores:
          - nDCG@10: 0.1550
            R@100: 0.4422
            R@1000: 0.7232
      - dataset: scifact
        scores:
          - nDCG@10: 0.6493
            R@100: 0.9260
            R@1000: 0.9967
  - name: contriever-msmarco
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --encoder-class contriever --encoder facebook/contriever-msmarco --index beir-v1.0.0-${dataset}.contriever-msmarco --topics beir-v1.0.0-${dataset}-test --output $output --hits 1000 --remove-query
    datasets:
      - dataset: trec-covid
        scores:
          - nDCG@10: 0.5964
            R@100: 0.0907
            R@1000: 0.3351
      - dataset: bioasq
        scores:
          - nDCG@10: 0.3829
            R@100: 0.6072
            R@1000: 0.7666
      - dataset: nfcorpus
        scores:
          - nDCG@10: 0.3281
            R@100: 0.3008
            R@1000: 0.6305
      - dataset: nq
        scores:
          - nDCG@10: 0.4977
            R@100: 0.9252
            R@1000: 0.986
      - dataset: hotpotqa
        scores:
          - nDCG@10: 0.6376
            R@100: 0.7772
            R@1000: 0.8718
      - dataset: fiqa
        scores:
          - nDCG@10: 0.3293
            R@100: 0.6558
            R@1000: 0.8695
      - dataset: signal1m
        scores:
          - nDCG@10: 0.2783
            R@100: 0.322
            R@1000: 0.5419
      - dataset: trec-news
        scores:
          - nDCG@10: 0.4283
            R@100: 0.4924
            R@1000: 0.7752
      - dataset: robust04
        scores:
          - nDCG@10: 0.4729
            R@100: 0.3917
            R@1000: 0.6552
      - dataset: arguana
        scores:
          - nDCG@10: 0.4461
            R@100: 0.9765
            R@1000: 0.9964
      - dataset: webis-touche2020
        scores:
          - nDCG@10: 0.204
            R@100: 0.442
            R@1000: 0.829
      - dataset: cqadupstack-android
        scores:
          - nDCG@10: 0.4255
            R@100: 0.7503
            R@1000: 0.9304
      - dataset: cqadupstack-english
        scores:
          - nDCG@10: 0.4326
            R@100: 0.6935
            R@1000: 0.8435
      - dataset: cqadupstack-gaming
        scores:
          - nDCG@10: 0.5276
            R@100: 0.8481
            R@1000: 0.9427
      - dataset: cqadupstack-gis
        scores:
          - nDCG@10: 0.3022
            R@100: 0.6272
            R@1000: 0.8417
      - dataset: cqadupstack-mathematica
        scores:
          - nDCG@10: 0.2355
            R@100: 0.5726
            R@1000: 0.7995
      - dataset: cqadupstack-physics
        scores:
          - nDCG@10: 0.4159
            R@100: 0.7619
            R@1000: 0.9162
      - dataset: cqadupstack-programmers
        scores:
          - nDCG@10: 0.3574
            R@100: 0.7191
            R@1000: 0.8878
      - dataset: cqadupstack-stats
        scores:
          - nDCG@10: 0.3095
            R@100: 0.586
            R@1000: 0.7805
      - dataset: cqadupstack-tex
        scores:
          - nDCG@10: 0.2209
            R@100: 0.4985
            R@1000: 0.7348
      - dataset: cqadupstack-unix
        scores:
          - nDCG@10: 0.3257
            R@100: 0.6161
            R@1000: 0.8373
      - dataset: cqadupstack-webmasters
        scores:
          - nDCG@10: 0.3392
            R@100: 0.7032
            R@1000: 0.8956
      - dataset: cqadupstack-wordpress
        scores:
          - nDCG@10: 0.2532
            R@100: 0.5769
            R@1000: 0.7929
      - dataset: quora
        scores:
          - nDCG@10: 0.8648
            R@100: 0.9935
            R@1000: 0.9994
      - dataset: dbpedia-entity
        scores:
          - nDCG@10: 0.4128
            R@100: 0.5414
            R@1000: 0.7751
      - dataset: scidocs
        scores:
          - nDCG@10: 0.1652
            R@100: 0.3783
            R@1000: 0.6216
      - dataset: fever
        scores:
          - nDCG@10: 0.7583
            R@100: 0.9494
            R@1000: 0.9705
      - dataset: climate-fever
        scores:
          - nDCG@10: 0.2371
            R@100: 0.5746
            R@1000: 0.8019
      - dataset: scifact
        scores:
          - nDCG@10: 0.6768
            R@100: 0.947
            R@1000: 0.9833
  - name: bge-base-en-v1.5.faiss
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --encoder-class auto --encoder BAAI/bge-base-en-v1.5 --l2-norm --query-prefix ${query_prefix} --index beir-v1.0.0-${dataset}.bge-base-en-v1.5 --topics beir-v1.0.0-${dataset}-test --output $output --hits 1000 --remove-query
    datasets:
      - dataset: arguana
        scores:
          - nDCG@10: 0.6362
            R@100: 0.9915
            R@1000: 0.9964
      - dataset: bioasq
        scores:
          - nDCG@10: 0.4148
            R@100: 0.6316
            R@1000: 0.8062
      - dataset: climate-fever
        scores:
          - nDCG@10: 0.3122
            R@100: 0.6362
            R@1000: 0.8305
      - dataset: cqadupstack-android
        scores:
          - nDCG@10: 0.5076
            R@100: 0.8454
            R@1000: 0.9611
      - dataset: cqadupstack-english
        scores:
          - nDCG@10: 0.4857
            R@100: 0.7586
            R@1000: 0.8839
      - dataset: cqadupstack-gaming
        scores:
          - nDCG@10: 0.5967
            R@100: 0.9036
            R@1000: 0.9719
      - dataset: cqadupstack-gis
        scores:
          - nDCG@10: 0.4127
            R@100: 0.7682
            R@1000: 0.9117
      - dataset: cqadupstack-mathematica
        scores:
          - nDCG@10: 0.3163
            R@100: 0.6922
            R@1000: 0.8810
      - dataset: cqadupstack-physics
        scores:
          - nDCG@10: 0.4724
            R@100: 0.8078
            R@1000: 0.9415
      - dataset: cqadupstack-programmers
        scores:
          - nDCG@10: 0.4238
            R@100: 0.7856
            R@1000: 0.9353
      - dataset: cqadupstack-stats
        scores:
          - nDCG@10: 0.3732
            R@100: 0.6727
            R@1000: 0.8445
      - dataset: cqadupstack-tex
        scores:
          - nDCG@10: 0.3115
            R@100: 0.6489
            R@1000: 0.8538
      - dataset: cqadupstack-unix
        scores:
          - nDCG@10: 0.4220
            R@100: 0.7797
            R@1000: 0.9235
      - dataset: cqadupstack-webmasters
        scores:
          - nDCG@10: 0.4072
            R@100: 0.7774
            R@1000: 0.9380
      - dataset: cqadupstack-wordpress
        scores:
          - nDCG@10: 0.3547
            R@100: 0.7047
            R@1000: 0.8861
      - dataset: dbpedia-entity
        scores:
          - nDCG@10: 0.4073
            R@100: 0.5298
            R@1000: 0.7833
      - dataset: fever
        scores:
          - nDCG@10: 0.8629
            R@100: 0.9719
            R@1000: 0.9855
      - dataset: fiqa
        scores:
          - nDCG@10: 0.4065
            R@100: 0.7415
            R@1000: 0.9083
      - dataset: hotpotqa
        scores:
          - nDCG@10: 0.7259
            R@100: 0.8726
            R@1000: 0.9423
      - dataset: nfcorpus
        scores:
          - nDCG@10: 0.3735
            R@100: 0.3368
            R@1000: 0.6622
      - dataset: nq
        scores:
          - nDCG@10: 0.5414
            R@100: 0.9415
            R@1000: 0.9859
      - dataset: quora
        scores:
          - nDCG@10: 0.8890
            R@100: 0.9968
            R@1000: 0.9998
      - dataset: robust04
        scores:
          - nDCG@10: 0.4435
            R@100: 0.3510
            R@1000: 0.5961
      - dataset: scidocs
        scores:
          - nDCG@10: 0.2172
            R@100: 0.4959
            R@1000: 0.7824
      - dataset: scifact
        scores:
          - nDCG@10: 0.7408
            R@100: 0.9667
            R@1000: 0.9967
      - dataset: signal1m
        scores:
          - nDCG@10: 0.2886
            R@100: 0.3112
            R@1000: 0.5331
      - dataset: trec-covid
        scores:
          - nDCG@10: 0.7815
            R@100: 0.1406
            R@1000: 0.4765
      - dataset: trec-news
        scores:
          - nDCG@10: 0.4424
            R@100: 0.4992
            R@1000: 0.7875
      - dataset: webis-touche2020
        scores:
          - nDCG@10: 0.2571
            R@100: 0.4867
            R@1000: 0.8298
  - name: bge-base-en-v1.5.lucene-flat
    command: python -m pyserini.search.lucene --threads ${dense_threads} --batch-size ${dense_batch_size} --dense --flat --index beir-v1.0.0-${dataset}.bge-base-en-v1.5.flat --topics beir-v1.0.0-${dataset} --onnx-encoder BgeBaseEn15 --output $output --output-format trec --hits 1000 --remove-query
    datasets:
      - dataset: arguana
        scores:
          - nDCG@10: 0.6228
            R@100: 0.9716
            R@1000: 0.9929
      - dataset: bioasq
        scores:
          - nDCG@10: 0.4148
            R@100: 0.6316
            R@1000: 0.8062
      - dataset: climate-fever
        scores:
          - nDCG@10: 0.3117
            R@100: 0.6354
            R@1000: 0.8306
      - dataset: cqadupstack-android
        scores:
          - nDCG@10: 0.5076
            R@100: 0.8454
            R@1000: 0.9611
      - dataset: cqadupstack-english
        scores:
          - nDCG@10: 0.4857
            R@100: 0.7586
            R@1000: 0.8839
      - dataset: cqadupstack-gaming
        scores:
          - nDCG@10: 0.5967
            R@100: 0.9036
            R@1000: 0.9719
      - dataset: cqadupstack-gis
        scores:
          - nDCG@10: 0.4131
            R@100: 0.7682
            R@1000: 0.9117
      - dataset: cqadupstack-mathematica
        scores:
          - nDCG@10: 0.3163
            R@100: 0.6922
            R@1000: 0.8810
      - dataset: cqadupstack-physics
        scores:
          - nDCG@10: 0.4724
            R@100: 0.8078
            R@1000: 0.9415
      - dataset: cqadupstack-programmers
        scores:
          - nDCG@10: 0.4238
            R@100: 0.7856
            R@1000: 0.9353
      - dataset: cqadupstack-stats
        scores:
          - nDCG@10: 0.3728
            R@100: 0.6719
            R@1000: 0.8445
      - dataset: cqadupstack-tex
        scores:
          - nDCG@10: 0.3115
            R@100: 0.6489
            R@1000: 0.8538
      - dataset: cqadupstack-unix
        scores:
          - nDCG@10: 0.4220
            R@100: 0.7797
            R@1000: 0.9235
      - dataset: cqadupstack-webmasters
        scores:
          - nDCG@10: 0.4072
            R@100: 0.7774
            R@1000: 0.9380
      - dataset: cqadupstack-wordpress
        scores:
          - nDCG@10: 0.3547
            R@100: 0.7047
            R@1000: 0.8861
      - dataset: dbpedia-entity
        scores:
          - nDCG@10: 0.4073
            R@100: 0.5298
            R@1000: 0.7833
      - dataset: fever
        scores:
          - nDCG@10: 0.8629
            R@100: 0.9719
            R@1000: 0.9855
      - dataset: fiqa
        scores:
          - nDCG@10: 0.4065
            R@100: 0.7415
            R@1000: 0.9083
      - dataset: hotpotqa
        scores:
          - nDCG@10: 0.7259
            R@100: 0.8726
            R@1000: 0.9423
      - dataset: nfcorpus
        scores:
          - nDCG@10: 0.3735
            R@100: 0.3368
            R@1000: 0.6622
      - dataset: nq
        scores:
          - nDCG@10: 0.5415
            R@100: 0.9414
            R@1000: 0.9859
      - dataset: quora
        scores:
          - nDCG@10: 0.8876
            R@100: 0.9968
            R@1000: 0.9999
      - dataset: robust04
        scores:
          - nDCG@10: 0.4435
            R@100: 0.3510
            R@1000: 0.5961
      - dataset: scidocs
        scores:
          - nDCG@10: 0.2172
            R@100: 0.4959
            R@1000: 0.7824
      - dataset: scifact
        scores:
          - nDCG@10: 0.7408
            R@100: 0.9667
            R@1000: 0.9967
      - dataset: signal1m
        scores:
          - nDCG@10: 0.2886
            R@100: 0.3112
            R@1000: 0.5331
      - dataset: trec-covid
        scores:
          - nDCG@10: 0.7815
            R@100: 0.1406
            R@1000: 0.4765
      - dataset: trec-news
        scores:
          - nDCG@10: 0.4424
            R@100: 0.4992
            R@1000: 0.7875
      - dataset: webis-touche2020
        scores:
          - nDCG@10: 0.2571
            R@100: 0.4867
            R@1000: 0.8298
  - name: bge-base-en-v1.5.lucene-hnsw
    command: python -m pyserini.search.lucene --threads ${dense_threads} --batch-size ${dense_batch_size} --dense --hnsw --index beir-v1.0.0-${dataset}.bge-base-en-v1.5.hnsw --topics beir-v1.0.0-${dataset} --onnx-encoder BgeBaseEn15 --output $output --output-format trec --hits 1000 --ef-search 1000 --remove-query
    datasets:
      - dataset: arguana
        scores:
          - nDCG@10: 0.6228
            R@100: 0.9716
            R@1000: 0.9929
      - dataset: bioasq
        scores:
          - nDCG@10: 0.4042
            R@100: 0.6118
            R@1000: 0.7687
      - dataset: climate-fever
        scores:
          - nDCG@10: 0.3117
            R@100: 0.6348
            R@1000: 0.8294
      - dataset: cqadupstack-android
        scores:
          - nDCG@10: 0.5076
            R@100: 0.8454
            R@1000: 0.9611
      - dataset: cqadupstack-english
        scores:
          - nDCG@10: 0.4855
            R@100: 0.7579
            R@1000: 0.8841
      - dataset: cqadupstack-gaming
        scores:
          - nDCG@10: 0.5967
            R@100: 0.9037
            R@1000: 0.9720
      - dataset: cqadupstack-gis
        scores:
          - nDCG@10: 0.4133
            R@100: 0.7682
            R@1000: 0.9117
      - dataset: cqadupstack-mathematica
        scores:
          - nDCG@10: 0.3163
            R@100: 0.6922
            R@1000: 0.8810
      - dataset: cqadupstack-physics
        scores:
          - nDCG@10: 0.4724
            R@100: 0.8078
            R@1000: 0.9415
      - dataset: cqadupstack-programmers
        scores:
          - nDCG@10: 0.4238
            R@100: 0.7856
            R@1000: 0.9354
      - dataset: cqadupstack-stats
        scores:
          - nDCG@10: 0.3728
            R@100: 0.6719
            R@1000: 0.8473
      - dataset: cqadupstack-tex
        scores:
          - nDCG@10: 0.3115
            R@100: 0.6489
            R@1000: 0.8534
      - dataset: cqadupstack-unix
        scores:
          - nDCG@10: 0.4220
            R@100: 0.7797
            R@1000: 0.9246
      - dataset: cqadupstack-webmasters
        scores:
          - nDCG@10: 0.4072
            R@100: 0.7774
            R@1000: 0.9380
      - dataset: cqadupstack-wordpress
        scores:
          - nDCG@10: 0.3547
            R@100: 0.7047
            R@1000: 0.8861
      - dataset: dbpedia-entity
        scores:
          - nDCG@10: 0.4076
            R@100: 0.5303
            R@1000: 0.7826
      - dataset: fever
        scores:
          - nDCG@10: 0.8620
            R@100: 0.9703
            R@1000: 0.9838
      - dataset: fiqa
        scores:
          - nDCG@10: 0.4065
            R@100: 0.7411
            R@1000: 0.9071
      - dataset: hotpotqa
        scores:
          - nDCG@10: 0.7241
            R@100: 0.8701
            R@1000: 0.9392
      - dataset: nfcorpus
        scores:
          - nDCG@10: 0.3735
            R@100: 0.3368
            R@1000: 0.6621
      - dataset: nq
        scores:
          - nDCG@10: 0.5415
            R@100: 0.9411
            R@1000: 0.9856
      - dataset: quora
        scores:
          - nDCG@10: 0.8876
            R@100: 0.9968
            R@1000: 0.9999
      - dataset: robust04
        scores:
          - nDCG@10: 0.4437
            R@100: 0.3505
            R@1000: 0.5971
      - dataset: scidocs
        scores:
          - nDCG@10: 0.2172
            R@100: 0.4959
            R@1000: 0.7824
      - dataset: scifact
        scores:
          - nDCG@10: 0.7408
            R@100: 0.9667
            R@1000: 0.9967
      - dataset: signal1m
        scores:
          - nDCG@10: 0.2869
            R@100: 0.3056
            R@1000: 0.5173
      - dataset: trec-covid
        scores:
          - nDCG@10: 0.7835
            R@100: 0.1405
            R@1000: 0.4769
      - dataset: trec-news
        scores:
          - nDCG@10: 0.4410
            R@100: 0.4943
            R@1000: 0.7786
      - dataset: webis-touche2020
        scores:
          - nDCG@10: 0.2571
            R@100: 0.4867
            R@1000: 0.8305
  - name: cohere-embed-english-v3.0
    command: python -m pyserini.search.faiss --threads ${dense_threads} --batch-size ${dense_batch_size} --index beir-v1.0.0-${dataset}.cohere-embed-english-v3.0  --topics beir-v1.0.0-${dataset}-test --encoded-queries cohere-embed-english-v3.0-beir-v1.0.0-${dataset}-test --output $output --hits 1000 --remove-query
    datasets:
      - dataset: arguana
        scores:
          - nDCG@10: 0.5398
            R@100: 0.9815
            R@1000: 0.9964
      - dataset: bioasq
        scores:
          - nDCG@10: 0.4565
            R@100: 0.6790
            R@1000: 0.8370
      - dataset: climate-fever
        scores:
          - nDCG@10: 0.2590
            R@100: 0.5810
            R@1000: 0.7833
      - dataset: cqadupstack-android
        scores:
          - nDCG@10: 0.5001
            R@100: 0.8319
            R@1000: 0.9583
      - dataset: cqadupstack-english
        scores:
        - nDCG@10: 0.4909
          R@100: 0.7573
          R@1000: 0.8711
      - dataset: cqadupstack-gaming
        scores:
        - nDCG@10: 0.6050
          R@100: 0.9003
          R@1000: 0.9708
      - dataset: cqadupstack-gis
        scores:
        - R@100: 0.7439
          R@1000: 0.8973
          nDCG@10: 0.3917
      - dataset: cqadupstack-mathematica
        scores:
        - nDCG@10: 0.3038
          R@100: 0.6671
          R@1000: 0.8690
      - dataset: cqadupstack-physics
        scores:
          - nDCG@10: 0.4382
            R@100: 0.7843
            R@1000: 0.9303
      - dataset: cqadupstack-programmers
        scores:
          - nDCG@10: 0.4367
            R@100: 0.7889
            R@1000: 0.9391
      - dataset: cqadupstack-stats
        scores:
          - nDCG@10: 0.3524
            R@100: 0.6431
            R@1000: 0.8297
      - dataset: cqadupstack-tex
        scores:
          - nDCG@10: 0.3083
            R@100: 0.6235
            R@1000: 0.8330
      - dataset: cqadupstack-unix
        scores:
          - nDCG@10: 0.4059
            R@100: 0.7543
            R@1000: 0.9189
      - dataset: cqadupstack-webmasters
        scores:
          - nDCG@10: 0.4068
            R@100: 0.7485
            R@1000: 0.9355
      - dataset: cqadupstack-wordpress
        scores:
          - nDCG@10: 0.3426
            R@100: 0.6937
            R@1000: 0.8916
      - dataset: dbpedia-entity
        scores:
          - nDCG@10: 0.4340
            R@100: 0.5358
            R@1000: 0.7642
      - dataset: fever
        scores:
          - nDCG@10: 0.8900
            R@100: 0.9649
            R@1000: 0.9787
      - dataset: fiqa
        scores:
          - nDCG@10: 0.4214
            R@100: 0.7357
            R@1000: 0.9190
      - dataset: hotpotqa
        scores:
          - nDCG@10: 0.7072
            R@100: 0.8232
            R@1000: 0.9093
      - dataset: nfcorpus
        scores:
          - nDCG@10: 0.3863
            R@100: 0.3512
            R@1000: 0.6657
      - dataset: nq
        scores:
          - nDCG@10: 0.6162
            R@100: 0.9560
            R@1000: 0.9896
      - dataset: quora
        scores:
          - nDCG@10: 0.8872
            R@100: 0.9962
            R@1000: 0.9999
      - dataset: robust04
        scores:
          - nDCG@10: 0.5406
            R@100: 0.4171
            R@1000: 0.6798
      - dataset: scidocs
        scores:
          - nDCG@10: 0.2034
            R@100: 0.4509
            R@1000: 0.7311
      - dataset: scifact
        scores:
          - nDCG@10: 0.7181
            R@100: 0.9633
            R@1000: 0.9933
      - dataset: signal1m
        scores:
          - nDCG@10: 0.2632
            R@100: 0.2832
            R@1000: 0.5146
      - dataset: trec-covid
        scores:
          - nDCG@10: 0.8178
            R@100: 0.1594
            R@1000: 0.5377
      - dataset: trec-news
        scores:
          - nDCG@10: 0.5042
            R@100: 0.5431
            R@1000: 0.8383
      - dataset: webis-touche2020
        scores:
          - nDCG@10: 0.3264
            R@100: 0.5157
            R@1000: 0.8640
