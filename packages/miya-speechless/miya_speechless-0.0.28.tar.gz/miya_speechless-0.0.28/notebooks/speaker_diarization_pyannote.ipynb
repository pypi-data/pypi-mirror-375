{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install pyannote.audio",
   "id": "b83f747d3cbd91f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install pydub",
   "id": "c0d019a919b979bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import time\n",
    "from pyannote.audio import Pipeline\n",
    "from pyannote.core import Annotation\n",
    "from typing import Optional\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "print(f\"TF32 matmul allowed: {torch.backends.cuda.matmul.allow_tf32}\")\n",
    "print(f\"TF32 cuDNN allowed: {torch.backends.cudnn.allow_tf32}\")"
   ],
   "id": "966168bf9685f179"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def perform_diarization(wav_path, num_speakers=2, use_gpu=False, api_token=None):\n",
    "    # Choose the device\n",
    "    device = \"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Initialize the pipeline and set device\n",
    "    if api_token:\n",
    "        pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization@2.1\", use_auth_token=api_token)\n",
    "    else:\n",
    "        pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization@2.1\")\n",
    "\n",
    "    # Ensure the model is loaded on the correct device\n",
    "    pipeline.to(torch.device(device))\n",
    "\n",
    "    # Run diarization\n",
    "    print(\"Performing diarization...\")\n",
    "    start_time = time.time()\n",
    "    diarization = pipeline({\"audio\": wav_path, \"num_speakers\": num_speakers})\n",
    "\n",
    "    # Print the results\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        print(f\"Speaker {speaker} speaks from {turn.start:.1f}s to {turn.end:.1f}s\")\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Total execution time: {elapsed_time:.2f} seconds\")\n",
    "    return diarization"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def download_diarization_model(api_token: Optional[str] = None) -> Pipeline:\n",
    "    \"\"\"\n",
    "    Downloads the pyannote.audio speaker diarization model and caches it locally.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    api_token : Optional[str], default=None\n",
    "        Hugging Face API token if the model is private. If the model is public, this can be omitted.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Pipeline\n",
    "        An instance of the `pyannote.audio.Pipeline` for speaker diarization.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ImportError\n",
    "        If `pyannote.audio` is not installed.\n",
    "    ValueError\n",
    "        If the provided API token is invalid or insufficient for accessing the model.\n",
    "    Exception\n",
    "        For any other exceptions that may occur during the model download.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Download the diarization model without an API token (for public models)\n",
    "    >>> pipeline = download_diarization_model()\n",
    "\n",
    "    >>> # Download the diarization model with an API token (for private models)\n",
    "    >>> pipeline = download_diarization_model(api_token=\"your_hugging_face_api_token\")\n",
    "\n",
    "    >>> # Use the downloaded pipeline for diarization\n",
    "    >>> diarization = pipeline(\"path/to/audio/file.wav\")\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Initialize the pipeline to trigger model download\n",
    "        if api_token:\n",
    "            pipeline = Pipeline.from_pretrained(\n",
    "                \"pyannote/speaker-diarization@2.1\",\n",
    "                use_auth_token=api_token\n",
    "            )\n",
    "        else:\n",
    "            pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization@2.1\")\n",
    "\n",
    "        print(\"Model downloaded and cached locally.\")\n",
    "        return pipeline\n",
    "\n",
    "    except ImportError as ie:\n",
    "        print(\"pyannote.audio is not installed. Please install it using 'pip install pyannote.audio'.\")\n",
    "        raise ie\n",
    "\n",
    "    except ValueError as ve:\n",
    "        print(\"Invalid API token provided or insufficient permissions to access the model.\")\n",
    "        raise ve\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while downloading the diarization model: {e}\")\n",
    "        raise e"
   ],
   "id": "f6f7e7cb7c929e00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def perform_diarization_offline(\n",
    "    wav_path: str,\n",
    "    num_speakers: int = 2,\n",
    "    use_gpu: bool = False,\n",
    "    model_path: Optional[str] = None\n",
    ") -> Annotation:\n",
    "    \"\"\"\n",
    "    Perform speaker diarization using a locally cached pyannote.audio model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    wav_path : str\n",
    "        Path to the input audio file.\n",
    "    num_speakers : int, default=2\n",
    "        Number of speakers to diarize.\n",
    "    use_gpu : bool, default=False\n",
    "        Whether to use GPU for processing. If `True`, the function will attempt to use CUDA.\n",
    "    model_path : Optional[str], default=None\n",
    "        Path to the local model directory. Must be provided for offline usage.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Annotation\n",
    "        The diarization result containing speaker segments.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `model_path` is not provided for offline usage.\n",
    "    ImportError\n",
    "        If required libraries (`pyannote.audio`, `torch`) are not installed.\n",
    "    RuntimeError\n",
    "        If GPU is requested but not available.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> wav_file_path = \"path/to/your/audio.wav\"\n",
    "    >>> local_model_path = \"/path/to/local_model/\"  # Replace with your local model path\n",
    "    >>> diarization = perform_diarization_offline(\n",
    "    ...     wav_path=wav_file_path,\n",
    "    ...     num_speakers=2,\n",
    "    ...     use_gpu=True,\n",
    "    ...     model_path=local_model_path\n",
    "    ... )\n",
    "    >>> for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    ...     print(f\"Speaker {speaker} speaks from {turn.start:.1f}s to {turn.end:.1f}s\")\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Validate model_path\n",
    "        if not model_path:\n",
    "            raise ValueError(\"`model_path` must be provided for offline usage.\")\n",
    "\n",
    "        # Choose the device\n",
    "        if use_gpu:\n",
    "            if torch.cuda.is_available():\n",
    "                device = \"cuda\"\n",
    "            else:\n",
    "                raise RuntimeError(\"GPU requested but CUDA is not available.\")\n",
    "        else:\n",
    "            device = \"cpu\"\n",
    "        print(f\"Using device: {device}\")\n",
    "\n",
    "        # Initialize the pipeline from the local model\n",
    "        pipeline = Pipeline.from_pretrained(model_path)\n",
    "        print(\"Pipeline loaded from local model.\")\n",
    "\n",
    "        # Ensure the model is loaded on the correct device\n",
    "        pipeline.to(torch.device(device))\n",
    "\n",
    "        # Run diarization\n",
    "        print(\"Performing diarization...\")\n",
    "        diarization = pipeline({\n",
    "            \"audio\": wav_path,\n",
    "            \"num_speakers\": num_speakers\n",
    "        })\n",
    "\n",
    "        # Print the results\n",
    "        for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "            print(f\"Speaker {speaker} speaks from {turn.start:.1f}s to {turn.end:.1f}s\")\n",
    "\n",
    "        return diarization\n",
    "\n",
    "    except ImportError as ie:\n",
    "        print(\"Required libraries are not installed. Please install them using:\")\n",
    "        print(\"pip install torch pyannote.audio\")\n",
    "        raise ie\n",
    "\n",
    "    except ValueError as ve:\n",
    "        print(f\"ValueError: {ve}\")\n",
    "        raise ve\n",
    "\n",
    "    except RuntimeError as re:\n",
    "        print(f\"RuntimeError: {re}\")\n",
    "        raise re\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during diarization: {e}\")\n",
    "        raise e"
   ],
   "id": "8f3f5e91d27c6ef3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "diarization_result = perform_diarization(\n",
    "    wav_path=\"sales_call_example_1.wav\",\n",
    "    use_gpu=True,\n",
    "    api_token=\"<your-hf-token-goes-here>\")"
   ],
   "id": "23c57d413eec360b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
