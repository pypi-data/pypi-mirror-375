Metadata-Version: 2.4
Name: llama-index-llms-stepfun
Version: 1.1.1
Summary: llama-index llms stepfun integration
Author-email: Bestony <bestony@linux.com>
License-Expression: MIT
License-File: LICENSE
Requires-Python: <4.0,>=3.9
Requires-Dist: llama-index-core<0.15,>=0.13.0
Requires-Dist: llama-index-llms-openai-like<0.6,>=0.5.0
Description-Content-Type: text/markdown

# LlamaIndex LLM Integration: Stepfun

## Installation

To install the required packages, run:

```bash
%pip install llama-index-llms-stepfun
!pip install llama-index
```

## Setup

### Initialize StepFun LLM

First, import the necessary libraries and set up your `StepFun` instance. Replace `step-1v-8k`, and `TOKEN` with your model name, and API key, respectively:

```python
import os
from typing import List, Optional
from llama_index.llms.stepfun import StepFun
from llama_index.core.llms import ChatMessage

llm = StepFun(
    api_key="TOKEN",
    max_tokens=256,
    context_window=4096,
    model="step-1v-8k",
)
```

## Chat Functionality

StepFun supports chat APIs, allowing you to handle conversation-like interactions. Hereâ€™s how to use it:

```python
from llama_index.llms.stepfun import StepFun
from llama_index.core.llms import ChatMessage

llm = StepFun(
    api_key="",
    max_tokens=256,
    context_window=4096,
    model="step-1v-8k",
)


message = ChatMessage(role="user", content="Tell me a joke")
resp = llm.chat([message])
print(resp)
```
