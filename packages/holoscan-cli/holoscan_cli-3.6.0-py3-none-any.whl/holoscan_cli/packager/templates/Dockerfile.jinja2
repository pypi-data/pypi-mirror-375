{#
SPDX-FileCopyrightText: Copyright (c) 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
SPDX-License-Identifier: Apache-2.0

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
#}

ARG GPU_TYPE=dgpu

{% if application_type == 'CppCMake' %}
# Build C++ application in the builder stage
FROM {{ build_image }} AS builder
ENV DEBIAN_FRONTEND=noninteractive

RUN apt-get update && \
    apt-get install -y --no-install-recommends jq

WORKDIR /src
COPY ./app/* /src

RUN mkdir -p /install/.cmake/api/v1/query/ && \
    touch /install/.cmake/api/v1/query/codemodel-v2
RUN cd /src && \
    cmake -S . -DHOLOHUB_DOWNLOAD_DATASETS=OFF {{ cmake_args }} -B /install && \
    cmake --build /install -j && \
    export OUTNAME=$(cat $(find /install/.cmake/api/v1/reply -type f | xargs grep -l "nameOnDisk") | jq -r '.nameOnDisk') && \
    cd /install && \
    if [ "${OUTNAME}" != "{{ command_filename }}" ]; then mv ./${OUTNAME} ./{{ command_filename }}; fi

RUN rm /install/CMakeCache.txt /install/Makefile /install/cmake_install.cmake && \
    rm -r /install/CMakeFiles/ /install/.cmake/
{% endif %}



FROM {{ base_image }} AS base

RUN apt-get update \
    && apt-get install -y --no-install-recommends --no-install-suggests \
        curl \
        jq \
    && rm -rf /var/lib/apt/lists/*

{% if 'torch' in includes %}
# Collect torch dependencies: libtorch, torchvision
FROM base AS torch-dependencies

ARG GPU_TYPE
ARG TORCHVISION_VERSION=0.20.0_24.08
ARG LIBTORCH_VERSION=2.5.0_24.08

# Install openmpi
RUN apt update && \
    apt-get install -y --no-install-recommends --no-install-suggests \
        bzip2 \
        libopenmpi3t64=4.1.6-* \
    && rm -rf /var/lib/apt/lists/*

# Download libtorch
WORKDIR /opt/libtorch/
RUN ARCH={{ target_arch }} && if [ "$ARCH" = "aarch64" ]; then ARCH="aarch64-${GPU_TYPE}"; fi && \
    curl -S  -#  -o libtorch.tgz  -L \
        https://edge.urm.nvidia.com/artifactory/sw-holoscan-thirdparty-generic-local/libtorch/libtorch-${LIBTORCH_VERSION}-${ARCH}.tar.gz
RUN mkdir -p ${LIBTORCH_VERSION} && \
    tar -xf libtorch.tgz -C ${LIBTORCH_VERSION} --strip-components 1 && \
    rm -f libtorch.tgz && \
    find . -type f -name "*Config.cmake" -exec sed -i '/kineto/d' {} +

# Download torchvision
WORKDIR /opt/torchvision/
RUN ARCH={{ target_arch }} && if [ "$ARCH" = "aarch64" ]; then ARCH="aarch64-${GPU_TYPE}"; fi && \
    curl -S -# -o torchvision.tgz -L \
        https://edge.urm.nvidia.com/artifactory/sw-holoscan-thirdparty-generic-local/torchvision/torchvision-${TORCHVISION_VERSION}-${ARCH}.tar.gz
RUN mkdir -p ${TORCHVISION_VERSION}
RUN tar -xf torchvision.tgz -C ${TORCHVISION_VERSION} --strip-components 1 && \
    rm -f torchvision.tgz

# Download HPCX for libucc.so.1
WORKDIR /opt/hpcx
RUN curl -S -# -o hpcx.tbz -L \
    https://www.mellanox.com/downloads/hpc/hpc-x/v2.15/hpcx-v2.15-gcc-inbox-ubuntu22.04-cuda12-gdrcopy2-nccl2.17-{{target_arch}}.tbz && \
    tar -xvjf hpcx.tbz hpcx-v2.15-gcc-inbox-ubuntu22.04-cuda12-gdrcopy2-nccl2.17-{{target_arch}}/ucc/lib/libucc.so.1.0.0 && \
    rm -f hpcx.tbz && \
    find . -name libucc.so.1.0.0 -exec mv -f {} /opt/hpcx/libucc.so.1 \;

# End collect torch dependencies
{% endif %}


{% if 'onnx' in includes %}
# Collect onnx dependencies
FROM base AS onnx-dependencies
ARG GPU_TYPE
ARG ONNX_RUNTIME_VERSION=1.18.1_38712740_24.08-cuda-12.6

WORKDIR /opt/onnxruntime

# Download onnx binaries
RUN curl -S -L -# -o ort.tar.gz \
    https://edge.urm.nvidia.com/artifactory/sw-holoscan-thirdparty-generic-local/onnxruntime/onnxruntime-${ONNX_RUNTIME_VERSION}-$(uname -m).tar.gz
RUN mkdir -p ${ONNX_RUNTIME_VERSION}
RUN ls -l && tar -xvzf ort.tar.gz -C ${ONNX_RUNTIME_VERSION} --strip-components 2 && \
    rm -f ort.tar.gz
WORKDIR /
# End collect onnx dependencies
{% endif %}

# FROM base AS mofed-installer
# ARG MOFED_VERSION=23.10-2.1.3.1

# # In a container, we only need to install the user space libraries, though the drivers are still
# # needed on the host.
# # Note: MOFED's installation is not easily portable, so we can't copy the output of this stage
# # to our final stage, but must inherit from it. For that reason, we keep track of the build/install
# # only dependencies in the `MOFED_DEPS` variable (parsing the output of `--check-deps-only`) to
# # remove them in that same layer, to ensure they are not propagated in the final image.
# WORKDIR /opt/nvidia/mofed
# ARG MOFED_INSTALL_FLAGS="--dpdk --with-mft --user-space-only --force --without-fw-update"
# RUN UBUNTU_VERSION=$(cat /etc/lsb-release | grep DISTRIB_RELEASE | cut -d= -f2) \
#     && OFED_PACKAGE="MLNX_OFED_LINUX-${MOFED_VERSION}-ubuntu${UBUNTU_VERSION}-$(uname -m)" \
#     && curl -S -# -o ${OFED_PACKAGE}.tgz -L \
#         https://www.mellanox.com/downloads/ofed/MLNX_OFED-${MOFED_VERSION}/${OFED_PACKAGE}.tgz \
#     && tar xf ${OFED_PACKAGE}.tgz \
#     && MOFED_INSTALLER=$(find . -name mlnxofedinstall -type f -executable -print) \
#     && MOFED_DEPS=$(${MOFED_INSTALLER} ${MOFED_INSTALL_FLAGS} --check-deps-only 2>/dev/null | tail -n1 |  cut -d' ' -f3-) \
#     && apt-get update \
#     && apt-get install --no-install-recommends -y ${MOFED_DEPS} \
#     && ${MOFED_INSTALLER} ${MOFED_INSTALL_FLAGS} \
#     && rm -r * \
#     && apt-get remove -y ${MOFED_DEPS} && apt-get autoremove -y \
#     && rm -rf /var/lib/apt/lists/*

FROM base AS release
ENV DEBIAN_FRONTEND=noninteractive
ENV TERM=xterm-256color

ARG GPU_TYPE
ARG UNAME
ARG UID
ARG GID

RUN mkdir -p /etc/holoscan/ \
        && mkdir -p /opt/holoscan/ \
        && mkdir -p {{ working_dir }} \
        && mkdir -p {{ app_dir }} \
        && mkdir -p {{ full_input_path }} \
        && mkdir -p {{ full_output_path }}

LABEL base="{{ base_image }}"
LABEL tag="{{ tag }}"
LABEL org.opencontainers.image.title="{{ title }}"
LABEL org.opencontainers.image.version="{{ version }}"
LABEL org.nvidia.holoscan="{{ holoscan_sdk_version }}"

{% if sdk_type == 'monai-deploy' %}
LABEL org.monai.deploy.app-sdk="{{ monai_deploy_app_sdk_version }}"
{% endif %}

ENV HOLOSCAN_INPUT_PATH={{ full_input_path }}
ENV HOLOSCAN_OUTPUT_PATH={{ full_output_path }}
ENV HOLOSCAN_WORKDIR={{ working_dir }}
ENV HOLOSCAN_APPLICATION={{ app_dir }}
ENV HOLOSCAN_TIMEOUT={{ timeout }}
ENV HOLOSCAN_MODEL_PATH={{ models_dir }}
ENV HOLOSCAN_DOCS_PATH={{ docs_dir }}
ENV HOLOSCAN_CONFIG_PATH={{ config_file_path }}
ENV HOLOSCAN_APP_MANIFEST_PATH={{ app_json }}
ENV HOLOSCAN_PKG_MANIFEST_PATH={{ pkg_json }}
ENV HOLOSCAN_LOGS_PATH={{ logs_dir }}
ENV HOLOSCAN_VERSION={{ holoscan_sdk_version }}

{% if 'debug' in includes %}
# Install debugging tools
RUN apt-get update \
    && apt-get install -y --no-install-recommends --no-install-suggests  \
        build-essential \
        ccache \
        gdb \
        strace \
        sudo \
    && rm -rf /var/lib/apt/lists/*
### End install debugging tools
{% endif %}


{% if 'holoviz' in includes %}
# Install Holoviz dependencies
RUN apt-get update \
    && apt-get install --no-install-recommends --no-install-suggests --allow-downgrades --allow-change-held-packages -y \
    libvulkan1="1.3.275.0-*" \
    # X11 support \
    libgl1="1.7.0-*" \
    # Wayland support \
    libwayland-client0="1.22.0-*" \
    libwayland-egl1="1.22.0-*" \
    libxkbcommon0="1.6.0-*"  \
    libdecor-0-plugin-1-cairo="0.2.2-*" \
    libegl1="1.7.0-*" \
    && rm -rf /var/lib/apt/lists/*
# End install Holoviz dependencies
{% endif %}


{% if 'torch' in includes %}
# Install torch dependencies
ENV PYTHON_VERSION=3.12.3-*
ENV PYTHON_PIP_VERSION=24.0+dfsg-*

RUN apt update \
&& apt-get install -y --no-install-recommends --no-install-suggests \
        python3-minimal=${PYTHON_VERSION} \
        libpython3-stdlib=${PYTHON_VERSION} \
        python3=${PYTHON_VERSION} \
        python3-venv=${PYTHON_VERSION} \
        python3-pip=${PYTHON_PIP_VERSION} \
        libjpeg-turbo8="2.1.5-*" \
        libnuma1="2.0.18-*" \
        libhwloc15="2.10.0-*" \
        libopenblas0="0.3.26+ds-*" \
        libevent-core-2.1-7 \
        libevent-pthreads-2.1-7 \
        cuda-cupti-12-8 \
        libcudnn9-cuda-12 \
    && rm -rf /var/lib/apt/lists/*

# Install NVIDIA Performance Libraries on arm64 dGPU platform
# as a runtime requirement for the Holoinfer `libtorch` backend (2.5.0).
{% if target_arch == "aarch64" and gpu_type == "dgpu" %}
RUN curl -L https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa/cuda-keyring_1.1-1_all.deb -O \
    && dpkg -i cuda-keyring_1.1-1_all.deb \
    && apt-get update \
    && apt-get install --no-install-recommends -y \
        nvpl-blas=0.2.0.1-* \
        nvpl-lapack=0.2.2.1-* \
    && rm -rf /var/lib/apt/lists/*
ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/sbsa-linux-gnu/
{% endif %}

#  mkl - dependency for libtorch plugin on x86_64 (match pytorch container version)
RUN if [ "{{ cuda_deb_arch }}" = "x86_64" ]; then \
        rm -rf /usr/lib/python3.12/EXTERNALLY-MANAGED \
        && python3 -m pip install --no-cache-dir \
            mkl==2021.1.1 \
        && \
        # Clean up duplicate libraries from mkl/tbb python wheel install which makes copies for symlinks.
        # Only keep the *.so.X libs, remove the *.so and *.so.X.Y libs
        # This can be removed once upgrading to an MKL pip wheel that fixes the symlinks
        find /usr/local/lib -maxdepth 1 -type f -regex '.*\/lib\(tbb\|mkl\).*\.so\(\.[0-9]+\.[0-9]+\)?' -exec rm -v {} +; \
    fi

# Copy Libtorch
ARG LIBTORCH_VERSION=2.5.0_24.08
ENV LIBTORCH=/opt/libtorch/${LIBTORCH_VERSION}/lib
COPY --from=torch-dependencies ${LIBTORCH} ${LIBTORCH}

# Copy TorchVision
ARG TORCHVISION_VERSION=0.20.0_24.08
ENV TORCHVISION=/opt/torchvision/${TORCHVISION_VERSION}/lib
COPY --from=torch-dependencies ${TORCHVISION} ${TORCHVISION}

ENV HPCX=/opt/hpcx/lib
COPY --from=torch-dependencies /opt/hpcx/libucc.so.1 ${LIBTORCH}/libucc.so.1
COPY --from=torch-dependencies /usr/lib/{{target_arch}}-linux-gnu/libmpi.so.40 ${LIBTORCH}/libmpi.so.40
COPY --from=torch-dependencies /usr/lib/{{target_arch}}-linux-gnu/libopen-rte.so.40 ${LIBTORCH}/libopen-rte.so.40
COPY --from=torch-dependencies /usr/lib/{{target_arch}}-linux-gnu/libopen-pal.so.40 ${LIBTORCH}/libopen-pal.so.40

ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:${LIBTORCH}:${TORCHVISION}:${HPCX}
WORKDIR /
### End install torch dependencies
{% endif %}


{% if 'onnx' in includes %}
# Install onnx dependencies
ARG ONNX_RUNTIME_VERSION=1.18.1_38712740_24.08-cuda-12.6
ENV ONNX_RUNTIME=/opt/onnxruntime/${ONNX_RUNTIME_VERSION}/lib
ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:${ONNX_RUNTIME}

# Copy ONNX Runtime
COPY --from=onnx-dependencies ${ONNX_RUNTIME} ${ONNX_RUNTIME}

{% if gpu_type == "dgpu" %}
RUN apt-get update \
    && apt-get install --no-install-recommends --no-install-suggests --allow-downgrades -y \
        libnvinfer10="10.9.0.34-1+cuda12.8" \
        libnvinfer-plugin10="10.9.0.34-1+cuda12.8" \
        libnvonnxparsers10="10.9.0.34-1+cuda12.8" \
        libcusparselt0="0.7.1.0-*" \
        libcudnn9-cuda-12  \
    && rm -rf /var/lib/apt/lists/* \
    && rm -f /usr/lib/*/libcudnn*train.so*
{% endif %}
### End install onnx dependencies
{% endif %}

{% if health_probe is defined %}
# Install gRPC health probe
RUN curl -L -o /bin/grpc_health_probe {{ health_probe | pprint }} \
    && chmod +x /bin/grpc_health_probe && ls -l /bin/grpc_health_probe

HEALTHCHECK --interval=10s --timeout=1s \
    CMD /bin/grpc_health_probe -addr=:8765 || exit 1

# End install gRPC health probe
{% endif %}

{% if application_type == 'PythonModule' or application_type == 'PythonFile' %}
{% if not 'torch' in includes %}
# If torch is installed, we can skip installing Python
ENV PYTHON_VERSION=3.12.3-*
ENV PYTHON_PIP_VERSION=24.0+dfsg-*

RUN apt update \
    && apt-get install -y --no-install-recommends --no-install-suggests \
        python3-minimal=${PYTHON_VERSION} \
        libpython3-stdlib=${PYTHON_VERSION} \
        python3=${PYTHON_VERSION} \
        python3-venv=${PYTHON_VERSION} \
        python3-pip=${PYTHON_PIP_VERSION} \
    && rm -rf /var/lib/apt/lists/*
{% endif %}

{% if holoscan_deb_arch == "arm64" %}
# Requires python3-dev on aarch64
RUN apt update \
    && apt-get install -y --no-install-recommends --no-install-suggests \
        gcc \
        python3-dev \
    && rm -rf /var/lib/apt/lists/*
{% endif %}

{% endif %}

{% if application_type == 'CppCMake' or application_type == 'Binary' %}

ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/nvidia/holoscan/lib

# Update NV GPG repo key
# https://developer.nvidia.com/blog/updating-the-cuda-linux-gpg-repository-key/
RUN curl -OL https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/{{ cuda_deb_arch }}/cuda-keyring_1.1-1_all.deb \
    && dpkg -i cuda-keyring_1.1-1_all.deb \
    && rm -f cuda-keyring_1.1-1_all.deb \
    && apt-get update

RUN if [ "{{ holoscan_deb_arch }}" = "arm64" ]; then \
        GDR_REPO_ARCH=aarch64 ; \
    else \
        GDR_REPO_ARCH=x64 ; \
    fi \
    && curl -O https://developer.download.nvidia.com/compute/redist/gdrcopy/CUDA%2012.2/ubuntu22_04/${GDR_REPO_ARCH}/libgdrapi_2.4-1_{{ holoscan_deb_arch }}.Ubuntu22_04.deb \
    && dpkg -i libgdrapi_2.4-1_{{ holoscan_deb_arch }}.Ubuntu22_04.deb \
    && rm -f libgdrapi_2.4-1_{{ holoscan_deb_arch }}.Ubuntu22_04.deb

{% if custom_holoscan_sdk == True %}

# Use user-specified Holoscan SDK Debian Package
COPY ./{{ holoscan_sdk_filename }} /tmp/{{ holoscan_sdk_filename }}
RUN apt-get install -y --no-install-recommends --no-install-suggests \
        /tmp/{{ holoscan_sdk_filename }} \
    && rm -rf /var/lib/apt/lists/*

{% else %}

# Install Holoscan SDK from NVIDIA APT repository
# Holoscan: available versions (https://pypi.org/project/holoscan/#history)
RUN apt-get install -y --no-install-recommends --no-install-suggests \
        holoscan={{ holoscan_sdk_filename }} \
    # && apt-get remove -y g++ g++-11 gcc gcc-11 gcc-11-base build-essential \
    && apt-get purge -y cuda-keyring \
    && rm -rf /var/lib/apt/lists/*

{% endif %}

{% endif %}


{% if holoscan_deb_arch == "arm64" %}
# Requires libnuma on aarch64
RUN apt update \
    && apt-get install -y --no-install-recommends --no-install-suggests \
        libnuma1="2.0.18-*" \
    && rm -rf /var/lib/apt/lists/*
{% endif %}

RUN if id "ubuntu" >/dev/null 2>&1; then touch /var/mail/ubuntu && chown ubuntu /var/mail/ubuntu && userdel -r ubuntu; fi
RUN groupadd -f -g $GID $UNAME
RUN useradd -rm -d /home/$UNAME -s /bin/bash -g $GID -G sudo -u $UID $UNAME
RUN chown -R holoscan {{ working_dir }} && \
    chown -R holoscan {{ full_input_path }} && \
    chown -R holoscan {{ full_output_path }}

# Set the working directory
WORKDIR {{ working_dir }}

# Copy HAP/MAP tool script
COPY ./tools {{ working_dir }}/tools
RUN chmod +x {{ working_dir }}/tools

# Remove EXTERNALLY-MANAGED directory
RUN rm -rf /usr/lib/python3.12/EXTERNALLY-MANAGED

# Set the working directory
WORKDIR {{ working_dir }}

USER $UNAME

ENV PATH=/home/${UNAME}/.local/bin:/opt/nvidia/holoscan/bin:$PATH
ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/${UNAME}/.local/lib/python3.10/site-packages/holoscan/lib

{% if application_type == 'PythonModule' or application_type == 'PythonFile' %}
COPY ./pip/requirements.txt /tmp/requirements.txt

RUN pip install --upgrade pip
RUN pip install --no-cache-dir --user -r /tmp/requirements.txt

{% if sdk_type == 'holoscan' %}
# Install Holoscan SDK

{% if custom_holoscan_sdk == True %}
# Copy user-specified Holoscan SDK wheel file
COPY ./{{ holoscan_sdk_filename }} /tmp/{{ holoscan_sdk_filename }}
RUN pip install /tmp/{{ holoscan_sdk_filename }}

{% else %}
# Install Holoscan SDK wheel from PyPI
RUN pip install holoscan=={{holoscan_sdk_filename}}
{% endif %}
{% else %}

# Install MONAI Deploy App SDK
{% if custom_monai_deploy_sdk == True %}
# Copy user-specified MONAI Deploy SDK file
COPY ./{{ monai_deploy_sdk_filename }} /tmp/{{ monai_deploy_sdk_filename }}
RUN pip install /tmp/{{ monai_deploy_sdk_filename }}
{% else %}

# Install MONAI Deploy from PyPI org
RUN pip install monai-deploy-app-sdk=={{ monai_deploy_app_sdk_version }}

{% endif %}
{% endif %}
{% endif %}

{% if models is defined %}
COPY ./models  {{ models_dir }}
{% endif %}

{% if docs is defined %}
COPY ./docs  {{ docs_dir }}
{% endif %}

COPY ./map/app.json {{ app_json }}
COPY ./app.config {{ config_file_path }}
COPY ./map/pkg.json {{ pkg_json }}

{% if application_type == 'CppCMake' %}
COPY --from=builder /install {{ app_dir }}
{% else %}
COPY ./app {{ app_dir }}
{% endif %}

{% if additional_lib_paths != '' %}

ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:{{ additional_lib_paths }}:{{ lib_dir }}
COPY ./lib {{ lib_dir }}

{% if application_type == 'PythonModule' or application_type == 'PythonFile' %}
ENV PYTHONPATH=$PYTHONPATH:{{ additional_lib_paths }}:{{ lib_dir }}
{% endif %}

{% endif %}

{% if input_data != None %}
COPY ./input $HOLOSCAN_INPUT_PATH
{% endif %}

ENTRYPOINT ["/var/holoscan/tools"]
