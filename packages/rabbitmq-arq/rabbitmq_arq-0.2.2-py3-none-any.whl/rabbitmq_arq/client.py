# -*- coding: utf-8 -*-
# @version        : 1.0
# @Create Time    : 2025/5/9 20:00
# @File           : client
# @IDE            : PyCharm
# @desc           : RabbitMQ å®¢æˆ·ç«¯ï¼Œç”¨äºæäº¤ä»»åŠ¡

from __future__ import annotations

import json
import logging
import uuid
from datetime import datetime, timedelta, timezone
from typing import Any

from aio_pika import connect_robust, Message, RobustConnection, Channel

from .connections import RabbitMQSettings
from .exceptions import SerializationError, RabbitMQConnectionError
from .job import Job
from .models import JobModel, JobStatus
from .result_storage.models import JobResult

# è·å–æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger('rabbitmq-arq.client')


class RabbitMQClient:
    """
    RabbitMQ å®¢æˆ·ç«¯ï¼Œç”¨äºæäº¤ä»»åŠ¡åˆ°é˜Ÿåˆ—
    
    æ”¯æŒå•ä¸ªå’Œæ‰¹é‡ä»»åŠ¡æäº¤ï¼Œå»¶è¿Ÿæ‰§è¡Œï¼Œä»¥åŠä»»åŠ¡ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€‚
    ä½¿ç”¨ Python 3.12 ç°ä»£ç±»å‹æ³¨è§£ã€‚
    
    æ¯ä¸ªé˜Ÿåˆ—æ”¯æŒç‹¬ç«‹çš„å»¶è¿Ÿæœºåˆ¶æ£€æµ‹å’Œé…ç½®ã€‚
    """

    def __init__(
            self,
            rabbitmq_settings: RabbitMQSettings | None = None,
            result_store_url: str = "redis://localhost:6379/0"
    ) -> None:
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯
        
        Args:
            rabbitmq_settings: RabbitMQ è¿æ¥é…ç½®ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
            result_store_url: ç»“æœå­˜å‚¨URLï¼Œé€šè¿‡URLè‡ªåŠ¨è¯†åˆ«å­˜å‚¨ç±»å‹
        """
        self.rabbitmq_settings = rabbitmq_settings or RabbitMQSettings()
        self.connection: RobustConnection | None = None
        self.channel: Channel | None = None

        # æŒ‰é˜Ÿåˆ—å­˜å‚¨å»¶è¿Ÿæœºåˆ¶ä¿¡æ¯å’Œé˜Ÿåˆ—çŠ¶æ€
        self._delay_mechanisms: dict[str, dict] = {}
        self._declared_queues: set[str] = set()  # å·²å£°æ˜çš„é˜Ÿåˆ—ç¼“å­˜

        # ç»“æœå­˜å‚¨é…ç½®
        self.result_store_url = result_store_url
        self.result_store = None
        self._init_result_store()

    def _init_result_store(self) -> None:
        """åˆå§‹åŒ–ç»“æœå­˜å‚¨"""
        try:
            from .result_storage.factory import create_result_store_from_settings

            self.result_store = create_result_store_from_settings(
                store_url=self.result_store_url,
                enabled=True  # Client ç«¯é»˜è®¤å¯ç”¨æŸ¥è¯¢
            )

            if self.result_store:
                from .result_storage.url_parser import parse_store_type_from_url
                store_type = parse_store_type_from_url(self.result_store_url)
                logger.info(f"å®¢æˆ·ç«¯ç»“æœå­˜å‚¨å·²åˆå§‹åŒ–: {store_type} ({self.result_store_url})")

        except Exception as e:
            logger.warning(f"åˆå§‹åŒ–å®¢æˆ·ç«¯ç»“æœå­˜å‚¨å¤±è´¥: {e}")
            logger.info("å°†æ— æ³•æŸ¥è¯¢ä»»åŠ¡ç»“æœ")

    async def connect(self):
        """
        è¿æ¥åˆ° RabbitMQï¼ˆä¸è¿›è¡Œé˜Ÿåˆ—æ“ä½œï¼‰
        
        Raises:
            RabbitMQConnectionError: è¿æ¥å¤±è´¥æ—¶æŠ›å‡º
        """
        if not self.connection or self.connection.is_closed:
            logger.info("ğŸ”— æ­£åœ¨è¿æ¥åˆ° RabbitMQ...")
            try:
                self.connection = await connect_robust(self.rabbitmq_settings.rabbitmq_url)
                self.channel = await self.connection.channel()
                logger.info("âœ… æˆåŠŸè¿æ¥åˆ° RabbitMQ")
            except Exception as e:
                logger.error(f"âŒ RabbitMQ è¿æ¥å¤±è´¥: {e}")
                raise RabbitMQConnectionError(f"è¿æ¥å¤±è´¥: {e}", self.rabbitmq_settings.rabbitmq_url)

    async def _ensure_queue(self, queue_name: str) -> None:
        """
        ç¡®ä¿é˜Ÿåˆ—å·²å£°æ˜ï¼ˆå¸¦ç¼“å­˜ï¼‰
        
        Args:
            queue_name: é˜Ÿåˆ—åç§°
        """
        if queue_name not in self._declared_queues:
            await self.channel.declare_queue(queue_name, durable=True)
            self._declared_queues.add(queue_name)
            logger.info(f"ğŸ“¦ é˜Ÿåˆ—å·²å£°æ˜: {queue_name}")

    async def _detect_delay_mechanism_for_queue(self, queue_name: str) -> None:
        """
        ä¸ºæŒ‡å®šé˜Ÿåˆ—æ£€æµ‹å¹¶è®¾ç½®å»¶è¿Ÿæœºåˆ¶ï¼šä¼˜å…ˆä½¿ç”¨å»¶è¿Ÿæ’ä»¶ï¼Œå…¶æ¬¡ä½¿ç”¨ TTL + DLX
        
        Args:
            queue_name: é˜Ÿåˆ—åç§°
        """
        if queue_name in self._delay_mechanisms:
            return  # å·²æ£€æµ‹è¿‡

        logger.info(f"ğŸ” æ­£åœ¨ä¸ºé˜Ÿåˆ— {queue_name} æ£€æµ‹å»¶è¿Ÿæœºåˆ¶...")

        # å®šä¹‰å»¶è¿Ÿç›¸å…³çš„åç§°
        delayed_exchange_name = f"delayed.{queue_name}"
        delay_queue_name = f"delay.{queue_name}"

        try:
            # å°è¯•å£°æ˜å»¶è¿Ÿäº¤æ¢æœºï¼ˆéœ€è¦ rabbitmq_delayed_message_exchange æ’ä»¶ï¼‰
            delayed_exchange = await self.channel.declare_exchange(
                delayed_exchange_name,
                type='x-delayed-message',  # ç‰¹æ®Šçš„å»¶è¿Ÿæ¶ˆæ¯ç±»å‹
                durable=True,
                arguments={
                    'x-delayed-type': 'direct'  # å®é™…çš„è·¯ç”±ç±»å‹
                }
            )

            # ç¡®ä¿ç›®æ ‡é˜Ÿåˆ—å­˜åœ¨å¹¶ç»‘å®šå»¶è¿Ÿäº¤æ¢æœº
            await self._ensure_queue(queue_name)
            queue = await self.channel.get_queue(queue_name)
            await queue.bind(delayed_exchange, routing_key=queue_name)

            # è®°å½•æˆåŠŸä½¿ç”¨å»¶è¿Ÿæ’ä»¶
            self._delay_mechanisms[queue_name] = {
                "use_delayed_exchange": True,
                "delayed_exchange_name": delayed_exchange_name,
                "delay_queue_name": delay_queue_name,
                "detected": True
            }
            logger.info(f"âœ… é˜Ÿåˆ— {queue_name} æ£€æµ‹åˆ° RabbitMQ å»¶è¿Ÿæ’ä»¶ï¼Œä½¿ç”¨å»¶è¿Ÿäº¤æ¢æœºæ¨¡å¼")

        except Exception as e:
            # æ’ä»¶æœªå®‰è£…æˆ–å£°æ˜å¤±è´¥ï¼Œé™çº§åˆ° TTL + DLX æ–¹æ¡ˆ
            logger.warning(f"âš ï¸ é˜Ÿåˆ— {queue_name} æœªæ£€æµ‹åˆ° RabbitMQ å»¶è¿Ÿæ’ä»¶: {e}")
            logger.info(f"ğŸ“Œ é˜Ÿåˆ— {queue_name} é™çº§ä½¿ç”¨ TTL + Dead Letter Exchange æ–¹æ¡ˆ")

            try:
                # ç¡®ä¿ç›®æ ‡é˜Ÿåˆ—å­˜åœ¨
                await self._ensure_queue(queue_name)

                # å£°æ˜ TTL å»¶è¿Ÿé˜Ÿåˆ—
                await self.channel.declare_queue(
                    delay_queue_name,
                    durable=True,
                    arguments={
                        'x-dead-letter-exchange': '',  # é»˜è®¤äº¤æ¢æœº
                        'x-dead-letter-routing-key': queue_name  # è·¯ç”±åˆ°ä¸»é˜Ÿåˆ—
                    }
                )

                # è®°å½•ä½¿ç”¨ TTL + DLX æ–¹æ¡ˆ
                self._delay_mechanisms[queue_name] = {
                    "use_delayed_exchange": False,
                    "delayed_exchange_name": delayed_exchange_name,
                    "delay_queue_name": delay_queue_name,
                    "detected": True
                }

            except Exception as dlx_error:
                logger.error(f"âŒ é˜Ÿåˆ— {queue_name} TTL + DLX æ–¹æ¡ˆé…ç½®å¤±è´¥: {dlx_error}")
                raise RabbitMQConnectionError(
                    f"å»¶è¿Ÿæœºåˆ¶é…ç½®å¤±è´¥ï¼Œå»¶è¿Ÿæ’ä»¶å’Œ TTL + DLX æ–¹æ¡ˆå‡ä¸å¯ç”¨: {dlx_error}",
                    self.rabbitmq_settings.rabbitmq_url
                )

    async def get_job_result(self, job_id: str):
        """è·å–å•ä¸ªä»»åŠ¡ç»“æœ
        
        Args:
            job_id: ä»»åŠ¡ID
            
        Returns:
            JobResult å¯¹è±¡ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
            
        Raises:
            ValueError: ç»“æœå­˜å‚¨æœªåˆå§‹åŒ–
        """
        if not self.result_store:
            raise ValueError("ç»“æœå­˜å‚¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•æŸ¥è¯¢ä»»åŠ¡ç»“æœ")

        return await self.result_store.get_result(job_id)

    async def get_job_results(self, job_ids: list[str]) -> dict[str, Any]:
        """æ‰¹é‡è·å–ä»»åŠ¡ç»“æœ
        
        Args:
            job_ids: ä»»åŠ¡IDåˆ—è¡¨
            
        Returns:
            ä»»åŠ¡IDåˆ°ç»“æœçš„æ˜ å°„å­—å…¸
            
        Raises:
            ValueError: ç»“æœå­˜å‚¨æœªåˆå§‹åŒ–
        """
        if not self.result_store:
            raise ValueError("ç»“æœå­˜å‚¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•æŸ¥è¯¢ä»»åŠ¡ç»“æœ")

        return await self.result_store.get_results(job_ids)

    async def get_job_status(self, job_id: str):
        """è·å–ä»»åŠ¡çŠ¶æ€
        
        Args:
            job_id: ä»»åŠ¡ID
            
        Returns:
            JobStatus æšä¸¾å€¼ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
            
        Raises:
            ValueError: ç»“æœå­˜å‚¨æœªåˆå§‹åŒ–
        """
        if not self.result_store:
            raise ValueError("ç»“æœå­˜å‚¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€")

        return await self.result_store.get_status(job_id)

    async def delete_job_result(self, job_id: str) -> bool:
        """åˆ é™¤ä»»åŠ¡ç»“æœ
        
        Args:
            job_id: ä»»åŠ¡ID
            
        Returns:
            åˆ é™¤æˆåŠŸè¿”å› Trueï¼Œç»“æœä¸å­˜åœ¨è¿”å› False
            
        Raises:
            ValueError: ç»“æœå­˜å‚¨æœªåˆå§‹åŒ–
        """
        if not self.result_store:
            raise ValueError("ç»“æœå­˜å‚¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•åˆ é™¤ä»»åŠ¡ç»“æœ")

        return await self.result_store.delete_result(job_id)

    async def get_storage_stats(self) -> dict[str, Any]:
        """è·å–å­˜å‚¨ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
            
        Raises:
            ValueError: ç»“æœå­˜å‚¨æœªåˆå§‹åŒ–
        """
        if not self.result_store:
            raise ValueError("ç»“æœå­˜å‚¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•è·å–ç»Ÿè®¡ä¿¡æ¯")

        return await self.result_store.get_stats()

    def get_job(self, job_id: str) -> Job:
        """
        è·å–Jobå¯¹è±¡ - ARQé£æ ¼API
        
        Args:
            job_id: ä»»åŠ¡ID
            
        Returns:
            Jobå¯¹è±¡ï¼Œç”¨äºæŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å’Œç»“æœ
            
        Example:
            ```python
            # è·å–ä»»åŠ¡å¯¹è±¡
            job = client.get_job('job_id_123')
            
            # æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
            status = await job.status()
            
            # è·å–ä»»åŠ¡ç»“æœ
            result = await job.result()
            
            # è·å–ä»»åŠ¡å®Œæ•´ä¿¡æ¯
            info = await job.info()
            ```
        """
        return Job(job_id=job_id, result_store=self.result_store)

    async def close(self):
        """
        å…³é—­è¿æ¥
        """
        # å…³é—­ç»“æœå­˜å‚¨è¿æ¥
        if self.result_store:
            try:
                await self.result_store.close()
                logger.info("âœ… å®¢æˆ·ç«¯ç»“æœå­˜å‚¨è¿æ¥å·²å…³é—­")
            except Exception as e:
                logger.warning(f"âš ï¸ å…³é—­å®¢æˆ·ç«¯ç»“æœå­˜å‚¨æ—¶å‡ºé”™: {e}")

        if self.connection and not self.connection.is_closed:
            try:
                await self.connection.close()
                logger.info("ğŸ”Œ RabbitMQ è¿æ¥å·²å…³é—­")
            except Exception as e:
                logger.warning(f"âš ï¸ å…³é—­ RabbitMQ è¿æ¥æ—¶å‡ºç°é”™è¯¯: {e}")
            finally:
                self.connection = None
                self.channel = None

    async def enqueue_job(
            self,
            function: str,
            *args,
            queue_name: str,  # ç°åœ¨æˆä¸ºå¿…éœ€å‚æ•°
            _job_id: str | None = None,
            _defer_until: datetime | None = None,
            _defer_by: int | float | timedelta | None = None,
            _expires: int | float | timedelta | None = None,
            _job_try: int | None = None,
            **kwargs
    ) -> Job:
        """
        æäº¤ä»»åŠ¡åˆ°é˜Ÿåˆ—
        
        Args:
            function: è¦æ‰§è¡Œçš„å‡½æ•°å
            *args: ä½ç½®å‚æ•°
            queue_name: é˜Ÿåˆ—åç§°ï¼ˆå¿…éœ€å‚æ•°ï¼‰
            _job_id: ä»»åŠ¡ IDï¼Œå¦‚æœä¸æä¾›åˆ™è‡ªåŠ¨ç”Ÿæˆ
            _defer_until: å»¶è¿Ÿæ‰§è¡Œåˆ°æŒ‡å®šæ—¶é—´
            _defer_by: å»¶è¿Ÿæ‰§è¡Œçš„æ—¶é—´é—´éš”
            _expires: ä»»åŠ¡è¿‡æœŸæ—¶é—´
            _job_try: ä»»åŠ¡å°è¯•æ¬¡æ•°
            **kwargs: å…³é”®å­—å‚æ•°
            
        Returns:
            JobModel: ä»»åŠ¡å¯¹è±¡
        """
        # ç¡®ä¿è¿æ¥
        await self.connect()

        # ç¡®ä¿é˜Ÿåˆ—å­˜åœ¨
        await self._ensure_queue(queue_name)

        # æŒ‰éœ€æ£€æµ‹å»¶è¿Ÿæœºåˆ¶
        if queue_name not in self._delay_mechanisms:
            await self._detect_delay_mechanism_for_queue(queue_name)

        # ç”Ÿæˆä»»åŠ¡ ID
        job_id = _job_id or uuid.uuid4().hex

        # è®¡ç®—å»¶è¿Ÿæ‰§è¡Œæ—¶é—´
        defer_until = None
        if _defer_until:
            defer_until = _defer_until if _defer_until.tzinfo is not None else _defer_until.replace(tzinfo=timezone.utc)
        elif _defer_by:
            if isinstance(_defer_by, timedelta):
                defer_until = datetime.now(timezone.utc) + _defer_by
            else:
                defer_until = datetime.now(timezone.utc) + timedelta(seconds=float(_defer_by))

        # è®¡ç®—è¿‡æœŸæ—¶é—´
        if _expires:
            if isinstance(_expires, (int, float)):
                expires_time = datetime.now(timezone.utc) + timedelta(seconds=float(_expires))
            elif isinstance(_expires, timedelta):
                expires_time = datetime.now(timezone.utc) + _expires
            else:
                expires_time = _expires
        else:
            # é»˜è®¤ 24 å°æ—¶è¿‡æœŸ
            expires_time = datetime.now(timezone.utc) + timedelta(hours=24)

        # åˆ›å»ºä»»åŠ¡å¯¹è±¡
        job = JobModel(
            job_id=job_id,
            function=function,
            args=list(args),
            kwargs=kwargs,
            job_try=_job_try or 1,
            queue_name=queue_name,
            defer_until=defer_until,
            expires=expires_time,
            status=JobStatus.QUEUED
        )

        # åºåˆ—åŒ–ä»»åŠ¡
        try:
            message_body = json.dumps(job.model_dump(), ensure_ascii=False, default=str).encode()
        except Exception as e:
            raise SerializationError(f"ä»»åŠ¡åºåˆ—åŒ–å¤±è´¥: {e}")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦å»¶è¿Ÿæ‰§è¡Œ
        if defer_until and defer_until > datetime.now(timezone.utc):
            delay_seconds = (defer_until - datetime.now(timezone.utc)).total_seconds()

            # ä¸ºå»¶è¿Ÿä»»åŠ¡æ·»åŠ æ ‡è®°ï¼Œé¿å… Worker é‡å¤å¤„ç†å»¶è¿Ÿ
            headers = {"x-retry-count": 0, "x-client-delayed": "true"}

            # æ¸…é™¤å»¶è¿Ÿæ—¶é—´ï¼Œé¿å… Worker é‡å¤å»¶è¿Ÿ
            job_copy = job.model_copy()
            job_copy.defer_until = None
            delayed_message_body = json.dumps(job_copy.model_dump(), ensure_ascii=False, default=str).encode()

            await self._send_delayed_job(delayed_message_body, queue_name, delay_seconds, headers)
            logger.info(f"ğŸ“¤ å»¶è¿Ÿä»»åŠ¡å·²æäº¤: {job.job_id} (å»¶è¿Ÿ {delay_seconds:.1f} ç§’)")
        else:
            # ç«‹å³æ‰§è¡Œçš„ä»»åŠ¡ï¼Œå‘é€åˆ°æ™®é€šé˜Ÿåˆ—
            await self.channel.default_exchange.publish(
                Message(
                    body=message_body,
                    headers={"x-retry-count": 0}
                ),
                routing_key=queue_name
            )
            logger.info(f"ğŸ“¤ ä»»åŠ¡å·²æäº¤: {job.job_id} -> {queue_name}")

        # ä¸ºæ‰€æœ‰ä»»åŠ¡åˆ›å»ºåˆå§‹çŠ¶æ€è®°å½•ï¼ˆARQé£æ ¼ï¼šä»»åŠ¡æäº¤å³å¯æŸ¥è¯¢ï¼‰
        await self._store_initial_job_state(job)

        # è¿”å›Jobå¯¹è±¡è€Œä¸æ˜¯JobModel
        return Job(job_id=job.job_id, result_store=self.result_store)

    async def _store_initial_job_state(self, job: JobModel) -> None:
        """
        ä¸ºä»»åŠ¡åˆ›å»ºåˆå§‹çŠ¶æ€è®°å½•
        
        Args:
            job: ä»»åŠ¡æ¨¡å‹å¯¹è±¡
        """
        if not self.result_store:
            return

        try:
            # åˆ›å»ºåˆå§‹ä»»åŠ¡ç»“æœè®°å½•ï¼ˆçŠ¶æ€ä¸º QUEUEDï¼‰
            initial_job_result = JobResult(
                job_id=job.job_id,
                status=job.status,  # JobStatus.QUEUED
                result=None,
                error=None,
                start_time=job.enqueue_time,  # ä½¿ç”¨å…¥é˜Ÿæ—¶é—´ä½œä¸ºå¼€å§‹æ—¶é—´
                end_time=None,
                duration=None,
                worker_id="pending",  # æš‚æœªåˆ†é…Worker
                queue_name=job.queue_name,
                retry_count=0,
                function_name=job.function,
                args=job.args,
                kwargs=job.kwargs,
                expires_at=job.expires
            )

            # å¼‚æ­¥å­˜å‚¨åˆå§‹çŠ¶æ€
            await self.result_store.store_result(initial_job_result)
            status_value = job.status.value if hasattr(job.status, 'value') else str(job.status)
            logger.debug(f"âœ… åˆå§‹ä»»åŠ¡çŠ¶æ€å·²å­˜å‚¨: {job.job_id} -> {status_value}")

        except Exception as e:
            logger.warning(f"âš ï¸ å­˜å‚¨åˆå§‹ä»»åŠ¡çŠ¶æ€å¤±è´¥ {job.job_id}: {e}")
            # å­˜å‚¨å¤±è´¥ä¸å½±å“ä»»åŠ¡æäº¤æµç¨‹

    async def _send_delayed_job(self, message_body: bytes, queue_name: str, delay_seconds: float, headers: dict | None = None):
        """
        å‘é€å»¶è¿Ÿä»»åŠ¡ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä½³å»¶è¿Ÿæœºåˆ¶
        
        Args:
            message_body: æ¶ˆæ¯ä½“
            queue_name: ç›®æ ‡é˜Ÿåˆ—å
            delay_seconds: å»¶è¿Ÿç§’æ•°
            headers: æ¶ˆæ¯å¤´
        """
        if headers is None:
            headers = {"x-retry-count": 0}

        # è·å–é˜Ÿåˆ—çš„å»¶è¿Ÿæœºåˆ¶é…ç½®
        delay_config = self._delay_mechanisms.get(queue_name, {})
        use_delayed_exchange = delay_config.get("use_delayed_exchange", False)

        if use_delayed_exchange:
            # ä½¿ç”¨å»¶è¿Ÿæ’ä»¶ï¼ˆæœ€ä¼˜æ–¹æ¡ˆï¼‰
            delay_ms = int(delay_seconds * 1000)
            headers['x-delay'] = delay_ms

            delayed_exchange_name = delay_config["delayed_exchange_name"]
            delayed_exchange = await self.channel.get_exchange(delayed_exchange_name)
            await delayed_exchange.publish(
                Message(body=message_body, headers=headers),
                routing_key=queue_name
            )
            logger.debug(f"ğŸš€ ä½¿ç”¨å»¶è¿Ÿäº¤æ¢æœºå‘é€ä»»åŠ¡åˆ° {queue_name} (å»¶è¿Ÿ {delay_seconds:.1f} ç§’)")

        else:
            # ä½¿ç”¨ TTL + DLX æ–¹æ¡ˆï¼ˆé™çº§æ–¹æ¡ˆï¼‰
            expiration = timedelta(seconds=delay_seconds)
            delay_queue_name = delay_config["delay_queue_name"]

            # å‘é€åˆ° TTL å»¶è¿Ÿé˜Ÿåˆ—
            await self.channel.default_exchange.publish(
                Message(
                    body=message_body,
                    headers=headers,
                    expiration=expiration
                ),
                routing_key=delay_queue_name
            )
            logger.debug(f"â±ï¸ ä½¿ç”¨ TTL é˜Ÿåˆ—å‘é€ä»»åŠ¡åˆ° {queue_name} (å»¶è¿Ÿ {delay_seconds:.1f} ç§’)")

    async def enqueue_jobs(
            self,
            jobs: list[dict[str, Any]]
    ) -> list[JobModel]:
        """
        æ‰¹é‡æäº¤ä»»åŠ¡
        
        Args:
            jobs: ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªä»»åŠ¡æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«ï¼š
                - function: å‡½æ•°å
                - args: ä½ç½®å‚æ•°åˆ—è¡¨
                - kwargs: å…³é”®å­—å‚æ•°å­—å…¸
                - queue_name: ç›®æ ‡é˜Ÿåˆ—åï¼ˆå¿…éœ€ï¼‰
                - å…¶ä»–å¯é€‰å‚æ•°ï¼ˆ_job_id, _defer_until ç­‰ï¼‰
                
        Returns:
            List[JobModel]: ä»»åŠ¡å¯¹è±¡åˆ—è¡¨
        """
        results = []
        for job_spec in jobs:
            function = job_spec.pop('function')
            queue_name = job_spec.pop('queue_name')  # ç°åœ¨æ˜¯å¿…éœ€çš„
            args = job_spec.pop('args', [])
            kwargs = job_spec.pop('kwargs', {})

            # æå–ç‰¹æ®Šå‚æ•°
            special_params = {}
            for key in list(job_spec.keys()):
                if key.startswith('_'):
                    special_params[key] = job_spec.pop(key)

            # åˆå¹¶å‰©ä½™å‚æ•°åˆ° kwargs
            kwargs.update(job_spec)

            # æäº¤ä»»åŠ¡
            job = await self.enqueue_job(
                function,
                *args,
                queue_name=queue_name,
                **special_params,
                **kwargs
            )
            results.append(job)

        return results

    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        await self.connect()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        await self.close()
