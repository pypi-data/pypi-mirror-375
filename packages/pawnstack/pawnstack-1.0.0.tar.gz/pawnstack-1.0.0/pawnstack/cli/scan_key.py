"""
ScanKey CLI - í‚¤ ìŠ¤ìº” ë° ë³´ì•ˆ ê²€ì‚¬ ë„êµ¬

ë ˆê±°ì‹œ pawnlib scan_key.py ê¸°ëŠ¥ì„ pawnstack ì•„í‚¤í…ì²˜ë¡œ ì´ì‹
"""

import asyncio
import json
import re
import hashlib
import base64
from datetime import datetime
from typing import Dict, List, Optional, Any, Set, Tuple
from argparse import ArgumentParser
from pathlib import Path

from pawnstack.cli.base import AsyncBaseCLI, register_cli_command
from pawnstack.config.global_config import pawn


@register_cli_command(
    name="scan-key",
    description="í‚¤ ìŠ¤ìº” ë° ë³´ì•ˆ ê²€ì‚¬ ë„êµ¬",
    epilog="""
ì˜ˆì œ:
  pawns scan-key --path /home/user --recursive
  pawns scan-key --file config.json --check-patterns
  pawns scan-key --url https://api.example.com --check-exposed
  pawns scan-key --directory /var/log --exclude "*.log" --format json
    """
)
class ScanKeyCLI(AsyncBaseCLI):
    """í‚¤ ìŠ¤ìº” ë° ë³´ì•ˆ ê²€ì‚¬ CLI"""
    
    def __init__(self, args=None):
        super().__init__(args)
        self.scan_results = []
        self.security_issues = []
        self.scanned_files = 0
        self.total_files = 0
        
        # ë¯¼ê°í•œ í‚¤ íŒ¨í„´ ì •ì˜
        self.key_patterns = {
            'aws_access_key': {
                'pattern': r'AKIA[0-9A-Z]{16}',
                'description': 'AWS Access Key ID',
                'severity': 'high'
            },
            'aws_secret_key': {
                'pattern': r'[A-Za-z0-9/+=]{40}',
                'description': 'AWS Secret Access Key (ì¶”ì •)',
                'severity': 'high',
                'context_required': True
            },
            'github_token': {
                'pattern': r'ghp_[A-Za-z0-9]{36}',
                'description': 'GitHub Personal Access Token',
                'severity': 'high'
            },
            'github_oauth': {
                'pattern': r'gho_[A-Za-z0-9]{36}',
                'description': 'GitHub OAuth Token',
                'severity': 'high'
            },
            'slack_token': {
                'pattern': r'xox[baprs]-[A-Za-z0-9-]+',
                'description': 'Slack Token',
                'severity': 'medium'
            },
            'discord_token': {
                'pattern': r'[MN][A-Za-z\d]{23}\.[\w-]{6}\.[\w-]{27}',
                'description': 'Discord Bot Token',
                'severity': 'medium'
            },
            'jwt_token': {
                'pattern': r'eyJ[A-Za-z0-9_-]*\.eyJ[A-Za-z0-9_-]*\.[A-Za-z0-9_-]*',
                'description': 'JWT Token',
                'severity': 'medium'
            },
            'api_key_generic': {
                'pattern': r'[Aa][Pp][Ii]_?[Kk][Ee][Yy].*[\'"][A-Za-z0-9]{20,}[\'"]',
                'description': 'ì¼ë°˜ API Key',
                'severity': 'medium'
            },
            'private_key': {
                'pattern': r'-----BEGIN [A-Z ]+PRIVATE KEY-----',
                'description': 'Private Key',
                'severity': 'high'
            },
            'password_field': {
                'pattern': r'[Pp][Aa][Ss][Ss][Ww][Oo][Rr][Dd].*[\'"][^\'"\s]{8,}[\'"]',
                'description': 'ë¹„ë°€ë²ˆí˜¸ í•„ë“œ',
                'severity': 'low'
            },
            'database_url': {
                'pattern': r'[a-zA-Z][a-zA-Z0-9+.-]*://[^\s]+:[^\s]+@[^\s]+',
                'description': 'ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° URL',
                'severity': 'high'
            },
            'email_credentials': {
                'pattern': r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}:[^\s]{6,}',
                'description': 'ì´ë©”ì¼ ì¸ì¦ ì •ë³´',
                'severity': 'medium'
            }
        }
        
        # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒŒì¼ í™•ì¥ì
        self.suspicious_extensions = {
            '.key', '.pem', '.p12', '.pfx', '.jks', '.keystore',
            '.crt', '.cer', '.der', '.csr', '.p7b', '.p7c'
        }
        
        # ì œì™¸í•  ë””ë ‰í† ë¦¬
        self.default_exclude_dirs = {
            '.git', '.svn', '.hg', '__pycache__', 'node_modules',
            '.venv', 'venv', '.env', 'build', 'dist', '.cache'
        }
    
    def get_arguments(self, parser: ArgumentParser):
        """ëª…ë ¹ì–´ ì¸ìˆ˜ ì •ì˜"""
        # ìŠ¤ìº” ëŒ€ìƒ
        parser.add_argument(
            '--path', '-p',
            type=str,
            help='ìŠ¤ìº”í•  ê²½ë¡œ (íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬)'
        )
        
        parser.add_argument(
            '--file', '-f',
            type=str,
            action='append',
            help='ìŠ¤ìº”í•  íŒŒì¼ (ì—¬ëŸ¬ ê°œ ì§€ì • ê°€ëŠ¥)'
        )
        
        parser.add_argument(
            '--directory', '-d',
            type=str,
            action='append',
            help='ìŠ¤ìº”í•  ë””ë ‰í† ë¦¬ (ì—¬ëŸ¬ ê°œ ì§€ì • ê°€ëŠ¥)'
        )
        
        parser.add_argument(
            '--url', '-u',
            type=str,
            action='append',
            help='ìŠ¤ìº”í•  URL (ì—¬ëŸ¬ ê°œ ì§€ì • ê°€ëŠ¥)'
        )
        
        # ìŠ¤ìº” ì˜µì…˜
        parser.add_argument(
            '--recursive', '-r',
            action='store_true',
            help='í•˜ìœ„ ë””ë ‰í† ë¦¬ ì¬ê·€ ìŠ¤ìº”'
        )
        
        parser.add_argument(
            '--include',
            type=str,
            action='append',
            help='í¬í•¨í•  íŒŒì¼ íŒ¨í„´ (ì˜ˆ: "*.py", "*.json")'
        )
        
        parser.add_argument(
            '--exclude',
            type=str,
            action='append',
            help='ì œì™¸í•  íŒŒì¼ íŒ¨í„´ (ì˜ˆ: "*.log", "test_*")'
        )
        
        parser.add_argument(
            '--max-size',
            type=int,
            default=10,  # 10MB
            help='ìŠ¤ìº”í•  ìµœëŒ€ íŒŒì¼ í¬ê¸° (MB, default: 10)'
        )
        
        parser.add_argument(
            '--max-depth',
            type=int,
            help='ìµœëŒ€ ë””ë ‰í† ë¦¬ ê¹Šì´'
        )
        
        # ê²€ì‚¬ ì˜µì…˜
        parser.add_argument(
            '--check-patterns',
            action='store_true',
            default=True,
            help='í‚¤ íŒ¨í„´ ê²€ì‚¬ ìˆ˜í–‰ (default: True)'
        )
        
        parser.add_argument(
            '--check-entropy',
            action='store_true',
            help='ë¬¸ìì—´ ì—”íŠ¸ë¡œí”¼ ê²€ì‚¬ ìˆ˜í–‰'
        )
        
        parser.add_argument(
            '--check-base64',
            action='store_true',
            help='Base64 ì¸ì½”ë”©ëœ ë°ì´í„° ê²€ì‚¬'
        )
        
        parser.add_argument(
            '--check-exposed',
            action='store_true',
            help='ê³µê°œëœ í‚¤ ê²€ì‚¬ (URL ëŒ€ìƒ)'
        )
        
        parser.add_argument(
            '--entropy-threshold',
            type=float,
            default=4.5,
            help='ì—”íŠ¸ë¡œí”¼ ì„ê³„ê°’ (default: 4.5)'
        )
        
        parser.add_argument(
            '--min-length',
            type=int,
            default=20,
            help='ê²€ì‚¬í•  ìµœì†Œ ë¬¸ìì—´ ê¸¸ì´ (default: 20)'
        )
        
        # ì‹¬ê°ë„ í•„í„°
        parser.add_argument(
            '--severity',
            choices=['low', 'medium', 'high', 'all'],
            default='all',
            help='í‘œì‹œí•  ìµœì†Œ ì‹¬ê°ë„ (default: all)'
        )
        
        # ì¶œë ¥ ì˜µì…˜
        parser.add_argument(
            '--format',
            choices=['table', 'json', 'csv', 'sarif'],
            default='table',
            help='ì¶œë ¥ í˜•ì‹ (default: table)'
        )
        
        parser.add_argument(
            '--output', '-o',
            type=str,
            help='ê²°ê³¼ ì €ì¥ íŒŒì¼ ê²½ë¡œ'
        )
        

        
        parser.add_argument(
            '--quiet',
            action='store_true',
            help='ì¡°ìš©í•œ ëª¨ë“œ (ìš”ì•½ë§Œ ì¶œë ¥)'
        )
        
        parser.add_argument(
            '--verbose',
            action='store_true',
            help='ìƒì„¸ ì¶œë ¥ ëª¨ë“œ'
        )
        
        # ë³´ì•ˆ ì˜µì…˜
        parser.add_argument(
            '--hash-secrets',
            action='store_true',
            help='ë°œê²¬ëœ ë¹„ë°€ ì •ë³´ë¥¼ í•´ì‹œë¡œ ë§ˆìŠ¤í‚¹'
        )
        
        parser.add_argument(
            '--no-content',
            action='store_true',
            help='íŒŒì¼ ë‚´ìš©ì„ ê²°ê³¼ì— í¬í•¨í•˜ì§€ ì•ŠìŒ'
        )
        
        # ì„¤ì • íŒŒì¼
        parser.add_argument(
            '--config',
            type=str,
            help='ìŠ¤ìº” ì„¤ì • íŒŒì¼ ê²½ë¡œ'
        )
        
        parser.add_argument(
            '--patterns-file',
            type=str,
            help='ì»¤ìŠ¤í…€ íŒ¨í„´ íŒŒì¼ ê²½ë¡œ'
        )
    
    def load_config(self) -> Dict[str, Any]:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        config = {}
        
        if hasattr(self.args, 'config') and self.args.config:
            config_path = Path(self.args.config)
            
            if config_path.exists():
                try:
                    with open(config_path, 'r', encoding='utf-8') as f:
                        if config_path.suffix.lower() == '.json':
                            config = json.load(f)
                        elif config_path.suffix.lower() in ['.yml', '.yaml']:
                            import yaml
                            config = yaml.safe_load(f)
                        else:
                            self.log_warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì„¤ì • íŒŒì¼ í˜•ì‹: {config_path.suffix}")
                    
                    self.log_debug(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {self.args.config}")
                    
                except Exception as e:
                    self.log_error(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        return config
    
    def load_custom_patterns(self) -> Dict[str, Dict[str, Any]]:
        """ì»¤ìŠ¤í…€ íŒ¨í„´ íŒŒì¼ ë¡œë“œ"""
        if not hasattr(self.args, 'patterns_file') or not self.args.patterns_file:
            return {}
        
        patterns_path = Path(self.args.patterns_file)
        
        if not patterns_path.exists():
            self.log_warning(f"íŒ¨í„´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.args.patterns_file}")
            return {}
        
        try:
            with open(patterns_path, 'r', encoding='utf-8') as f:
                if patterns_path.suffix.lower() == '.json':
                    patterns = json.load(f)
                elif patterns_path.suffix.lower() in ['.yml', '.yaml']:
                    import yaml
                    patterns = yaml.safe_load(f)
                else:
                    self.log_warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒ¨í„´ íŒŒì¼ í˜•ì‹: {patterns_path.suffix}")
                    return {}
            
            self.log_debug(f"ì»¤ìŠ¤í…€ íŒ¨í„´ ë¡œë“œ ì™„ë£Œ: {len(patterns)}ê°œ")
            return patterns
            
        except Exception as e:
            self.log_error(f"íŒ¨í„´ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}
    
    def should_scan_file(self, file_path: Path) -> bool:
        """íŒŒì¼ ìŠ¤ìº” ì—¬ë¶€ ê²°ì •"""
        # íŒŒì¼ í¬ê¸° ê²€ì‚¬
        try:
            file_size_mb = file_path.stat().st_size / (1024 * 1024)
            if file_size_mb > self.args.max_size:
                self.log_debug(f"íŒŒì¼ í¬ê¸° ì´ˆê³¼ë¡œ ìŠ¤í‚µ: {file_path} ({file_size_mb:.1f}MB)")
                return False
        except OSError:
            return False
        
        # í¬í•¨ íŒ¨í„´ ê²€ì‚¬
        if hasattr(self.args, 'include') and self.args.include:
            import fnmatch
            if not any(fnmatch.fnmatch(file_path.name, pattern) for pattern in self.args.include):
                return False
        
        # ì œì™¸ íŒ¨í„´ ê²€ì‚¬
        if hasattr(self.args, 'exclude') and self.args.exclude:
            import fnmatch
            if any(fnmatch.fnmatch(file_path.name, pattern) for pattern in self.args.exclude):
                return False
        
        # ë°”ì´ë„ˆë¦¬ íŒŒì¼ ì œì™¸ (ê°„ë‹¨í•œ ê²€ì‚¬)
        try:
            with open(file_path, 'rb') as f:
                chunk = f.read(1024)
                if b'\x00' in chunk:  # NULL ë°”ì´íŠ¸ê°€ ìˆìœ¼ë©´ ë°”ì´ë„ˆë¦¬ë¡œ ê°„ì£¼
                    return False
        except (OSError, PermissionError):
            return False
        
        return True
    
    def calculate_entropy(self, text: str) -> float:
        """ë¬¸ìì—´ ì—”íŠ¸ë¡œí”¼ ê³„ì‚°"""
        if not text:
            return 0.0
        
        # ë¬¸ì ë¹ˆë„ ê³„ì‚°
        char_counts = {}
        for char in text:
            char_counts[char] = char_counts.get(char, 0) + 1
        
        # ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
        entropy = 0.0
        text_length = len(text)
        
        for count in char_counts.values():
            probability = count / text_length
            if probability > 0:
                entropy -= probability * (probability.bit_length() - 1)
        
        return entropy
    
    def is_base64_encoded(self, text: str) -> bool:
        """Base64 ì¸ì½”ë”© ì—¬ë¶€ í™•ì¸"""
        if len(text) < 4 or len(text) % 4 != 0:
            return False
        
        try:
            # Base64 ë””ì½”ë”© ì‹œë„
            decoded = base64.b64decode(text, validate=True)
            # ë””ì½”ë”©ëœ ê²°ê³¼ê°€ ì˜ë¯¸ìˆëŠ” ë°ì´í„°ì¸ì§€ ê°„ë‹¨íˆ í™•ì¸
            return len(decoded) > 0 and not all(b == 0 for b in decoded)
        except Exception:
            return False
    
    def mask_secret(self, secret: str) -> str:
        """ë¹„ë°€ ì •ë³´ ë§ˆìŠ¤í‚¹"""
        if not self.args.hash_secrets:
            # ê°„ë‹¨í•œ ë§ˆìŠ¤í‚¹
            if len(secret) <= 8:
                return '*' * len(secret)
            else:
                return secret[:4] + '*' * (len(secret) - 8) + secret[-4:]
        else:
            # í•´ì‹œ ê¸°ë°˜ ë§ˆìŠ¤í‚¹
            hash_obj = hashlib.sha256(secret.encode('utf-8'))
            return f"[HASH:{hash_obj.hexdigest()[:16]}]"
    
    def scan_text_content(self, content: str, file_path: str) -> List[Dict[str, Any]]:
        """í…ìŠ¤íŠ¸ ë‚´ìš© ìŠ¤ìº”"""
        findings = []
        lines = content.split('\n')
        
        # íŒ¨í„´ ê¸°ë°˜ ê²€ì‚¬
        if self.args.check_patterns:
            all_patterns = self.key_patterns.copy()
            custom_patterns = self.load_custom_patterns()
            all_patterns.update(custom_patterns)
            
            for pattern_name, pattern_info in all_patterns.items():
                pattern = pattern_info['pattern']
                
                for line_num, line in enumerate(lines, 1):
                    matches = re.finditer(pattern, line, re.IGNORECASE)
                    
                    for match in matches:
                        matched_text = match.group(0)
                        
                        # ì»¨í…ìŠ¤íŠ¸ ê²€ì‚¬ê°€ í•„ìš”í•œ ê²½ìš°
                        if pattern_info.get('context_required'):
                            # AWS Secret Key ê°™ì€ ê²½ìš° ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸ í™•ì¸
                            context = line.lower()
                            if not any(keyword in context for keyword in ['secret', 'key', 'password', 'token']):
                                continue
                        
                        finding = {
                            'type': 'pattern',
                            'pattern_name': pattern_name,
                            'description': pattern_info['description'],
                            'severity': pattern_info['severity'],
                            'file_path': file_path,
                            'line_number': line_num,
                            'column': match.start() + 1,
                            'matched_text': self.mask_secret(matched_text) if not self.args.no_content else '[MASKED]',
                            'line_content': line.strip() if not self.args.no_content else '[MASKED]'
                        }
                        
                        findings.append(finding)
        
        # ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ ê²€ì‚¬
        if self.args.check_entropy:
            for line_num, line in enumerate(lines, 1):
                # ë¬¸ìì—´ ë¦¬í„°ëŸ´ ì¶”ì¶œ (ë”°ì˜´í‘œë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ë¶€ë¶„)
                string_patterns = [
                    r'"([^"]{' + str(self.args.min_length) + r',})"',
                    r"'([^']{" + str(self.args.min_length) + r",})'"
                ]
                
                for pattern in string_patterns:
                    matches = re.finditer(pattern, line)
                    
                    for match in matches:
                        text = match.group(1)
                        entropy = self.calculate_entropy(text)
                        
                        if entropy >= self.args.entropy_threshold:
                            finding = {
                                'type': 'entropy',
                                'description': f'ë†’ì€ ì—”íŠ¸ë¡œí”¼ ë¬¸ìì—´ (ì—”íŠ¸ë¡œí”¼: {entropy:.2f})',
                                'severity': 'medium',
                                'file_path': file_path,
                                'line_number': line_num,
                                'column': match.start() + 1,
                                'matched_text': self.mask_secret(text) if not self.args.no_content else '[MASKED]',
                                'entropy': entropy,
                                'line_content': line.strip() if not self.args.no_content else '[MASKED]'
                            }
                            
                            findings.append(finding)
        
        # Base64 ê²€ì‚¬
        if self.args.check_base64:
            base64_pattern = r'[A-Za-z0-9+/]{' + str(self.args.min_length) + r',}={0,2}'
            
            for line_num, line in enumerate(lines, 1):
                matches = re.finditer(base64_pattern, line)
                
                for match in matches:
                    text = match.group(0)
                    
                    if self.is_base64_encoded(text):
                        finding = {
                            'type': 'base64',
                            'description': 'Base64 ì¸ì½”ë”©ëœ ë°ì´í„°',
                            'severity': 'low',
                            'file_path': file_path,
                            'line_number': line_num,
                            'column': match.start() + 1,
                            'matched_text': self.mask_secret(text) if not self.args.no_content else '[MASKED]',
                            'line_content': line.strip() if not self.args.no_content else '[MASKED]'
                        }
                        
                        findings.append(finding)
        
        return findings
    
    async def scan_file(self, file_path: Path) -> List[Dict[str, Any]]:
        """ë‹¨ì¼ íŒŒì¼ ìŠ¤ìº”"""
        findings = []
        
        try:
            # íŒŒì¼ í™•ì¥ì ê²€ì‚¬
            if file_path.suffix.lower() in self.suspicious_extensions:
                finding = {
                    'type': 'suspicious_file',
                    'description': f'ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒŒì¼ í™•ì¥ì: {file_path.suffix}',
                    'severity': 'medium',
                    'file_path': str(file_path),
                    'line_number': 0,
                    'column': 0
                }
                findings.append(finding)
            
            # íŒŒì¼ ë‚´ìš© ì½ê¸°
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            # í…ìŠ¤íŠ¸ ë‚´ìš© ìŠ¤ìº”
            text_findings = self.scan_text_content(content, str(file_path))
            findings.extend(text_findings)
            
            self.scanned_files += 1
            
            if self.args.verbose and findings:
                self.log_info(f"ìŠ¤ìº” ì™„ë£Œ: {file_path} ({len(findings)}ê°œ ë°œê²¬)")
            
        except Exception as e:
            self.log_debug(f"íŒŒì¼ ìŠ¤ìº” ì‹¤íŒ¨: {file_path} - {e}")
        
        return findings
    
    async def scan_directory(self, directory: Path, current_depth: int = 0) -> List[Dict[str, Any]]:
        """ë””ë ‰í† ë¦¬ ìŠ¤ìº”"""
        findings = []
        
        if hasattr(self.args, 'max_depth') and self.args.max_depth and current_depth >= self.args.max_depth:
            return findings
        
        try:
            for item in directory.iterdir():
                if item.is_file():
                    if self.should_scan_file(item):
                        self.total_files += 1
                        file_findings = await self.scan_file(item)
                        findings.extend(file_findings)
                
                elif item.is_dir() and self.args.recursive:
                    # ì œì™¸ ë””ë ‰í† ë¦¬ ê²€ì‚¬
                    if item.name not in self.default_exclude_dirs:
                        dir_findings = await self.scan_directory(item, current_depth + 1)
                        findings.extend(dir_findings)
        
        except PermissionError:
            self.log_debug(f"ë””ë ‰í† ë¦¬ ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ: {directory}")
        except Exception as e:
            self.log_debug(f"ë””ë ‰í† ë¦¬ ìŠ¤ìº” ì‹¤íŒ¨: {directory} - {e}")
        
        return findings
    
    async def scan_url(self, url: str) -> List[Dict[str, Any]]:
        """URL ìŠ¤ìº”"""
        findings = []
        
        if not self.args.check_exposed:
            return findings
        
        try:
            import aiohttp
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=aiohttp.ClientTimeout(total=30)) as response:
                    if response.status == 200:
                        content = await response.text()
                        
                        # URL ë‚´ìš© ìŠ¤ìº”
                        url_findings = self.scan_text_content(content, url)
                        findings.extend(url_findings)
                        
                        # ê³µê°œëœ í‚¤ íŠ¹ë³„ ê²€ì‚¬
                        if any(pattern in content.lower() for pattern in ['key', 'token', 'secret', 'password']):
                            finding = {
                                'type': 'exposed_endpoint',
                                'description': 'ê³µê°œëœ ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ë¯¼ê°í•œ ì •ë³´ ë°œê²¬ ê°€ëŠ¥ì„±',
                                'severity': 'high',
                                'file_path': url,
                                'line_number': 0,
                                'column': 0
                            }
                            findings.append(finding)
                    
                    else:
                        self.log_debug(f"URL ì ‘ê·¼ ì‹¤íŒ¨: {url} (HTTP {response.status})")
        
        except Exception as e:
            self.log_debug(f"URL ìŠ¤ìº” ì‹¤íŒ¨: {url} - {e}")
        
        return findings
    
    def filter_by_severity(self, findings: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì‹¬ê°ë„ë³„ í•„í„°ë§"""
        if self.args.severity == 'all':
            return findings
        
        severity_levels = {'low': 1, 'medium': 2, 'high': 3}
        min_level = severity_levels.get(self.args.severity, 1)
        
        filtered = []
        for finding in findings:
            finding_level = severity_levels.get(finding.get('severity', 'low'), 1)
            if finding_level >= min_level:
                filtered.append(finding)
        
        return filtered
    
    def display_results(self, findings: List[Dict[str, Any]]):
        """ê²°ê³¼ ì¶œë ¥"""
        if self.args.quiet:
            return
        
        if self.args.format == 'json':
            output = {
                'scan_summary': {
                    'total_files': self.total_files,
                    'scanned_files': self.scanned_files,
                    'findings_count': len(findings),
                    'scan_time': datetime.now().isoformat()
                },
                'findings': findings
            }
            pawn.console.print_json(data=output)
            
        elif self.args.format == 'csv':
            # CSV í—¤ë”
            headers = ['file_path', 'line_number', 'severity', 'type', 'description']
            print(','.join(headers))
            
            # CSV ë°ì´í„°
            for finding in findings:
                row = [
                    finding.get('file_path', ''),
                    str(finding.get('line_number', 0)),
                    finding.get('severity', ''),
                    finding.get('type', ''),
                    finding.get('description', '').replace(',', ';')  # CSV í˜¸í™˜ì„±
                ]
                print(','.join(row))
                
        elif self.args.format == 'sarif':
            # SARIF í˜•ì‹ (Static Analysis Results Interchange Format)
            sarif_output = {
                'version': '2.1.0',
                'runs': [{
                    'tool': {
                        'driver': {
                            'name': 'PawnStack ScanKey',
                            'version': '1.0.0'
                        }
                    },
                    'results': []
                }]
            }
            
            for finding in findings:
                sarif_result = {
                    'ruleId': finding.get('type', 'unknown'),
                    'message': {
                        'text': finding.get('description', '')
                    },
                    'level': {
                        'low': 'note',
                        'medium': 'warning',
                        'high': 'error'
                    }.get(finding.get('severity', 'low'), 'note'),
                    'locations': [{
                        'physicalLocation': {
                            'artifactLocation': {
                                'uri': finding.get('file_path', '')
                            },
                            'region': {
                                'startLine': finding.get('line_number', 1),
                                'startColumn': finding.get('column', 1)
                            }
                        }
                    }]
                }
                sarif_output['runs'][0]['results'].append(sarif_result)
            
            pawn.console.print_json(data=sarif_output)
            
        else:  # table í˜•ì‹
            from rich.table import Table
            from rich.panel import Panel
            
            # ìš”ì•½ ì •ë³´
            summary_text = f"""
ìŠ¤ìº” ì™„ë£Œ ìš”ì•½:
â€¢ ì´ íŒŒì¼ ìˆ˜: {self.total_files}
â€¢ ìŠ¤ìº”ëœ íŒŒì¼: {self.scanned_files}
â€¢ ë°œê²¬ëœ ì´ìŠˆ: {len(findings)}
"""
            
            if findings:
                severity_counts = {}
                for finding in findings:
                    severity = finding.get('severity', 'unknown')
                    severity_counts[severity] = severity_counts.get(severity, 0) + 1
                
                summary_text += "\nì‹¬ê°ë„ë³„ ë¶„í¬:\n"
                for severity, count in sorted(severity_counts.items()):
                    summary_text += f"â€¢ {severity}: {count}ê°œ\n"
            
            summary_panel = Panel(summary_text.strip(), title="ğŸ” ìŠ¤ìº” ê²°ê³¼ ìš”ì•½", border_style="blue")
            pawn.console.print(summary_panel)
            
            if findings:
                # ë°œê²¬ëœ ì´ìŠˆ í…Œì´ë¸”
                table = Table(title="ğŸš¨ ë°œê²¬ëœ ë³´ì•ˆ ì´ìŠˆ")
                table.add_column("íŒŒì¼", style="cyan", width=30)
                table.add_column("ë¼ì¸", style="white", width=6)
                table.add_column("ì‹¬ê°ë„", style="yellow", width=8)
                table.add_column("ìœ í˜•", style="green", width=15)
                table.add_column("ì„¤ëª…", style="white")
                
                for finding in findings[:50]:  # ìµœëŒ€ 50ê°œë§Œ í‘œì‹œ
                    # ì‹¬ê°ë„ë³„ ìƒ‰ìƒ
                    severity_colors = {
                        'low': 'green',
                        'medium': 'yellow',
                        'high': 'red'
                    }
                    severity_color = severity_colors.get(finding.get('severity', 'low'), 'white')
                    
                    file_path = finding.get('file_path', '')
                    if len(file_path) > 30:
                        file_path = '...' + file_path[-27:]
                    
                    table.add_row(
                        file_path,
                        str(finding.get('line_number', 0)),
                        f"[{severity_color}]{finding.get('severity', 'unknown')}[/{severity_color}]",
                        finding.get('type', 'unknown'),
                        finding.get('description', '')[:60] + ('...' if len(finding.get('description', '')) > 60 else '')
                    )
                
                pawn.console.print(table)
                
                if len(findings) > 50:
                    pawn.console.print(f"\n[yellow]âš ï¸  {len(findings) - 50}ê°œì˜ ì¶”ê°€ ì´ìŠˆê°€ ìˆìŠµë‹ˆë‹¤. --output ì˜µì…˜ìœ¼ë¡œ ì „ì²´ ê²°ê³¼ë¥¼ ì €ì¥í•˜ì„¸ìš”.[/yellow]")
    
    def save_results(self, findings: List[Dict[str, Any]]):
        """ê²°ê³¼ ì €ì¥"""
        if not hasattr(self.args, 'output') or not self.args.output:
            return
        
        try:
            output_path = Path(self.args.output)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            output_data = {
                'scan_summary': {
                    'total_files': self.total_files,
                    'scanned_files': self.scanned_files,
                    'findings_count': len(findings),
                    'scan_time': datetime.now().isoformat(),
                    'scan_args': vars(self.args)
                },
                'findings': findings
            }
            
            with open(output_path, 'w', encoding='utf-8') as f:
                if output_path.suffix.lower() == '.json':
                    json.dump(output_data, f, indent=2, ensure_ascii=False)
                elif output_path.suffix.lower() in ['.yml', '.yaml']:
                    import yaml
                    yaml.dump(output_data, f, default_flow_style=False, allow_unicode=True)
                else:
                    # ê¸°ë³¸ì ìœ¼ë¡œ JSONìœ¼ë¡œ ì €ì¥
                    json.dump(output_data, f, indent=2, ensure_ascii=False)
            
            self.log_success(f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {self.args.output}")
            
        except Exception as e:
            self.log_error(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    async def run_async(self) -> int:
        """ë¹„ë™ê¸° ì‹¤í–‰"""
        try:
            # ì„¤ì • ë¡œë“œ
            config = self.load_config()
            
            # ì„¤ì • íŒŒì¼ì˜ ê°’ìœ¼ë¡œ ê¸°ë³¸ê°’ ì—…ë°ì´íŠ¸
            if config:
                for key, value in config.items():
                    if not hasattr(self.args, key) or getattr(self.args, key) is None:
                        setattr(self.args, key, value)
            
            self.log_info("í‚¤ ìŠ¤ìº” ì‹œì‘")
            
            all_findings = []
            
            # íŒŒì¼ ìŠ¤ìº”
            if hasattr(self.args, 'file') and self.args.file:
                for file_path in self.args.file:
                    file_path_obj = Path(file_path)
                    if file_path_obj.exists() and file_path_obj.is_file():
                        if self.should_scan_file(file_path_obj):
                            self.total_files += 1
                            findings = await self.scan_file(file_path_obj)
                            all_findings.extend(findings)
                    else:
                        self.log_warning(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            
            # ë””ë ‰í† ë¦¬ ìŠ¤ìº”
            directories_to_scan = []
            
            if hasattr(self.args, 'directory') and self.args.directory:
                directories_to_scan.extend(self.args.directory)
            
            if hasattr(self.args, 'path') and self.args.path:
                path_obj = Path(self.args.path)
                if path_obj.exists():
                    if path_obj.is_file():
                        if self.should_scan_file(path_obj):
                            self.total_files += 1
                            findings = await self.scan_file(path_obj)
                            all_findings.extend(findings)
                    elif path_obj.is_dir():
                        directories_to_scan.append(str(path_obj))
                else:
                    self.log_warning(f"ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.args.path}")
            
            # ë””ë ‰í† ë¦¬ë“¤ ìŠ¤ìº”
            for directory_path in directories_to_scan:
                directory_obj = Path(directory_path)
                if directory_obj.exists() and directory_obj.is_dir():
                    self.log_info(f"ë””ë ‰í† ë¦¬ ìŠ¤ìº”: {directory_path}")
                    findings = await self.scan_directory(directory_obj)
                    all_findings.extend(findings)
                else:
                    self.log_warning(f"ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {directory_path}")
            
            # URL ìŠ¤ìº”
            if hasattr(self.args, 'url') and self.args.url:
                for url in self.args.url:
                    self.log_info(f"URL ìŠ¤ìº”: {url}")
                    findings = await self.scan_url(url)
                    all_findings.extend(findings)
            
            # ìŠ¤ìº” ëŒ€ìƒì´ ì—†ëŠ” ê²½ìš°
            if not all_findings and self.total_files == 0:
                self.log_error("ìŠ¤ìº”í•  ëŒ€ìƒì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. --path, --file, --directory, ë˜ëŠ” --url ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
                return 1
            
            # ì‹¬ê°ë„ë³„ í•„í„°ë§
            filtered_findings = self.filter_by_severity(all_findings)
            
            # ê²°ê³¼ ì¶œë ¥
            self.display_results(filtered_findings)
            
            # ê²°ê³¼ ì €ì¥
            self.save_results(filtered_findings)
            
            # ì¢…ë£Œ ì½”ë“œ ê²°ì •
            if filtered_findings:
                high_severity_count = sum(1 for f in filtered_findings if f.get('severity') == 'high')
                if high_severity_count > 0:
                    self.log_warning(f"ë†’ì€ ì‹¬ê°ë„ ì´ìŠˆ {high_severity_count}ê°œ ë°œê²¬")
                    return 1
                else:
                    self.log_info("ìŠ¤ìº” ì™„ë£Œ (ë‚®ì€/ì¤‘ê°„ ì‹¬ê°ë„ ì´ìŠˆë§Œ ë°œê²¬)")
                    return 0
            else:
                self.log_success("ìŠ¤ìº” ì™„ë£Œ (ì´ìŠˆ ì—†ìŒ)")
                return 0
        
        except Exception as e:
            self.log_error(f"í‚¤ ìŠ¤ìº” ì¤‘ ì˜¤ë¥˜: {e}")
            return 1


def main():
    """CLI ì§„ì…ì """
    cli = ScanKeyCLI()
    return cli.main()


if __name__ == "__main__":
    exit(main())