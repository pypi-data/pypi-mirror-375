#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºçš„å¼•æ“å®ç°
è§£å†³å¤§è§„æ¨¡è¯·æ±‚ç”Ÿæˆæ—¶çš„å¹¶å‘æ§åˆ¶å’ŒèƒŒå‹é—®é¢˜
"""
import asyncio

from crawlo.core.engine import Engine as BaseEngine
from crawlo.utils.log import get_logger


class EnhancedEngine(BaseEngine):
    """
    å¢å¼ºçš„å¼•æ“å®ç°
    
    ä¸»è¦æ”¹è¿›ï¼š
    1. æ™ºèƒ½çš„è¯·æ±‚ç”Ÿæˆæ§åˆ¶
    2. èƒŒå‹æ„ŸçŸ¥çš„è°ƒåº¦
    3. åŠ¨æ€å¹¶å‘è°ƒæ•´
    """
    
    def __init__(self, crawler):
        super().__init__(crawler)
        
        # å¢å¼ºæ§åˆ¶å‚æ•°
        self.max_queue_size = self.settings.get_int('SCHEDULER_MAX_QUEUE_SIZE', 200)
        self.generation_batch_size = 10
        self.generation_interval = 0.05
        self.backpressure_ratio = 0.8  # é˜Ÿåˆ—è¾¾åˆ°80%æ—¶å¯åŠ¨èƒŒå‹
        
        # çŠ¶æ€è·Ÿè¸ª
        self._generation_paused = False
        self._last_generation_time = 0
        self._generation_stats = {
            'total_generated': 0,
            'backpressure_events': 0
        }
        
        self.logger = get_logger(self.__class__.__name__)
    
    async def crawl(self):
        """
        å¢å¼ºçš„çˆ¬å–å¾ªç¯
        æ”¯æŒæ™ºèƒ½è¯·æ±‚ç”Ÿæˆå’ŒèƒŒå‹æ§åˆ¶
        """
        generation_task = None
        
        try:
            # å¯åŠ¨è¯·æ±‚ç”Ÿæˆä»»åŠ¡
            if self.start_requests:
                generation_task = asyncio.create_task(
                    self._controlled_request_generation()
                )
            
            # ä¸»çˆ¬å–å¾ªç¯
            while self.running:
                # è·å–å¹¶å¤„ç†è¯·æ±‚
                if request := await self._get_next_request():
                    await self._crawl(request)
                
                # æ£€æŸ¥é€€å‡ºæ¡ä»¶
                if await self._should_exit():
                    break
                
                # çŸ­æš‚ä¼‘æ¯é¿å…å¿™ç­‰
                await asyncio.sleep(0.001)
        
        finally:
            # æ¸…ç†ç”Ÿæˆä»»åŠ¡
            if generation_task and not generation_task.done():
                generation_task.cancel()
                try:
                    await generation_task
                except asyncio.CancelledError:
                    pass
            
            await self.close_spider()
    
    async def _controlled_request_generation(self):
        """å—æ§çš„è¯·æ±‚ç”Ÿæˆ"""
        self.logger.info("ğŸ›ï¸ å¯åŠ¨å—æ§è¯·æ±‚ç”Ÿæˆ")
        
        batch = []
        total_generated = 0
        
        try:
            for request in self.start_requests:
                batch.append(request)
                
                # æ‰¹é‡å¤„ç†
                if len(batch) >= self.generation_batch_size:
                    generated = await self._process_generation_batch(batch)
                    total_generated += generated
                    batch = []
                
                # èƒŒå‹æ£€æŸ¥
                if await self._should_pause_generation():
                    await self._wait_for_capacity()
            
            # å¤„ç†å‰©ä½™è¯·æ±‚
            if batch:
                generated = await self._process_generation_batch(batch)
                total_generated += generated
        
        except Exception as e:
            self.logger.error(f"âŒ è¯·æ±‚ç”Ÿæˆå¤±è´¥: {e}")
        
        finally:
            self.start_requests = None
            self.logger.info(f"ğŸ‰ è¯·æ±‚ç”Ÿæˆå®Œæˆï¼Œæ€»è®¡: {total_generated}")
    
    async def _process_generation_batch(self, batch) -> int:
        """å¤„ç†ä¸€æ‰¹è¯·æ±‚"""
        generated = 0
        
        for request in batch:
            if not self.running:
                break
            
            # ç­‰å¾…é˜Ÿåˆ—æœ‰ç©ºé—´
            while await self._is_queue_full() and self.running:
                await asyncio.sleep(0.1)
            
            if self.running:
                await self.enqueue_request(request)
                generated += 1
                self._generation_stats['total_generated'] += 1
            
            # æ§åˆ¶ç”Ÿæˆé€Ÿåº¦
            if self.generation_interval > 0:
                await asyncio.sleep(self.generation_interval)
        
        return generated
    
    async def _should_pause_generation(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æš‚åœç”Ÿæˆ"""
        # æ£€æŸ¥é˜Ÿåˆ—å¤§å°
        if await self._is_queue_full():
            return True
        
        # æ£€æŸ¥ä»»åŠ¡ç®¡ç†å™¨è´Ÿè½½
        if self.task_manager:
            current_tasks = len(self.task_manager.current_task)
            if hasattr(self.task_manager, 'semaphore'):
                max_concurrency = getattr(self.task_manager.semaphore, '_initial_value', 8)
                if current_tasks >= max_concurrency * self.backpressure_ratio:
                    return True
        
        return False
    
    async def _is_queue_full(self) -> bool:
        """æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦å·²æ»¡"""
        if not self.scheduler:
            return False
        
        queue_size = len(self.scheduler)
        return queue_size >= self.max_queue_size * self.backpressure_ratio
    
    async def _wait_for_capacity(self):
        """ç­‰å¾…ç³»ç»Ÿæœ‰è¶³å¤Ÿå®¹é‡"""
        self._generation_stats['backpressure_events'] += 1
        self.logger.debug("â¸ï¸ è§¦å‘èƒŒå‹ï¼Œæš‚åœè¯·æ±‚ç”Ÿæˆ")
        
        wait_time = 0.1
        max_wait = 2.0
        
        while await self._should_pause_generation() and self.running:
            await asyncio.sleep(wait_time)
            wait_time = min(wait_time * 1.1, max_wait)
    
    async def _should_exit(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥é€€å‡º"""
        # æ²¡æœ‰å¯åŠ¨è¯·æ±‚ï¼Œä¸”æ‰€æœ‰é˜Ÿåˆ—éƒ½ç©ºé—²
        if (self.start_requests is None and 
            self.scheduler.idle() and 
            self.downloader.idle() and 
            self.task_manager.all_done() and 
            self.processor.idle()):
            return True
        
        return False
    
    def get_generation_stats(self) -> dict:
        """è·å–ç”Ÿæˆç»Ÿè®¡"""
        return {
            **self._generation_stats,
            'queue_size': len(self.scheduler) if self.scheduler else 0,
            'active_tasks': len(self.task_manager.current_task) if self.task_manager else 0
        }