import cv2
import numpy as np
import os
from typing import Dict, List, Tuple, Optional
import json
from pathlib import Path

class ImageAutoAdjuster:
    """
    Class tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh áº£nh templates Ä‘á»ƒ Ä‘áº¡t cháº¥t lÆ°á»£ng tá»‘t vÃ  tá»· lá»‡ Ä‘á»“ng nháº¥t
    """
    
    def __init__(self, base_template_path: str):
        """
        Khá»Ÿi táº¡o auto adjuster vá»›i base template
        
        Args:
            base_template_path: ÄÆ°á»ng dáº«n áº£nh template chuáº©n
        """
        self.base_template_path = base_template_path
        self.base_specs = self._get_base_specs()
        
        print(f"ğŸ“‹ Base template: {os.path.basename(base_template_path)}")
        print(f"   Target size: {self.base_specs['dimensions']}")
        print(f"   Target ratio: {self.base_specs['aspect_ratio']:.3f}")
    
    def _get_base_specs(self) -> Dict:
        """Láº¥y thÃ´ng sá»‘ base template"""
        if not os.path.exists(self.base_template_path):
            raise FileNotFoundError(f"Base template not found: {self.base_template_path}")
        
        image = cv2.imread(self.base_template_path)
        height, width = image.shape[:2]
        aspect_ratio = width / height
        
        return {
            'dimensions': (width, height),
            'aspect_ratio': aspect_ratio,
            'width': width,
            'height': height
        }
    
    def auto_adjust_image(self, input_path: str, output_path: str = None) -> Dict:
        """
        Tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh áº£nh Ä‘á»ƒ phÃ¹ há»£p vá»›i base template
        
        Args:
            input_path: ÄÆ°á»ng dáº«n áº£nh Ä‘áº§u vÃ o
            output_path: ÄÆ°á»ng dáº«n áº£nh Ä‘áº§u ra (None = auto generate)
            
        Returns:
            Dict káº¿t quáº£ Ä‘iá»u chá»‰nh
        """
        try:
            # Äá»c áº£nh
            image = cv2.imread(input_path)
            if image is None:
                return {"success": False, "error": "Cannot read image"}
            
            original_shape = image.shape
            print(f"ğŸ”§ Adjusting: {os.path.basename(input_path)} {original_shape[:2]}")
            
            # BÆ°á»›c 1: Resize vá» Ä‘Ãºng aspect ratio vÃ  kÃ­ch thÆ°á»›c
            adjusted_image = self._resize_to_target(image)
            print(f"   ğŸ“ Resized to: {adjusted_image.shape[:2]}")
            
            # BÆ°á»›c 2: Äiá»u chá»‰nh brightness (giáº£m Ä‘á»™ sÃ¡ng vÃ¬ háº§u háº¿t áº£nh quÃ¡ sÃ¡ng)
            adjusted_image = self._adjust_brightness(adjusted_image, factor=0.85)
            print(f"   ğŸ’¡ Brightness adjusted")
            
            # BÆ°á»›c 3: Giáº£m noise
            adjusted_image = self._reduce_noise(adjusted_image)
            print(f"   ğŸ”‡ Noise reduced")
            
            # BÆ°á»›c 4: TÄƒng sharpness nháº¹
            adjusted_image = self._enhance_sharpness(adjusted_image)
            print(f"   ğŸ” Sharpness enhanced")
            
            # BÆ°á»›c 5: Äiá»u chá»‰nh contrast
            adjusted_image = self._adjust_contrast(adjusted_image, factor=1.1)
            print(f"   ğŸ¨ Contrast adjusted")
            
            # Táº¡o output path náº¿u chÆ°a cÃ³
            if output_path is None:
                name, ext = os.path.splitext(input_path)
                output_path = f"{name}_adjusted{ext}"
            
            # LÆ°u áº£nh
            cv2.imwrite(output_path, adjusted_image)
            
            # TÃ­nh quality score sau Ä‘iá»u chá»‰nh
            quality_after = self._calculate_quality_score(adjusted_image)
            
            return {
                "success": True,
                "input_path": input_path,
                "output_path": output_path,
                "original_shape": original_shape,
                "adjusted_shape": adjusted_image.shape,
                "quality_score": quality_after,
                "adjustments_applied": [
                    "resize_to_target",
                    "brightness_adjustment", 
                    "noise_reduction",
                    "sharpness_enhancement",
                    "contrast_adjustment"
                ]
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def _resize_to_target(self, image: np.ndarray) -> np.ndarray:
        """Resize áº£nh vá» Ä‘Ãºng tá»· lá»‡ vÃ  kÃ­ch thÆ°á»›c target"""
        target_width = self.base_specs['width']
        target_height = self.base_specs['height']
        
        # Resize vá» Ä‘Ãºng kÃ­ch thÆ°á»›c target
        resized = cv2.resize(image, (target_width, target_height), interpolation=cv2.INTER_LANCZOS4)
        
        return resized
    
    def _adjust_brightness(self, image: np.ndarray, factor: float = 0.85) -> np.ndarray:
        """Äiá»u chá»‰nh Ä‘á»™ sÃ¡ng"""
        # Convert to float Ä‘á»ƒ trÃ¡nh overflow
        adjusted = image.astype(np.float32) * factor
        
        # Clip vá» range há»£p lá»‡
        adjusted = np.clip(adjusted, 0, 255).astype(np.uint8)
        
        return adjusted
    
    def _reduce_noise(self, image: np.ndarray) -> np.ndarray:
        """Giáº£m noise sá»­ dá»¥ng bilateral filter"""
        # Bilateral filter giá»¯ edges sáº¯c nÃ©t nhÆ°ng giáº£m noise
        denoised = cv2.bilateralFilter(image, 9, 75, 75)
        
        return denoised
    
    def _enhance_sharpness(self, image: np.ndarray) -> np.ndarray:
        """TÄƒng Ä‘á»™ sáº¯c nÃ©t nháº¹"""
        # Kernel cho sharpening
        kernel = np.array([[-1,-1,-1],
                          [-1, 9,-1], 
                          [-1,-1,-1]])
        
        # Apply kernel nháº¹
        sharpened = cv2.filter2D(image, -1, kernel * 0.1)
        
        # Blend vá»›i áº£nh gá»‘c
        enhanced = cv2.addWeighted(image, 0.8, sharpened, 0.2, 0)
        
        return enhanced
    
    def _adjust_contrast(self, image: np.ndarray, factor: float = 1.1) -> np.ndarray:
        """Äiá»u chá»‰nh contrast"""
        # Convert to float
        adjusted = image.astype(np.float32)
        
        # Apply contrast: new_pixel = (old_pixel - 128) * factor + 128
        adjusted = (adjusted - 128) * factor + 128
        
        # Clip vá» range há»£p lá»‡
        adjusted = np.clip(adjusted, 0, 255).astype(np.uint8)
        
        return adjusted
    
    def _calculate_quality_score(self, image: np.ndarray) -> float:
        """TÃ­nh quality score cho áº£nh"""
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Sharpness (Laplacian variance)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        sharpness_score = min(laplacian_var / 200.0, 1.0)
        
        # Contrast
        contrast = np.std(gray)
        contrast_score = max(0, 1.0 - abs(contrast - 60) / 60.0)
        
        # Brightness
        brightness = np.mean(gray)
        brightness_score = max(0, 1.0 - abs(brightness - 130) / 130.0)
        
        # Edge density
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.sum(edges > 0) / (gray.shape[0] * gray.shape[1])
        edge_score = min(edge_density / 0.1, 1.0) if edge_density > 0.01 else 0
        
        # Combined score
        quality = (0.3 * sharpness_score + 
                  0.25 * contrast_score + 
                  0.2 * brightness_score + 
                  0.25 * edge_score)
        
        return min(1.0, max(0.0, quality))
    
    def batch_adjust_directory(self, input_dir: str, output_dir: str = None) -> Dict:
        """
        Tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh táº¥t cáº£ áº£nh trong thÆ° má»¥c
        
        Args:
            input_dir: ThÆ° má»¥c Ä‘áº§u vÃ o
            output_dir: ThÆ° má»¥c Ä‘áº§u ra (None = input_dir + "_adjusted")
            
        Returns:
            Dict bÃ¡o cÃ¡o káº¿t quáº£
        """
        print(f"ğŸš€ Batch adjusting directory: {input_dir}")
        
        # Táº¡o output directory
        if output_dir is None:
            output_dir = f"{input_dir}_adjusted"
        
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            print(f"ğŸ“ Created output directory: {output_dir}")
        
        # TÃ¬m táº¥t cáº£ file áº£nh
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
        image_files = []
        
        for root, dirs, files in os.walk(input_dir):
            for file in files:
                if any(file.lower().endswith(ext) for ext in image_extensions):
                    # Bá» qua áº£nh Ä‘Ã£ adjusted
                    if "_adjusted" not in file:
                        image_files.append(os.path.join(root, file))
        
        print(f"ğŸ“‹ Found {len(image_files)} images to adjust")
        
        # Äiá»u chá»‰nh tá»«ng áº£nh
        results = []
        success_count = 0
        
        for i, image_path in enumerate(image_files, 1):
            print(f"\nğŸ“¸ ({i}/{len(image_files)}) Processing...")
            
            # Táº¡o output path
            rel_path = os.path.relpath(image_path, input_dir)
            name, ext = os.path.splitext(rel_path)
            output_path = os.path.join(output_dir, f"{name}_adjusted{ext}")
            
            # Táº¡o thÆ° má»¥c con náº¿u cáº§n
            output_subdir = os.path.dirname(output_path)
            if not os.path.exists(output_subdir):
                os.makedirs(output_subdir)
            
            # Äiá»u chá»‰nh áº£nh
            result = self.auto_adjust_image(image_path, output_path)
            
            if result["success"]:
                success_count += 1
                print(f"   âœ… Success: Quality {result['quality_score']:.3f}")
            else:
                print(f"   âŒ Failed: {result['error']}")
            
            results.append(result)
        
        # TÃ³m táº¯t
        summary = {
            "total_images": len(image_files),
            "success_count": success_count,
            "failed_count": len(image_files) - success_count,
            "success_rate": success_count / len(image_files) * 100 if image_files else 0,
            "output_directory": output_dir
        }
        
        print(f"\nğŸ“Š Batch adjustment completed:")
        print(f"   âœ… Success: {success_count}/{len(image_files)} ({summary['success_rate']:.1f}%)")
        print(f"   ğŸ“ Output: {output_dir}")
        
        return {
            "summary": summary,
            "detailed_results": results
        }
    
    def compare_before_after(self, original_dir: str, adjusted_dir: str) -> Dict:
        """
        So sÃ¡nh cháº¥t lÆ°á»£ng trÆ°á»›c vÃ  sau Ä‘iá»u chá»‰nh
        
        Args:
            original_dir: ThÆ° má»¥c áº£nh gá»‘c
            adjusted_dir: ThÆ° má»¥c áº£nh Ä‘Ã£ Ä‘iá»u chá»‰nh
            
        Returns:
            Dict bÃ¡o cÃ¡o so sÃ¡nh
        """
        print(f"ğŸ“Š Comparing before/after quality...")
        
        # Import ImageQualityChecker Ä‘á»ƒ so sÃ¡nh
        from .image_quality_checker import ImageQualityChecker
        
        checker = ImageQualityChecker(self.base_template_path)
        
        # Kiá»ƒm tra áº£nh gá»‘c
        print(f"\nğŸ” Analyzing original images...")
        original_report = checker.check_template_directory(original_dir)
        
        # Kiá»ƒm tra áº£nh Ä‘Ã£ Ä‘iá»u chá»‰nh
        print(f"\nğŸ” Analyzing adjusted images...")
        adjusted_report = checker.check_template_directory(adjusted_dir)
        
        # So sÃ¡nh
        orig_summary = original_report["summary"]
        adj_summary = adjusted_report["summary"]
        
        improvement = {
            "quality_improvement": adj_summary["quality_passed"] - orig_summary["quality_passed"],
            "ratio_improvement": adj_summary["ratio_compatible"] - orig_summary["ratio_compatible"],
            "quality_rate_before": orig_summary["quality_passed"] / orig_summary["total_images"] * 100,
            "quality_rate_after": adj_summary["quality_passed"] / adj_summary["total_images"] * 100,
            "ratio_rate_before": orig_summary["ratio_compatible"] / orig_summary["total_images"] * 100,
            "ratio_rate_after": adj_summary["ratio_compatible"] / adj_summary["total_images"] * 100
        }
        
        print(f"\nğŸ“ˆ IMPROVEMENT SUMMARY:")
        print(f"   Quality pass rate: {improvement['quality_rate_before']:.1f}% â†’ {improvement['quality_rate_after']:.1f}%")
        print(f"   Ratio compatibility: {improvement['ratio_rate_before']:.1f}% â†’ {improvement['ratio_rate_after']:.1f}%")
        
        return {
            "original_report": original_report,
            "adjusted_report": adjusted_report,
            "improvement": improvement
        }

def main():
    """Demo auto adjustment"""
    # Base template
    base_template = r"C:\WorkSpace\DECDM\VietCardLib\templates\base\0_CANCUOC.jpg"
    
    # Khá»Ÿi táº¡o auto adjuster
    adjuster = ImageAutoAdjuster(base_template)
    
    # Auto adjust toÃ n bá»™ thÆ° má»¥c templates
    template_dir = r"C:\WorkSpace\DECDM\VietCardLib\templates"
    
    print("ğŸš€ AUTO-ADJUSTING TEMPLATES")
    print("="*50)
    
    # Cháº¡y batch adjustment
    batch_result = adjuster.batch_adjust_directory(template_dir)
    
    # So sÃ¡nh trÆ°á»›c vÃ  sau
    comparison = adjuster.compare_before_after(template_dir, batch_result["summary"]["output_directory"])
    
    print("\nğŸ‰ Auto adjustment completed!")

if __name__ == "__main__":
    main()
