from functools import wraps, partial
import asyncio
import aiometer
from aiometer._impl import utils
import httpx
import sys

from pawnstack.log import AppLogger
from pawnstack.type_utils.constants import const

# Initialize a logger for this module
logger = AppLogger().get_logger("pawnstack.asyncio.tasks")


class AsyncTasks:
    def __init__(
        self,
        max_at_once: int = 10,
        max_per_second: int = 10,
        title: str = "Working on async tasks ...",
        debug: bool = False,
        status: bool = False,
        **kwargs
    ):
        """
        This Class is to run asyncio using aiometer.

        :param max_at_once: Limit maximum number of concurrently running tasks.
        :param max_per_second: Limit request rate to not overload the server.
        :param title: Title of the tasks
        :param status: Status of the tasks
        :param debug: Whether to use debug
        :param kwargs:

        Example:

            .. code-block:: python

                async_tasks = AsyncTasks(max_at_once=10, max_per_second=10)
                # Assuming a function `my_async_func` is defined
                tasks = [partial(my_async_func, i) for i in range(100)]
                async_tasks.run(tasks)

        """
        self.tasks = []
        self.max_at_once = max_at_once
        self.max_per_second = max_per_second
        self.debug = debug
        if self.debug:
            logger.debug(f"AsyncTasks initialized with: {self.__dict__}")

        self.get_list_function = None
        self.async_partial_target_func = None
        self.async_partial_task_func = None
        self.status_console = None

        self._title = title
        self._view_status = status
        self._function_name = ""

    def get_tasks(self):
        return self.tasks

    def _is_event_loop_running(self):
        """
        현재 이벤트 루프 상태를 감지합니다.

        :return: 이벤트 루프가 실행 중이면 True, 아니면 False
        """
        try:
            loop = asyncio.get_running_loop()
            return loop.is_running()
        except RuntimeError:
            # 실행 중인 이벤트 루프가 없는 경우
            return False

    def generate_tasks(self, target_list=None, function=None, **kwargs):
        """
        This function generates the async tasks list

        :param target_list: List of targets for asynchronous execution
        :param function: Name of the function to execute
        :param kwargs:
        :return: self
        """
        if function and getattr(function, "__qualname__"):
            self._function_name = function.__qualname__
        else:
            raise ValueError(f"{function} is not a valid function")

        if self.debug:
            logger.debug(f"Generating tasks for target_list: {target_list} with function: {self._function_name}")

        if kwargs.get('kwargs'):
            kwargs = kwargs['kwargs']
        else:
            kwargs = {}

        if target_list is None:
            target_list = []

        for target in target_list:
            if self.debug:
                logger.debug(f"Adding task: target={target}, function={self._function_name}(), kwargs={kwargs}")
            self.tasks.append(partial(function, target, **kwargs))
        return self

    def run(self, tasks=None):
        """
        This function executes an asynchronous operation.
        :param tasks: Optional list of tasks to run. If None, uses tasks generated by `generate_tasks`.
        :return: List of results from the async tasks.
        """
        if tasks:
            self.tasks = tasks

        logger.info(f"Running {len(self.tasks)} tasks...")

        # 이벤트 루프 상태를 감지하고 적절한 실행 방법 선택
        if self._is_event_loop_running():
            logger.warning("Event loop is already running. Consider using run_async() method instead.")
            # 이미 실행 중인 이벤트 루프에서는 run_async() 사용을 권장
            # 하지만 호환성을 위해 동기적으로 실행할 수 있는 방법을 제공
            import concurrent.futures
            import threading

            def run_in_thread():
                return asyncio.run(self._runner())

            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(run_in_thread)
                result = future.result()
        else:
            # 이벤트 루프가 실행 중이 아닌 경우 asyncio.run() 사용
            try:
                result = asyncio.run(self._runner())
            except RuntimeError as e:
                if "This event loop is already running" in str(e):
                    logger.error("RuntimeError: Event loop is already running. Use run_async() method instead.")
                    raise RuntimeError(
                        "Cannot run asyncio.run() in an already running event loop. "
                        "Use run_async() method for asynchronous execution."
                    ) from e
                else:
                    raise e

        logger.info("All tasks completed.")
        return result

    async def run_async(self, tasks=None):
        """
        This function executes an asynchronous operation.
        :param tasks: Optional list of tasks to run. If None, uses tasks generated by `generate_tasks`.
        :return: List of results from the async tasks.
        """
        if tasks:
            self.tasks = tasks

        # This part is tricky because rich.status needs a console object.
        # Assuming a global or passed-in console object for status.
        # For simplicity, we will log to the logger instead of a live status for now.
        # A more advanced implementation would involve passing a Rich console object.
        logger.info(f"Running {len(self.tasks)} tasks...")
        result = await self._runner()
        logger.info("All tasks completed.")
        return result

    async def _runner(self):
        results = {}
        tasks_length = len(self.tasks)

        if tasks_length > 0:
            async with aiometer.amap(
                async_fn=lambda fn: fn(),
                args=self.tasks,
                max_at_once=self.max_at_once,
                max_per_second=self.max_per_second,
                _include_index=True,
            ) as amap_results:
                async for _index, _result in amap_results:
                    results[_index] = _result
                    if self._view_status:
                        # Simple logging instead of rich status update
                        logger.info(f"{self._title} <{self._function_name}> [{_index + 1}/{tasks_length}] Completed.")
        else:
            logger.warning("No tasks to run.")
        return utils.list_from_indexed_dict(results)


class AsyncHttp(AsyncTasks):
    """
    This class is a subclass of AsyncTasks and is used to handle asynchronous HTTP requests.
    """

    def __init__(
        self,
        urls: list = None,
        max_at_once: int = 10,
        max_per_second: int = 10,
        title="Fetching URLs ...",
        debug: bool = False,
        status: bool = False,
        **kwargs
    ):
        super().__init__(max_at_once, max_per_second, title, debug, status, **kwargs)
        self.urls = urls if urls is not None else []
        self._prepare()

    def append_task(self, task):
        """
        Append a new task to the task list.

        Args:
            task (str or dict): If it's a string, it's considered as a URL. If it's a dictionary, it should contain a 'url' key.
        """
        _url = None
        _kwargs = {}

        if isinstance(task, str):
            _url = task
        elif isinstance(task, dict) and task.get('url'):
            _url = task.pop("url")
            _kwargs = task
        else:
            logger.error(f"Invalid task format: {task}")
            return

        self.generate_tasks(
            target_list=[_url],
            function=fetch_httpx_url,
            kwargs=_kwargs
        )
        if self.debug:
            logger.debug(f"Appended task: url={_url}, kwargs={_kwargs}")

    def _prepare(self):
        """
        Prepare the tasks based on the provided URLs.
        """
        if self.urls:
            for info in self.urls:
                self.append_task(info)


async def fetch_httpx_url(url, method="get", timeout=4, max_keepalive_connections=10, max_connections=20, **kwargs):
    """
    Asynchronously fetch a URL using httpx.
    """
    response = None
    try:
        limits = httpx.Limits(max_keepalive_connections=max_keepalive_connections, max_connections=max_connections)
        async with httpx.AsyncClient(timeout=timeout, limits=limits) as client:
            if method.lower() in const.get_http_methods(lowercase=True):
                response = await getattr(client, method.lower())(url, timeout=timeout, **kwargs)
                response.raise_for_status()  # Raise an exception for bad status codes
            else:
                logger.error(f"Unsupported HTTP method -> {method}")
                raise ValueError(f"Unsupported HTTP method: {method}")
            return response
    except httpx.HTTPStatusError as e:
        logger.error(f"HTTP error for {url}: {e.response.status_code} - {e.response.text}")
    except Exception as e:
        logger.error(f"Error fetching {url}: {e}")
    return None

def async_partial(async_fn, *args, **kwargs):
    async def wrapped():
        if asyncio.iscoroutinefunction(async_fn):
            return await async_fn(*args, **kwargs)
        else:
            logger.warning(f"{async_fn} is not a coroutine function")
            return None
    return wrapped


def run_in_async_loop(f):
    @wraps(f)
    async def wrapped(*args, **kwargs):
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(None, partial(f, *args, **kwargs))
    return wrapped
