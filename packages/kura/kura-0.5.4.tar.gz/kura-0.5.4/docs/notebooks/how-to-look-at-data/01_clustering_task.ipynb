{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clustering Conversations: Discovering User Query Patterns\n",
        "\n",
        "> **Series Overview**: This is the first notebook in a three-part series on systematically analyzing and improving RAG systems. We'll move from raw user queries to production-ready classifiers that enable data-driven improvements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/567-labs/kura/blob/main/docs/notebooks/how-to-look-at-data/01_clustering_task.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install kura in Google Colab\n",
        "!pip install kura\n",
        "\n",
        "\n",
        "# Make sure you've setup your `OPENAI_API_KEY``\n",
        "# os.environ['OPENAI_API_KEY'] = <your api key here> \n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "\n",
        "# Create data directory and download dataset\n",
        "DATA_DIRECTORY = './data'\n",
        "CHECKPOINT_DIRECTORY = './checkpoints'\n",
        "\n",
        "# Curl the Conversation Dataset\n",
        "os.makedirs(DATA_DIRECTORY, exist_ok=True)\n",
        "!curl -o {DATA_DIRECTORY}/conversations.json https://usekura.xyz/assets/conversations.json\n",
        "\n",
        "# Curl the Checkpoints\n",
        "os.makedirs(CHECKPOINT_DIRECTORY, exist_ok=True)\n",
        "\n",
        "!curl -o {CHECKPOINT_DIRECTORY}/clusters.jsonl https://usekura.xyz/assets/notebooks/checkpoints/clusters.jsonl\n",
        "!curl -o {CHECKPOINT_DIRECTORY}/conversations.jsonl https://usekura.xyz/assets/notebooks/checkpoints/conversations.jsonl  \n",
        "!curl -o {CHECKPOINT_DIRECTORY}/dimensionality.jsonl https://usekura.xyz/assets/notebooks/checkpoints/dimensionality.jsonl\n",
        "!curl -o {CHECKPOINT_DIRECTORY}/meta_clusters.jsonl https://usekura.xyz/assets/notebooks/checkpoints/meta_clusters.jsonl\n",
        "!curl -o {CHECKPOINT_DIRECTORY}/summaries.jsonl https://usekura.xyz/assets/notebooks/checkpoints/summaries.jsonl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Reproducing Results**: To reproduce the exact results from this notebook, the first cell downloads pre-computed checkpoints from our server. These checkpoints contain the intermediate results from each step of the clustering pipeline, allowing you to follow along without waiting for the computationally expensive embedding and clustering operations to complete.\n",
        "> \n",
        "> To download our precomputed checkpoints, make sure that you curl the `checkpoints` directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Matters\n",
        "\n",
        "In large-scale RAG applications, you'll encounter thousands of user queries. Manually reviewing each is impossible, and simple keyword counting misses deeper patterns. **Topic modeling helps you systematically identify patterns in user queries**, giving you insights into what users are asking and how well your system serves them.\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "In this first notebook, you'll discover how to:\n",
        "\n",
        "1. **Prepare Query Data for Analysis**\n",
        "   - Format JSON data into Kura conversation objects\n",
        "   - Structure query-document pairs with proper metadata\n",
        "   - Set up data for effective clustering\n",
        "\n",
        "2. **Run Hierarchical Topic Clustering**\n",
        "   - Use Kura's procedural API for LLM-enhanced clustering\n",
        "   - Generate meaningful summaries of conversation groups\n",
        "   - Visualize the topic hierarchies that emerge\n",
        "\n",
        "3. **Analyze and Interpret Results**\n",
        "   - Examine cluster themes and distribution patterns\n",
        "   - Identify high-impact areas for system improvements\n",
        "   - Recognize limitations in default summarization\n",
        "\n",
        "## What You'll Discover\n",
        "\n",
        "**By the end of this notebook, you'll uncover that just three major topics account for over two-thirds of all user queries**, with experiment tracking and logging appearing as dominant themes. However, you'll also discover that default summaries miss crucial details about specific features—a limitation that motivates the custom summarization approach in the next notebook.\n",
        "\n",
        "## What Makes Kura Different\n",
        "\n",
        "Traditional topic modeling approaches like BERTopic or LDA rely purely on embeddings to group similar documents. **Kura enhances this process by leveraging LLMs to**:\n",
        "\n",
        "1. **Generate Meaningful Summaries** - Create human-readable descriptions rather than just numeric vectors\n",
        "2. **Build Topic Hierarchies** - Create multi-level trees showing relationships between themes\n",
        "3. **Provide Procedural API** - Simple functions rather than complex object hierarchies\n",
        "\n",
        "By using LLMs for summarization before clustering, Kura produces more intuitive, actionable results than pure embedding-based approaches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding Topic Modeling\n",
        "\n",
        "### What is Topic Modeling?\n",
        "\n",
        "Topic modeling is a technique for automatically discovering themes or patterns in large collections of text. Think of it like sorting a massive pile of documents into folders based on what they're about—except the computer figures out both what the folders should be AND which documents belong in each one.\n",
        "\n",
        "### The Role of Embeddings\n",
        "\n",
        "To group similar texts together, we first need to convert them into a format computers can compare. **Embeddings** are numerical representations of text—think of them as coordinates in a high-dimensional space where similar meanings are positioned closer together.\n",
        "\n",
        "For example:\n",
        "- \"How do I version my model?\" and \"What's the best way to track model versions?\" would have similar embeddings despite using different words\n",
        "- These queries would be far from \"How do I visualize training metrics?\" in the embedding space\n",
        "\n",
        "### Making Sense with Dimensionality Reduction\n",
        "\n",
        "Embeddings typically have hundreds or thousands of dimensions—impossible to visualize directly. **Dimensionality reduction** techniques compress these high-dimensional representations down to 2D or 3D while preserving the important relationships between points.\n",
        "\n",
        "It's like creating a map of a globe—you lose some information when flattening 3D to 2D, but the relative positions of continents remain meaningful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "import json\n",
        "\n",
        "with open(f\"{DATA_DIRECTORY}/conversations.json\") as f:\n",
        "    conversations_raw = json.load(f)\n",
        "\n",
        "conversations_raw[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query_id': '5e878c76-25c1-4bad-8cae-6a40ca4c8138',\n",
              " 'query': 'experiment tracking',\n",
              " 'matching_document': '## Track Experiments\\n### How it works\\nTrack a machine learning experiment with a few lines of code:\\n1. Create a W&B run.\\n2. Store a dictionary of hyperparameters, such as learning rate or model type, into your configuration (`wandb.config`).\\n3. Log metrics (`wandb.log()`) over time in a training loop, such as accuracy and loss.\\n4. Save outputs of a run, like the model weights or a table of predictions.  \\n\\nThe proceeding pseudocode demonstrates a common W&B Experiment tracking workflow:  \\n\\n```python showLineNumbers\\n\\n# 1. Start a W&B Run\\n\\nwandb.init(entity=\"\", project=\"my-project-name\")\\n\\n# 2. Save mode inputs and hyperparameters\\n\\nwandb.config.learning\\\\_rate = 0.01\\n\\n# Import model and data\\n\\nmodel, dataloader = get\\\\_model(), get\\\\_data()\\n\\n# Model training code goes here\\n\\n# 3. Log metrics over time to visualize performance\\n\\nwandb.log({\"loss\": loss})\\n\\n# 4. Log an artifact to W&B\\n\\nwandb.log\\\\_artifact(model)\\n```',\n",
              " 'matching_document_document_id': '1c7f8798-7b2a-4baa-9829-14ada61db6bc',\n",
              " 'query_weight': 0.1}"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with open(\"./data/conversations.json\") as f:\n",
        "    conversations_raw = json.load(f)\n",
        "\n",
        "conversations_raw[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This raw format isn't immediately useful for topic modeling. We need to transform it into something that Kura can process effectively. \n",
        "\n",
        "To do so, we'll convert it to a `Conversation` class which `Kura` exposes. This format allows Kura to:\n",
        "\n",
        "1. Process the conversation flow (even though we only have single queries in this example)\n",
        "2. Generate summaries of each conversation\n",
        "3. Embed and cluster conversations based on content and structure\n",
        "\n",
        "We'll create a function to convert each query-document pair into a Kura Conversation object with a single user Message that combines both the query and retrieved document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Conversation</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">chat_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'5e878c76-25c1-4bad-8cae-6a40ca4c8138'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">created_at</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">92552</span><span style=\"font-weight: bold\">)</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">messages</span>=<span style=\"font-weight: bold\">[</span>\n",
              "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Message</span><span style=\"font-weight: bold\">(</span>\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">created_at</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">41</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">92555</span><span style=\"font-weight: bold\">)</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>,\n",
              "            <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\\nUser Query: experiment tracking\\nRetrieved Information : ## Track Experiments\\n### How it </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">works\\nTrack a machine learning experiment with a few lines of code:\\n1. Create a W&amp;B run.\\n2. Store a dictionary </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">of hyperparameters, such as learning rate or model type, into your configuration (`wandb.config`).\\n3. Log metrics </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">(`wandb.log()`) over time in a training loop, such as accuracy and loss.\\n4. Save outputs of a run, like the model </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">weights or a table of predictions.  \\n\\nThe proceeding pseudocode demonstrates a common W&amp;B Experiment tracking </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">workflow:  \\n\\n```python showLineNumbers\\n\\n# 1. Start a W&amp;B Run\\n\\nwandb.init(entity=\"\", </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">project=\"my-project-name\")\\n\\n# 2. Save mode inputs and hyperparameters\\n\\nwandb.config.learning\\\\_rate = 0.01\\n\\n#</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">Import model and data\\n\\nmodel, dataloader = get\\\\_model(), get\\\\_data()\\n\\n# Model training code goes here\\n\\n# 3.</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">Log metrics over time to visualize performance\\n\\nwandb.log({\"loss\": loss})\\n\\n# 4. Log an artifact to </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">W&amp;B\\n\\nwandb.log\\\\_artifact(model)\\n```\\n'</span>\n",
              "        <span style=\"font-weight: bold\">)</span>\n",
              "    <span style=\"font-weight: bold\">]</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'query_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'5e878c76-25c1-4bad-8cae-6a40ca4c8138'</span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mConversation\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[33mchat_id\u001b[0m=\u001b[32m'5e878c76-25c1-4bad-8cae-6a40ca4c8138'\u001b[0m,\n",
              "    \u001b[33mcreated_at\u001b[0m=\u001b[1;35mdatetime\u001b[0m\u001b[1;35m.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2025\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m29\u001b[0m, \u001b[1;36m22\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m41\u001b[0m, \u001b[1;36m92552\u001b[0m\u001b[1m)\u001b[0m,\n",
              "    \u001b[33mmessages\u001b[0m=\u001b[1m[\u001b[0m\n",
              "        \u001b[1;35mMessage\u001b[0m\u001b[1m(\u001b[0m\n",
              "            \u001b[33mcreated_at\u001b[0m=\u001b[1;35mdatetime\u001b[0m\u001b[1;35m.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2025\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m29\u001b[0m, \u001b[1;36m22\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m41\u001b[0m, \u001b[1;36m92555\u001b[0m\u001b[1m)\u001b[0m,\n",
              "            \u001b[33mrole\u001b[0m=\u001b[32m'user'\u001b[0m,\n",
              "            \u001b[33mcontent\u001b[0m=\u001b[32m'\\nUser Query: experiment tracking\\nRetrieved Information : ## Track Experiments\\n### How it \u001b[0m\n",
              "\u001b[32mworks\\nTrack a machine learning experiment with a few lines of code:\\n1. Create a W&B run.\\n2. Store a dictionary \u001b[0m\n",
              "\u001b[32mof hyperparameters, such as learning rate or model type, into your configuration \u001b[0m\u001b[32m(\u001b[0m\u001b[32m`wandb.config`\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n3. Log metrics \u001b[0m\n",
              "\u001b[32m(\u001b[0m\u001b[32m`wandb.log\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m`\u001b[0m\u001b[32m)\u001b[0m\u001b[32m over time in a training loop, such as accuracy and loss.\\n4. Save outputs of a run, like the model \u001b[0m\n",
              "\u001b[32mweights or a table of predictions.  \\n\\nThe proceeding pseudocode demonstrates a common W&B Experiment tracking \u001b[0m\n",
              "\u001b[32mworkflow:  \\n\\n```python showLineNumbers\\n\\n# 1. Start a W&B Run\\n\\nwandb.init\u001b[0m\u001b[32m(\u001b[0m\u001b[32mentity\u001b[0m\u001b[32m=\"\", \u001b[0m\n",
              "\u001b[32mproject\u001b[0m\u001b[32m=\u001b[0m\u001b[32m\"my\u001b[0m\u001b[32m-project-name\"\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n# 2. Save mode inputs and hyperparameters\\n\\nwandb.config.learning\\\\_rate = 0.01\\n\\n#\u001b[0m\n",
              "\u001b[32mImport model and data\\n\\nmodel, dataloader = get\\\\_model\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, get\\\\_data\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n# Model training code goes here\\n\\n# 3.\u001b[0m\n",
              "\u001b[32mLog metrics over time to visualize performance\\n\\nwandb.log\u001b[0m\u001b[32m(\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"loss\": loss\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n# 4. Log an artifact to \u001b[0m\n",
              "\u001b[32mW&B\\n\\nwandb.log\\\\_artifact\u001b[0m\u001b[32m(\u001b[0m\u001b[32mmodel\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n```\\n'\u001b[0m\n",
              "        \u001b[1m)\u001b[0m\n",
              "    \u001b[1m]\u001b[0m,\n",
              "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'query_id'\u001b[0m: \u001b[32m'5e878c76-25c1-4bad-8cae-6a40ca4c8138'\u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from kura.types import Message, Conversation\n",
        "from datetime import datetime\n",
        "from rich import print\n",
        "\n",
        "\n",
        "def process_query_obj(obj: dict):\n",
        "    return Conversation(\n",
        "        chat_id=obj[\"query_id\"],\n",
        "        created_at=datetime.now(),\n",
        "        messages=[\n",
        "            Message(\n",
        "                created_at=datetime.now(),\n",
        "                role=\"user\",\n",
        "                content=f\"\"\"\n",
        "User Query: {obj[\"query\"]}\n",
        "Retrieved Information : {obj[\"matching_document\"]}\n",
        "\"\"\",\n",
        "            )\n",
        "        ],\n",
        "        metadata={\"query_id\": obj[\"query_id\"]},\n",
        "    )\n",
        "\n",
        "\n",
        "print(process_query_obj(conversations_raw[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "conversations = [process_query_obj(obj) for obj in conversations_raw]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each individual `Conversation` object exposes a metadata field which allows us to provide additional context that can be valuable for analysis.\n",
        "\n",
        "In this case here, we add the Query ID to the metadata field so that we can preserve it for downstream processing. By properly structuring our data and enriching it with metadata, we're setting a strong foundation for the topic modeling work ahead. \n",
        "\n",
        "This careful preparation will pay off when we analyze the results and turn insights into actionable improvements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the Clustering Process\n",
        "\n",
        "Now that we've converted our raw data into Kura's Conversation format, we're ready to run the clustering process.\n",
        "\n",
        "### The Clustering Pipeline\n",
        "\n",
        "The hierarchical clustering process follows these systematic steps:\n",
        "\n",
        "1. **Summarization**: `summarise_conversations()` - Each conversation is summarized by an LLM\n",
        "2. **Base Clustering**: `generate_base_clusters_from_conversation_summaries()` - Similar conversations are grouped into initial clusters\n",
        "3. **Hierarchical Merging**: `reduce_clusters_from_base_clusters()` - Similar clusters are progressively combined\n",
        "4. **Dimensionality Reduction**: `reduce_dimensionality_from_clusters()` - Projects clusters for visualization\n",
        "\n",
        "Each function handles one step, making it easy to customize individual components and save intermediate results with checkpointing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from kura.checkpoints import JSONLCheckpointManager\n",
        "from kura import (\n",
        "        summarise_conversations,\n",
        "        generate_base_clusters_from_conversation_summaries,\n",
        "        reduce_clusters_from_base_clusters,\n",
        "        reduce_dimensionality_from_clusters,\n",
        "    )\n",
        "from kura.summarisation import SummaryModel\n",
        "from kura.cluster import ClusterDescriptionModel\n",
        "from kura.meta_cluster import MetaClusterModel\n",
        "from kura.dimensionality import HDBUMAP\n",
        "\n",
        "\n",
        "async def analyze_conversations(conversations, checkpoint_manager):\n",
        "    \n",
        "    # Set up models\n",
        "    summary_model = SummaryModel()\n",
        "    cluster_model = ClusterDescriptionModel()\n",
        "    meta_cluster_model = MetaClusterModel()\n",
        "    dimensionality_model = HDBUMAP()\n",
        "\n",
        "    # Run pipeline steps\n",
        "    summaries = await summarise_conversations(\n",
        "        conversations, model=summary_model, checkpoint_manager=checkpoint_manager\n",
        "    )\n",
        "\n",
        "    clusters = await generate_base_clusters_from_conversation_summaries(\n",
        "        summaries, model=cluster_model, checkpoint_manager=checkpoint_manager\n",
        "    )\n",
        "\n",
        "    reduced_clusters = await reduce_clusters_from_base_clusters(\n",
        "        clusters, model=meta_cluster_model, checkpoint_manager=checkpoint_manager\n",
        "    )\n",
        "\n",
        "    projected = await reduce_dimensionality_from_clusters(\n",
        "        reduced_clusters,\n",
        "        model=dimensionality_model,\n",
        "        checkpoint_manager=checkpoint_manager,\n",
        "    )\n",
        "\n",
        "    return projected\n",
        "\n",
        "\n",
        "checkpoint_manager = JSONLCheckpointManager(CHECKPOINT_DIRECTORY, enabled=True)\n",
        "checkpoint_manager.save_checkpoint(\"conversations\", conversations)\n",
        "clusters = await analyze_conversations(\n",
        "    conversations, checkpoint_manager=checkpoint_manager\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the output, we can see the consolidation process happening in real-time. Kura starts with 56 base clusters, then gradually merges them through multiple rounds until we reach 9 final top-level clusters. Each merge combines similar topics while preserving the essential distinctions between different conversation types.\n",
        "\n",
        "Now, let's examine these top-level clusters to understand the main themes in our data. \n",
        "\n",
        "By looking at the cluster names, descriptions, and sizes, we can quickly identify what users are discussing most frequently and how these topics relate to each other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Optimize security and management for data in AWS</span> : Users sought to improve security by clarifying IAM roles \n",
              "specific to AWS SageMaker training and by exploring best practices for dataset versioning. They also aimed to \n",
              "enhance data storage management strategies while addressing privacy concerns. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">75</span>\n",
              "\n",
              "<span style=\"font-weight: bold\">Enhance data management and team collaboration</span> : Users requested assistance with data tracking, table manipulation \n",
              "techniques, and improving team collaboration and project management. They sought guidance on collaboration metrics,\n",
              "programming techniques, and best practices for managing project tasks effectively. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67</span>\n",
              "\n",
              "<span style=\"font-weight: bold\">Guide on secure API key practices</span> : The user researched different strategies for safely managing API keys, \n",
              "emphasizing best practices in authentication and configuration. Key discussions included the use of environment \n",
              "variables and cloud secrets managers to enhance security measures. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
              "\n",
              "<span style=\"font-weight: bold\">Streamline ML logging and visualization enhancements</span> : Users sought guidance on effectively integrating and \n",
              "utilizing Weights &amp; Biases for machine learning logging and data analysis. They requested best practices for \n",
              "optimizing logging techniques, automating processes, and customizing visualizations to enhance their projects. : \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">178</span>\n",
              "\n",
              "<span style=\"font-weight: bold\">Enhance machine learning performance and evaluation</span> : Users sought to improve machine learning models through \n",
              "hyperparameter optimization and logging metrics for accurate evaluations. They requested guidance on tools and \n",
              "libraries to assess model performance effectively. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span>\n",
              "\n",
              "<span style=\"font-weight: bold\">Guide me on machine learning and Markdown usage</span> : Users received assistance in utilizing Markdown effectively for \n",
              "reports and troubleshooting machine learning tools. They sought guidance on configurations, training runs, and \n",
              "artifact management across various contexts. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">84</span>\n",
              "\n",
              "<span style=\"font-weight: bold\">Manage and log machine learning experiments efficiently</span> : Users focused on effective management and logging of \n",
              "machine learning experiments. They discussed techniques and specific tools like WandB to optimize performance and \n",
              "tracking. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">123</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mOptimize security and management for data in AWS\u001b[0m : Users sought to improve security by clarifying IAM roles \n",
              "specific to AWS SageMaker training and by exploring best practices for dataset versioning. They also aimed to \n",
              "enhance data storage management strategies while addressing privacy concerns. : \u001b[1;36m75\u001b[0m\n",
              "\n",
              "\u001b[1mEnhance data management and team collaboration\u001b[0m : Users requested assistance with data tracking, table manipulation \n",
              "techniques, and improving team collaboration and project management. They sought guidance on collaboration metrics,\n",
              "programming techniques, and best practices for managing project tasks effectively. : \u001b[1;36m67\u001b[0m\n",
              "\n",
              "\u001b[1mGuide on secure API key practices\u001b[0m : The user researched different strategies for safely managing API keys, \n",
              "emphasizing best practices in authentication and configuration. Key discussions included the use of environment \n",
              "variables and cloud secrets managers to enhance security measures. : \u001b[1;36m5\u001b[0m\n",
              "\n",
              "\u001b[1mStreamline ML logging and visualization enhancements\u001b[0m : Users sought guidance on effectively integrating and \n",
              "utilizing Weights & Biases for machine learning logging and data analysis. They requested best practices for \n",
              "optimizing logging techniques, automating processes, and customizing visualizations to enhance their projects. : \n",
              "\u001b[1;36m178\u001b[0m\n",
              "\n",
              "\u001b[1mEnhance machine learning performance and evaluation\u001b[0m : Users sought to improve machine learning models through \n",
              "hyperparameter optimization and logging metrics for accurate evaluations. They requested guidance on tools and \n",
              "libraries to assess model performance effectively. : \u001b[1;36m28\u001b[0m\n",
              "\n",
              "\u001b[1mGuide me on machine learning and Markdown usage\u001b[0m : Users received assistance in utilizing Markdown effectively for \n",
              "reports and troubleshooting machine learning tools. They sought guidance on configurations, training runs, and \n",
              "artifact management across various contexts. : \u001b[1;36m84\u001b[0m\n",
              "\n",
              "\u001b[1mManage and log machine learning experiments efficiently\u001b[0m : Users focused on effective management and logging of \n",
              "machine learning experiments. They discussed techniques and specific tools like WandB to optimize performance and \n",
              "tracking. : \u001b[1;36m123\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get top-level clusters (those without parents)\n",
        "parent_clusters = [cluster for cluster in clusters if cluster.parent_id is None]\n",
        "\n",
        "# Format each cluster's info with name, description and number of chats\n",
        "formatted_clusters = []\n",
        "for cluster in parent_clusters:\n",
        "    cluster_info = (\n",
        "        f\"[bold]{cluster.name}[/bold] : {cluster.description} : {len(cluster.chat_ids)}\"\n",
        "    )\n",
        "    formatted_clusters.append(cluster_info)\n",
        "\n",
        "# Join with newlines and print\n",
        "print(\"\\n\\n\".join(formatted_clusters))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysing Our Results\n",
        "\n",
        "### Understanding Our Top-Level Clusters\n",
        "\n",
        "Looking at the seven top-level clusters generated by Kura, we can identify clear patterns in how users are interacting with the documentation.\n",
        "\n",
        "The three largest clusters account for 69% of all queries:\n",
        "1. **Streamline ML logging and visualization enhancements** (178 conversations) - Users seeking guidance on integrating W&B for logging and customizing visualizations\n",
        "2. **Manage and log machine learning experiments efficiently** (123 conversations) - Focus on experiment management and tracking using tools like WandB\n",
        "3. **Guide me on machine learning and Markdown usage** (84 conversations) - Assistance with Markdown reports and troubleshooting ML tools\n",
        "\n",
        "What's particularly notable is that **logging and experiment management dominate user concerns**. The top two clusters alone represent 54% of all queries (301 out of 560), both focusing on different aspects of experiment tracking and logging.\n",
        "\n",
        "Additional significant themes include:\n",
        "- **AWS integration and security** (75 conversations) - IAM roles, SageMaker training, and data storage\n",
        "- **Team collaboration and data management** (67 conversations) - Table manipulation, collaboration metrics, and project management\n",
        "- **Model performance optimization** (28 conversations) - Hyperparameter tuning and evaluation\n",
        "\n",
        "This clustering reveals that the majority of user questions center around **how to effectively use W&B for logging, tracking, and visualizing ML experiments**. Users are consistently trying to figure out how to properly integrate W&B into their workflows, optimize their logging strategies, and create meaningful visualizations of their results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analysing Our Summaries\n",
        "\n",
        "Let's now examine what are some of the summaries that were generated by Kura for our individual query document pairs. \n",
        "\n",
        "To do so, we'll read in the list of conversations that we started with and then find their corresponding summary. This will allows us to then evaluate how representative the conversation summary is of the individual conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The user is seeking guidance on tracking machine learning experiments using a specific tool, detailing the steps \n",
              "and providing pseudocode for implementation.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "The user is seeking guidance on tracking machine learning experiments using a specific tool, detailing the steps \n",
              "and providing pseudocode for implementation.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "User Query: experiment tracking\n",
              "Retrieved Information : ## Track Experiments\n",
              "### How it works\n",
              "Track a machine learning experiment with a few lines of code:\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Create a W&amp;B run.\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Store a dictionary of hyperparameters, such as learning rate or model type, into your configuration \n",
              "<span style=\"font-weight: bold\">(</span>`wandb.config`<span style=\"font-weight: bold\">)</span>.\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Log metrics <span style=\"font-weight: bold\">(</span>`<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.log</span><span style=\"font-weight: bold\">()</span>`<span style=\"font-weight: bold\">)</span> over time in a training loop, such as accuracy and loss.\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. Save outputs of a run, like the model weights or a table of predictions.  \n",
              "\n",
              "The proceeding pseudocode demonstrates a common W&amp;B Experiment tracking workflow:  \n",
              "\n",
              "```python showLineNumbers\n",
              "\n",
              "# <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Start a W&amp;B Run\n",
              "\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.init</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">entity</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">project</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"my-project-name\"</span><span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "# <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Save mode inputs and hyperparameters\n",
              "\n",
              "wandb.config.learning\\_rate = <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>\n",
              "\n",
              "# Import model and data\n",
              "\n",
              "model, dataloader = get\\<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_model</span><span style=\"font-weight: bold\">()</span>, get\\<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_data</span><span style=\"font-weight: bold\">()</span>\n",
              "\n",
              "# Model training code goes here\n",
              "\n",
              "# <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Log metrics over time to visualize performance\n",
              "\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.log</span><span style=\"font-weight: bold\">({</span><span style=\"color: #008000; text-decoration-color: #008000\">\"loss\"</span>: loss<span style=\"font-weight: bold\">})</span>\n",
              "\n",
              "# <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. Log an artifact to W&amp;B\n",
              "\n",
              "wandb.log\\<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_artifact</span><span style=\"font-weight: bold\">(</span>model<span style=\"font-weight: bold\">)</span>\n",
              "```\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "User Query: experiment tracking\n",
              "Retrieved Information : ## Track Experiments\n",
              "### How it works\n",
              "Track a machine learning experiment with a few lines of code:\n",
              "\u001b[1;36m1\u001b[0m. Create a W&B run.\n",
              "\u001b[1;36m2\u001b[0m. Store a dictionary of hyperparameters, such as learning rate or model type, into your configuration \n",
              "\u001b[1m(\u001b[0m`wandb.config`\u001b[1m)\u001b[0m.\n",
              "\u001b[1;36m3\u001b[0m. Log metrics \u001b[1m(\u001b[0m`\u001b[1;35mwandb.log\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m`\u001b[1m)\u001b[0m over time in a training loop, such as accuracy and loss.\n",
              "\u001b[1;36m4\u001b[0m. Save outputs of a run, like the model weights or a table of predictions.  \n",
              "\n",
              "The proceeding pseudocode demonstrates a common W&B Experiment tracking workflow:  \n",
              "\n",
              "```python showLineNumbers\n",
              "\n",
              "# \u001b[1;36m1\u001b[0m. Start a W&B Run\n",
              "\n",
              "\u001b[1;35mwandb.init\u001b[0m\u001b[1m(\u001b[0m\u001b[33mentity\u001b[0m=\u001b[32m\"\"\u001b[0m, \u001b[33mproject\u001b[0m=\u001b[32m\"my\u001b[0m\u001b[32m-project-name\"\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              "# \u001b[1;36m2\u001b[0m. Save mode inputs and hyperparameters\n",
              "\n",
              "wandb.config.learning\\_rate = \u001b[1;36m0.01\u001b[0m\n",
              "\n",
              "# Import model and data\n",
              "\n",
              "model, dataloader = get\\\u001b[1;35m_model\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m, get\\\u001b[1;35m_data\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              "# Model training code goes here\n",
              "\n",
              "# \u001b[1;36m3\u001b[0m. Log metrics over time to visualize performance\n",
              "\n",
              "\u001b[1;35mwandb.log\u001b[0m\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\u001b[32m\"loss\"\u001b[0m: loss\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              "# \u001b[1;36m4\u001b[0m. Log an artifact to W&B\n",
              "\n",
              "wandb.log\\\u001b[1;35m_artifact\u001b[0m\u001b[1m(\u001b[0mmodel\u001b[1m)\u001b[0m\n",
              "```\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Bayesian optimization is a hyperparameter tuning technique that uses a surrogate function for informed search, \n",
              "contrasting with grid and random search methods.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Bayesian optimization is a hyperparameter tuning technique that uses a surrogate function for informed search, \n",
              "contrasting with grid and random search methods.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "User Query: Bayesian optimization\n",
              "Retrieved Information : ## Methods for Automated Hyperparameter Optimization\n",
              "### Bayesian Optimization\n",
              "Bayesian optimization is a hyperparameter tuning technique that uses a surrogate function to determine the next set\n",
              "of hyperparameters to evaluate. In contrast to grid search and random search, Bayesian optimization is an informed \n",
              "search method.  \n",
              "\n",
              "### Inputs  \n",
              "\n",
              "* A set of hyperparameters you want to optimize\n",
              "* A continuous search space for each hyperparameter as a value range\n",
              "* A performance metric to optimize\n",
              "* Explicit number of runs: Because the search space is continuous, you must manually stop the search or define a \n",
              "maximum number of runs.  \n",
              "\n",
              "The differences in grid search are highlighted in bold above.  \n",
              "\n",
              "A popular way to implement Bayesian optimization in Python is to use BayesianOptimization from the \n",
              "<span style=\"font-weight: bold\">(</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/fmfn/BayesianOptimization)</span> library. Alternatively, as shown below, you can set up Bayesian \n",
              "optimization for hyperparameter tuning with W&amp;B.  \n",
              "\n",
              "### Steps  \n",
              "\n",
              "### Output  \n",
              "\n",
              "### Advantages  \n",
              "\n",
              "### Disadvantages\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "User Query: Bayesian optimization\n",
              "Retrieved Information : ## Methods for Automated Hyperparameter Optimization\n",
              "### Bayesian Optimization\n",
              "Bayesian optimization is a hyperparameter tuning technique that uses a surrogate function to determine the next set\n",
              "of hyperparameters to evaluate. In contrast to grid search and random search, Bayesian optimization is an informed \n",
              "search method.  \n",
              "\n",
              "### Inputs  \n",
              "\n",
              "* A set of hyperparameters you want to optimize\n",
              "* A continuous search space for each hyperparameter as a value range\n",
              "* A performance metric to optimize\n",
              "* Explicit number of runs: Because the search space is continuous, you must manually stop the search or define a \n",
              "maximum number of runs.  \n",
              "\n",
              "The differences in grid search are highlighted in bold above.  \n",
              "\n",
              "A popular way to implement Bayesian optimization in Python is to use BayesianOptimization from the \n",
              "\u001b[1m(\u001b[0m\u001b[4;94mhttps://github.com/fmfn/BayesianOptimization\u001b[0m\u001b[4;94m)\u001b[0m library. Alternatively, as shown below, you can set up Bayesian \n",
              "optimization for hyperparameter tuning with W&B.  \n",
              "\n",
              "### Steps  \n",
              "\n",
              "### Output  \n",
              "\n",
              "### Advantages  \n",
              "\n",
              "### Disadvantages\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The user seeks guidance on integrating a specific tool with a programming framework for tracking machine learning \n",
              "experiments. The conversation includes pseudocode for implementation steps.\n",
              "</pre>\n"
            ],
            "text/plain": [
              "The user seeks guidance on integrating a specific tool with a programming framework for tracking machine learning \n",
              "experiments. The conversation includes pseudocode for implementation steps.\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "User Query: How to integrate Weights &amp; Biases with PyTorch?\n",
              "Retrieved Information : ## 🔥 = W&amp;B ➕ PyTorch\n",
              "\n",
              "Use Weights &amp; Biases for machine learning experiment tracking, dataset versioning, and project collaboration.  \n",
              "\n",
              "## What this notebook covers:  \n",
              "\n",
              "We show you how to integrate Weights &amp; Biases with your PyTorch code to add experiment tracking to your pipeline.  \n",
              "\n",
              "## The resulting interactive W&amp;B dashboard will look like:  \n",
              "\n",
              "## In pseudocode, what we'll do is:  \n",
              "\n",
              "```\n",
              "# import the library\n",
              "import wandb\n",
              "\n",
              "# start a new experiment\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.init</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">project</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"new-sota-model\"</span><span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "# capture a dictionary of hyperparameters with config\n",
              "wandb.config = <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"learning\\_rate\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.001</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"epochs\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"batch\\_size\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span><span style=\"font-weight: bold\">}</span>\n",
              "\n",
              "# set up model and data\n",
              "model, dataloader = get\\<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_model</span><span style=\"font-weight: bold\">()</span>, get\\<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_data</span><span style=\"font-weight: bold\">()</span>\n",
              "\n",
              "# optional: track gradients\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.watch</span><span style=\"font-weight: bold\">(</span>model<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "for batch in dataloader:\n",
              "metrics = model.training\\<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_step</span><span style=\"font-weight: bold\">()</span>\n",
              "# log metrics inside your training loop to visualize model performance\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.log</span><span style=\"font-weight: bold\">(</span>metrics<span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "# optional: save model at the end\n",
              "model.to\\<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_onnx</span><span style=\"font-weight: bold\">()</span>\n",
              "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">wandb.save</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"model.onnx\"</span><span style=\"font-weight: bold\">)</span>\n",
              "\n",
              "```  \n",
              "\n",
              "## Follow along with a video tutorial!\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "User Query: How to integrate Weights & Biases with PyTorch?\n",
              "Retrieved Information : ## 🔥 = W&B ➕ PyTorch\n",
              "\n",
              "Use Weights & Biases for machine learning experiment tracking, dataset versioning, and project collaboration.  \n",
              "\n",
              "## What this notebook covers:  \n",
              "\n",
              "We show you how to integrate Weights & Biases with your PyTorch code to add experiment tracking to your pipeline.  \n",
              "\n",
              "## The resulting interactive W&B dashboard will look like:  \n",
              "\n",
              "## In pseudocode, what we'll do is:  \n",
              "\n",
              "```\n",
              "# import the library\n",
              "import wandb\n",
              "\n",
              "# start a new experiment\n",
              "\u001b[1;35mwandb.init\u001b[0m\u001b[1m(\u001b[0m\u001b[33mproject\u001b[0m=\u001b[32m\"new\u001b[0m\u001b[32m-sota-model\"\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              "# capture a dictionary of hyperparameters with config\n",
              "wandb.config = \u001b[1m{\u001b[0m\u001b[32m\"learning\\_rate\"\u001b[0m: \u001b[1;36m0.001\u001b[0m, \u001b[32m\"epochs\"\u001b[0m: \u001b[1;36m100\u001b[0m, \u001b[32m\"batch\\_size\"\u001b[0m: \u001b[1;36m128\u001b[0m\u001b[1m}\u001b[0m\n",
              "\n",
              "# set up model and data\n",
              "model, dataloader = get\\\u001b[1;35m_model\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m, get\\\u001b[1;35m_data\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              "# optional: track gradients\n",
              "\u001b[1;35mwandb.watch\u001b[0m\u001b[1m(\u001b[0mmodel\u001b[1m)\u001b[0m\n",
              "\n",
              "for batch in dataloader:\n",
              "metrics = model.training\\\u001b[1;35m_step\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "# log metrics inside your training loop to visualize model performance\n",
              "\u001b[1;35mwandb.log\u001b[0m\u001b[1m(\u001b[0mmetrics\u001b[1m)\u001b[0m\n",
              "\n",
              "# optional: save model at the end\n",
              "model.to\\\u001b[1;35m_onnx\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1;35mwandb.save\u001b[0m\u001b[1m(\u001b[0m\u001b[32m\"model.onnx\"\u001b[0m\u001b[1m)\u001b[0m\n",
              "\n",
              "```  \n",
              "\n",
              "## Follow along with a video tutorial!\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from kura.types import ConversationSummary\n",
        "from kura.checkpoints import JSONLCheckpointManager\n",
        "\n",
        "checkpoint_manager = JSONLCheckpointManager(CHECKPOINT_DIRECTORY, enabled=True)\n",
        "summaries = checkpoint_manager.load_checkpoint(\"summaries\", ConversationSummary)\n",
        "conversations = checkpoint_manager.load_checkpoint(\"conversations\", Conversation)\n",
        "\n",
        "\n",
        "id_to_conversation = {\n",
        "    conversation.chat_id: conversation for conversation in conversations\n",
        "}\n",
        "\n",
        "\n",
        "for i in range(3):\n",
        "    print(summaries[i].summary)\n",
        "    print(id_to_conversation[summaries[i].chat_id].messages[0].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "### What You Learned\n",
        "\n",
        "In this notebook, you discovered how to transform raw user queries into actionable insights for RAG system improvements. You learned to:\n",
        "\n",
        "- **Prepare query data for Kura** by formatting JSON data into Conversation objects with proper metadata\n",
        "- **Run hierarchical clustering** using Kura's built-in capabilities to group similar conversations\n",
        "- **Analyze clustering results** to identify the most common user query patterns and pain points\n",
        "\n",
        "### What We Accomplished\n",
        "\n",
        "By leveraging Kura's clustering capabilities, we organized 560 user queries into nine meaningful clusters that revealed clear patterns in how users interact with Weights & Biases documentation. The analysis showed that three major topics—experiment tracking, tool integration, and artifact management—account for over two-thirds of all queries, with artifact management appearing as a significant theme across multiple clusters (61% of conversations).\n",
        "\n",
        "However, we also identified critical limitations in the default summarization approach. Our generated summaries lacked specificity about the tools users wanted to use and sometimes included irrelevant context from retrieved documents. For example, summaries described queries as \"user seeks information about tracking\" rather than capturing the specific W&B features involved.\n",
        "\n",
        "### Next: Better Summaries\n",
        "\n",
        "While our clustering revealed valuable high-level patterns, the generic summaries limit our ability to understand specific user needs. In the next notebook, \"Better Summaries\", we'll address this limitation by building a custom summarization model that:\n",
        "\n",
        "- **Identifies specific W&B features** (Artifacts, Configs, Reports) mentioned in each query\n",
        "- **Captures precise user intent** rather than generic descriptions  \n",
        "- **Creates domain-specific summaries** tailored to W&B terminology and workflows\n",
        "\n",
        "By replacing vague summaries like \"user seeks information about tracking\" with precise descriptions like \"user is managing W&B Artifacts for model versioning\", we'll create clusters that better reflect real user needs and provide more targeted, actionable insights for system improvements."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
