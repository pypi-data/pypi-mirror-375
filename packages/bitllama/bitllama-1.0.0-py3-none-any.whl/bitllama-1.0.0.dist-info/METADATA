Metadata-Version: 2.1
Name: bitllama
Version: 1.0.0
Summary: Python SDK for BitLlama Protocol
Home-page: https://github.com/bitllama/bitllama
Author: BitLlama Team
Author-email: team@bitllama.ai
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.9
Description-Content-Type: text/markdown
Requires-Dist: web3 >=6.0.0
Requires-Dist: aiohttp >=3.9.0
Requires-Dist: asyncio >=3.4.3
Requires-Dist: pydantic >=2.0.0
Requires-Dist: eth-account >=0.10.0
Requires-Dist: python-dotenv >=1.0.0
Provides-Extra: dev
Requires-Dist: pytest >=7.4.0 ; extra == 'dev'
Requires-Dist: pytest-asyncio >=0.21.0 ; extra == 'dev'
Requires-Dist: pytest-cov >=4.1.0 ; extra == 'dev'
Requires-Dist: black >=23.0.0 ; extra == 'dev'
Requires-Dist: mypy >=1.5.0 ; extra == 'dev'
Requires-Dist: flake8 >=6.0.0 ; extra == 'dev'

# BitLlama Python SDK

<div align="center">
  <img src="../../assets/logo.png" alt="BitLlama Logo" width="150" height="150" />
  
  <h3>Official Python SDK for the BitLlama Protocol</h3>
  
  <img src="https://img.shields.io/pypi/v/bitllama.svg" />
  <img src="https://img.shields.io/badge/python-%3E%3D3.9-blue.svg" />
  <img src="https://img.shields.io/badge/license-MIT-green.svg" />
</div>

## Installation

```bash
pip install bitllama
```

## Quick Start

```python
from bitllama import BitLlama, MiningClient
import asyncio

async def main():
    # Initialize client
    client = BitLlama(
        coordinator_url="https://api.bitllama.ai",
        private_key="your_private_key",
        network="base-mainnet"
    )
    
    # Create inference request
    response = await client.i
    nference.create(
        model="llama3:70b",
        prompt="Explain quantum computing",
        max_tokens=500
    )
    print(response.text)

asyncio.run(main())
```

## Mining

```python
# Initialize mining client
miner = MiningClient(
    client=client,
    model_provider="ollama",
    model_name="llama3:70b"
)

# Start mining
await miner.start()

# Check status
status = await miner.get_status()
print(f"Jobs completed: {status.jobs_completed}")
print(f"Earnings: {status.total_earnings} BLMA")

# Stop mining
await miner.stop()
```

## Documentation

Full documentation available at [https://docs.bitllama.ai/python-sdk](https://docs.bitllama.ai/python-sdk)
