{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "uNlQH3at-_RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://huggingface.co/datasets/google/Synthetic-Persona-Chat/resolve/main/data/Synthetic-Persona-Chat_train.csv\"\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "cXsFg5B7_2Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fN5ZuNHF9ONa"
      },
      "outputs": [],
      "source": [
        "def fit_wave(arr):\n",
        "    \"\"\"\n",
        "    Mutate arr in-place to form a smooth sine wave pattern,\n",
        "    ending at arr[-1] and avoiding extreme scaling.\n",
        "    \"\"\"\n",
        "    arr = np.asarray(arr, dtype=float)\n",
        "    n = len(arr)\n",
        "    if n < 3:\n",
        "        return arr\n",
        "\n",
        "    final_val = arr[-1]\n",
        "\n",
        "    # 1. Create a base sine wave with consistent shape\n",
        "    x = np.linspace(0, np.pi, n)  # One half-wave\n",
        "    sine_wave = np.sin(x)\n",
        "\n",
        "    # 2. Scale to approximate original amplitude\n",
        "    mean_val = np.mean(arr[:-1])  # exclude last value for scaling\n",
        "    amp = (np.max(arr[:-1]) - np.min(arr[:-1])) / 2\n",
        "    if amp == 0:\n",
        "        amp = 1.0  # avoid flatline\n",
        "    scaled_wave = (sine_wave - 0.5) * 2 * amp + mean_val\n",
        "\n",
        "    # 3. Smoothly shift so that last value matches\n",
        "    delta = final_val - scaled_wave[-1]\n",
        "    ramp = np.linspace(0, delta, n)\n",
        "    adjusted_wave = scaled_wave + ramp\n",
        "\n",
        "    # 4. Mutate in-place\n",
        "    for i in range(n - 1):\n",
        "        arr[i] = adjusted_wave[i]\n",
        "    arr[-1] = final_val\n",
        "\n",
        "    return arr\n",
        "\n",
        "def generate_blurbs(df, n_samples=50000):\n",
        "    \"\"\"\n",
        "    Extracts short, cleaned text blurbs from the 'Best Generated Conversation' column.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): Input dataframe with a 'Best Generated Conversation' column.\n",
        "        n_samples (int): Number of blurbs to return.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: A list of blurbs (short text segments).\n",
        "    \"\"\"\n",
        "    all_blurbs = []\n",
        "\n",
        "    for convo in df[\"Best Generated Conversation\"].dropna():\n",
        "        # Split into sentences\n",
        "        sentences = re.split(r'[.?!]\\s+', convo.strip())\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence = sentence.strip().lower()\n",
        "\n",
        "            # Remove speaker labels like \"user 1: \"\n",
        "            sentence = re.sub(r\"user \\d+: ?\", \"\", sentence)\n",
        "\n",
        "            # Keep only blurbs with 3 to 256 words\n",
        "            words = sentence.split()\n",
        "            if 3 <= len(words) <= 256:\n",
        "                all_blurbs.append(\" \".join(words))\n",
        "\n",
        "    # If fewer than n_samples are found, return all\n",
        "    if len(all_blurbs) < n_samples:\n",
        "        print(f\"Only {len(all_blurbs)} blurbs found.\")\n",
        "        return all_blurbs\n",
        "\n",
        "    # Randomly sample\n",
        "    return random.sample(all_blurbs, n_samples)\n",
        "\n",
        "def tokenize_blurbs(df, n_samples=50000):\n",
        "    blurbs = generate_blurbs(df, n_samples)\n",
        "    tokenized_blurbs = []\n",
        "    vocab = set()\n",
        "\n",
        "    for blurb in blurbs:\n",
        "        tokens = re.findall(r'\\b\\w+\\b', blurb.lower())\n",
        "        if len(tokens) > 1:\n",
        "            tokenized_blurbs.append(tokens)\n",
        "            vocab.update(tokens)\n",
        "\n",
        "    return tokenized_blurbs, sorted(vocab)\n",
        "\n",
        "def build_training_pairs(tokenized_blurbs):\n",
        "    pairs = []\n",
        "    for tokens in tokenized_blurbs:\n",
        "        for i in range(len(tokens) - 1):\n",
        "            pairs.append((tokens[i], tokens[i + 1]))\n",
        "    return pairs\n",
        "\n",
        "def init_embeds(df, embed_dim=2):\n",
        "    all_text = (\n",
        "        df[\"user 1 personas\"].fillna('') + \" \" +\n",
        "        df[\"user 2 personas\"].fillna('') + \" \" +\n",
        "        df[\"Best Generated Conversation\"].fillna('')\n",
        "    )\n",
        "\n",
        "    def tokenize(text):\n",
        "        return re.findall(r'\\b\\w+\\b', text.lower())\n",
        "\n",
        "    unique_words = set()\n",
        "    for row in all_text:\n",
        "        unique_words.update(tokenize(row))\n",
        "\n",
        "    embedding_dict = {\n",
        "        word: np.random.uniform(-1, 1, size=embed_dim).tolist()\n",
        "        for word in unique_words\n",
        "    }\n",
        "    return embedding_dict\n",
        "\n",
        "def get_blurb_embedding_blob(blurb, embedding_dict):\n",
        "    \"\"\"\n",
        "    Given a blurb and an embedding dictionary, return the embedding blob.\n",
        "\n",
        "    Parameters:\n",
        "        blurb (str): The input text (a short sentence or phrase).\n",
        "        embedding_dict (dict): A dictionary mapping words to [float, float] vectors.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: A (n_words, 2) array of word embeddings.\n",
        "    \"\"\"\n",
        "    tokens = re.findall(r'\\b\\w+\\b', blurb.lower())\n",
        "    embeddings = []\n",
        "\n",
        "    for word in tokens:\n",
        "        if word in embedding_dict:\n",
        "            embeddings.append(embedding_dict[word])\n",
        "        else:\n",
        "            # If word not found, assign a zero vector\n",
        "            embeddings.append([0.0, 0.0])\n",
        "\n",
        "    return np.array(embeddings)\n",
        "\n",
        "def update_embedding_dict_with_wave(words, blob, embedding_dict):\n",
        "    blob = np.array(blob, dtype=float)\n",
        "    assert len(words) == blob.shape[0], \"Mismatch between words and blob rows.\"\n",
        "\n",
        "    for i in range(blob.shape[1]):\n",
        "        fit_wave(blob[:, i])\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "        embedding_dict[word] = blob[i].tolist()\n",
        "\n",
        "def try_fit_all_blurbs(df, max_dim=100, n_samples=50000, tolerance=1e-3):\n",
        "    blurbs = generate_blurbs(df, n_samples)\n",
        "    word_set = set()\n",
        "    for blurb in blurbs:\n",
        "        word_set.update(re.findall(r'\\b\\w+\\b', blurb.lower()))\n",
        "\n",
        "    # Track how many blurbs succeeded at each embedding dim\n",
        "    success_counts = []\n",
        "\n",
        "    for embed_dim in range(2, max_dim + 1):\n",
        "        print(f\"Trying embedding dimension: {embed_dim}\")\n",
        "        # Re-initialize embedding dict with this dimension\n",
        "        embedding_dict = {\n",
        "            word: np.random.uniform(-1, 1, size=embed_dim).tolist()\n",
        "            for word in word_set\n",
        "        }\n",
        "\n",
        "        success = 0\n",
        "        for blurb in blurbs:\n",
        "            tokens = re.findall(r'\\b\\w+\\b', blurb.lower())\n",
        "            blob = get_blurb_embedding_blob(blurb, embedding_dict)\n",
        "            original_blob = blob.copy()\n",
        "\n",
        "            # Try fitting wave to each column\n",
        "            try:\n",
        "                for i in range(blob.shape[1]):\n",
        "                    fit_wave(blob[:, i])\n",
        "\n",
        "                # Update dictionary\n",
        "                for i, word in enumerate(tokens):\n",
        "                    embedding_dict[word] = blob[i].tolist()\n",
        "\n",
        "                # Reconstruct and validate\n",
        "                reconstructed = get_blurb_embedding_blob(blurb, embedding_dict)\n",
        "                if np.allclose(original_blob, reconstructed, atol=tolerance):\n",
        "                    success += 1\n",
        "                else:\n",
        "                    raise ValueError(\"Embedding mismatch\")\n",
        "\n",
        "            except Exception as e:\n",
        "                continue  # Skip if any fitting or mismatch occurs\n",
        "\n",
        "        print(f\"Success at dim {embed_dim}: {success}/{len(blurbs)}\")\n",
        "        success_counts.append((embed_dim, success))\n",
        "\n",
        "        # If all blurbs succeed, stop early\n",
        "        if success == len(blurbs):\n",
        "            break\n",
        "\n",
        "    return success_counts\n",
        "\n",
        "def train_embeddings(pairs, vocab, dim, lr=0.01, epochs=10):\n",
        "    word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
        "    n_words = len(vocab)\n",
        "\n",
        "    # Embeddings: shape (vocab_size, dim)\n",
        "    E = np.random.randn(n_words, dim) * 0.1\n",
        "    W = np.random.randn(dim, dim) * 0.1  # Linear predictor\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        random.shuffle(pairs)\n",
        "\n",
        "        for w1, w2 in pairs:\n",
        "            i1, i2 = word_to_idx[w1], word_to_idx[w2]\n",
        "            e1, e2 = E[i1], E[i2]\n",
        "\n",
        "            pred = W @ e1\n",
        "            error = pred - e2\n",
        "            loss = np.sum(error ** 2)\n",
        "            total_loss += loss\n",
        "\n",
        "            # Backprop\n",
        "            grad_W = np.outer(error, e1)\n",
        "            grad_e1 = W.T @ error\n",
        "            grad_e2 = -error\n",
        "\n",
        "            W -= lr * grad_W\n",
        "            E[i1] -= lr * grad_e1\n",
        "            E[i2] -= lr * grad_e2  # Optional: allow e2 to adapt too\n",
        "\n",
        "        avg_loss = total_loss / len(pairs)\n",
        "        losses.append(avg_loss)\n",
        "\n",
        "    return E, W, losses[-1]\n",
        "\n",
        "def optimize_dimensionality(df, max_dim=100, n_samples=50000, epochs=10):\n",
        "    tokenized_blurbs, vocab = tokenize_blurbs(df, n_samples)\n",
        "    pairs = build_training_pairs(tokenized_blurbs)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for dim in range(2, max_dim + 1):\n",
        "        print(f\"Training with embedding dim = {dim}\")\n",
        "        _, _, final_loss = train_embeddings(pairs, vocab, dim, lr=0.01, epochs=epochs)\n",
        "        print(f\"  Final MSE Loss: {final_loss:.6f}\")\n",
        "        results.append((dim, final_loss))\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "E.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odRZgJVpaPez",
        "outputId": "518a173b-5df5-433a-c5e4-e1fa15f90732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3376, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "SIpQpCGSaZT9",
        "outputId": "ba3b5a13-2c77-4fa8-bb11-9cb19003345e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        user 1 personas  \\\n",
              "0     I am 32.\\nI do not want a job.\\nI play video g...   \n",
              "1     I am 32.\\nI play video games all day.\\nI still...   \n",
              "2     I am 32.\\nI play video games all day.\\nI still...   \n",
              "3     I write.\\nI work at mcdonald s.\\nI watch youtu...   \n",
              "4     I am bald.\\nI like to swim.\\nMy favorite drink...   \n",
              "...                                                 ...   \n",
              "8933  My parents used to work in politics , until th...   \n",
              "8934  My parents used to work in politics , until th...   \n",
              "8935  I went on welfare last month , which makes me ...   \n",
              "8936  I went on welfare last month , which makes me ...   \n",
              "8937  I went on welfare last month , which makes me ...   \n",
              "\n",
              "                                        user 2 personas  \\\n",
              "0     My favorite drink is iced coffee.\\nI have a bl...   \n",
              "1     I have a ford f150.\\nI like ford cars.\\nMy tru...   \n",
              "2     I can recite the movie young frankenstein word...   \n",
              "3     I want to move.\\nI don t like feeling controll...   \n",
              "4     My favorite store is american eagle.\\nI enjoy ...   \n",
              "...                                                 ...   \n",
              "8933  I am in a very intimate and loving relationshi...   \n",
              "8934  My mind is set on things above.\\nI hate evil.\\...   \n",
              "8935  I got married last year.\\nI am a hair stylist....   \n",
              "8936  I wish i made more money.\\nI have a strange ob...   \n",
              "8937  I enjoy reading history books.\\nI love to danc...   \n",
              "\n",
              "                            Best Generated Conversation  \n",
              "0     User 1: Hi! I'm [user 1's name].\\nUser 2: Hi [...  \n",
              "1     User 1: Hey, how's it going?\\nUser 2: Good, I'...  \n",
              "2     User 1: Hi, my name is John. What's your name?...  \n",
              "3     User 1: Hi!\\nUser 2: Hey!\\nUser 1: What's up?\\...  \n",
              "4     User 1: Hello!\\nUser 2: Hi!\\nUser 1: What do y...  \n",
              "...                                                 ...  \n",
              "8933  User 1: Hey, what's up?\\nUser 2: Not much, jus...  \n",
              "8934  User 1: Hey!\\nUser 2: Hello!\\nUser 1: What do ...  \n",
              "8935  User 1: Hey, I'm [name].\\nUser 2: Hi, I'm [nam...  \n",
              "8936  User 1: Hi, I'm [user 1].\\n\\nUser 2: Hi, I'm [...  \n",
              "8937  User 1: Hello!\\nUser 2: Hello! How are you doi...  \n",
              "\n",
              "[8938 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b417fed-372b-4760-ab80-1ac68c2602c0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user 1 personas</th>\n",
              "      <th>user 2 personas</th>\n",
              "      <th>Best Generated Conversation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am 32.\\nI do not want a job.\\nI play video g...</td>\n",
              "      <td>My favorite drink is iced coffee.\\nI have a bl...</td>\n",
              "      <td>User 1: Hi! I'm [user 1's name].\\nUser 2: Hi [...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I am 32.\\nI play video games all day.\\nI still...</td>\n",
              "      <td>I have a ford f150.\\nI like ford cars.\\nMy tru...</td>\n",
              "      <td>User 1: Hey, how's it going?\\nUser 2: Good, I'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I am 32.\\nI play video games all day.\\nI still...</td>\n",
              "      <td>I can recite the movie young frankenstein word...</td>\n",
              "      <td>User 1: Hi, my name is John. What's your name?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I write.\\nI work at mcdonald s.\\nI watch youtu...</td>\n",
              "      <td>I want to move.\\nI don t like feeling controll...</td>\n",
              "      <td>User 1: Hi!\\nUser 2: Hey!\\nUser 1: What's up?\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I am bald.\\nI like to swim.\\nMy favorite drink...</td>\n",
              "      <td>My favorite store is american eagle.\\nI enjoy ...</td>\n",
              "      <td>User 1: Hello!\\nUser 2: Hi!\\nUser 1: What do y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8933</th>\n",
              "      <td>My parents used to work in politics , until th...</td>\n",
              "      <td>I am in a very intimate and loving relationshi...</td>\n",
              "      <td>User 1: Hey, what's up?\\nUser 2: Not much, jus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8934</th>\n",
              "      <td>My parents used to work in politics , until th...</td>\n",
              "      <td>My mind is set on things above.\\nI hate evil.\\...</td>\n",
              "      <td>User 1: Hey!\\nUser 2: Hello!\\nUser 1: What do ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8935</th>\n",
              "      <td>I went on welfare last month , which makes me ...</td>\n",
              "      <td>I got married last year.\\nI am a hair stylist....</td>\n",
              "      <td>User 1: Hey, I'm [name].\\nUser 2: Hi, I'm [nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8936</th>\n",
              "      <td>I went on welfare last month , which makes me ...</td>\n",
              "      <td>I wish i made more money.\\nI have a strange ob...</td>\n",
              "      <td>User 1: Hi, I'm [user 1].\\n\\nUser 2: Hi, I'm [...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8937</th>\n",
              "      <td>I went on welfare last month , which makes me ...</td>\n",
              "      <td>I enjoy reading history books.\\nI love to danc...</td>\n",
              "      <td>User 1: Hello!\\nUser 2: Hello! How are you doi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8938 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b417fed-372b-4760-ab80-1ac68c2602c0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9b417fed-372b-4760-ab80-1ac68c2602c0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9b417fed-372b-4760-ab80-1ac68c2602c0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-14fe35ed-a038-4d11-801d-2559d1b163fd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-14fe35ed-a038-4d11-801d-2559d1b163fd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-14fe35ed-a038-4d11-801d-2559d1b163fd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_c93a146d-f1f8-418c-bc5b-45dab2a7fff0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c93a146d-f1f8-418c-bc5b-45dab2a7fff0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8938,\n  \"fields\": [\n    {\n      \"column\": \"user 1 personas\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8773,\n        \"samples\": [\n          \"I like to play video games.\\nI am a scientist.\\nI am an amateur chef who cooks 5 different cuisines.\\nI live alone.\",\n          \"I live in colorado.\\nI own my home.\\nMy car is blue.\\nI am married.\\nI have an mba degree.\",\n          \"I am fascinated with ghosts.\\nI love 80 s music.\\nI m a wedding planner.\\nMy favorite color is yellow.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user 2 personas\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8783,\n        \"samples\": [\n          \"I live in ahuge mansion.\\nI went to college in maryland.\\nI make 35 million a year.\\nI play for the washington wizards.\\nI am a professional basketball player.\",\n          \"I am a michigan state trooper.\\nI have two siberian huskies.\\nI love chocolate cake with extra frosting.\\nI play guitar.\\nI have four daughters.\",\n          \"I enjoy playing with edged weapons.\\nI like watching videos of surgery.\\nTraveling and making friends is something i find delightful.\\nBritney spears is a wonderful singer who really touches me.\\nMy favorite ice cream is pistachio.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Best Generated Conversation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8938,\n        \"samples\": [\n          \"User 1: Hello, what is your name?\\nUser 2: Hello, my name is John.\\nUser 1: It is nice to meet you, John. What do you do for fun?\\nUser 2: I enjoy reading and spending time in the library.\\nUser 1: Me too! I love reading. What kind of books do you like to read?\\nUser 2: I like to read anything that is interesting, but I especially enjoy science fiction and fantasy novels.\\nUser 1: I love those genres too! I also enjoy reading nonfiction.\\nUser 2: That's great! What are some of your favorite books?\\nUser 1: I have a lot of favorite books, but some of my favorites include The Lord of the Rings, Dune, and Ender's Game.\\nUser 2: Those are all great books! I have read all of them.\\nUser 1: Me too! I love them all.\\nUser 2: What are you currently reading?\\nUser 1: I am currently reading a book called The Three-Body Problem.\\nUser 2: I have heard good things about that book.\\nUser 1: It is a very good book. I am enjoying it a lot.\\nUser 2: I am glad to hear that.\\nUser 1: What are you currently working on?\\nUser 2: I am currently working as a freelance accountant.\\nUser 1: That sounds interesting.\\nUser 2: It is. I enjoy it a lot.\\nUser 1: I am glad to hear that.\\nUser 2: Thank you.\\nUser 1: What do you like to do in your free time?\\nUser 2: In my free time, I enjoy spending time with my family, reading, and playing video games.\\nUser 1: That sounds like a lot of fun.\\nUser 2: It is.\\nUser 1: What are your plans for the future?\\nUser 2: I am not sure yet. I am just enjoying my life for now.\\nUser 1: That is a good plan.\\nUser 2: Thank you.\\nUser 1: It was nice meeting you, John.\\nUser 2: It was nice meeting you too, Jane.\",\n          \"User 1: Hello!\\nUser 2: Hello there!\\nUser 1: I'm [user 1's name].\\nUser 2: It's nice to meet you, [user 1's name]. I'm [user 2's name].\\nUser 1: What do you do for a living?\\nUser 2: I'm a hair stylist and I own my own salon.\\nUser 1: That's so cool! I've always wanted to be a hair stylist.\\nUser 2: It's a lot of fun, but it can be challenging at times.\\nUser 1: I can imagine. What's the hardest part?\\nUser 2: The hardest part is dealing with all the different kinds of people.\\nUser 1: I can see how that would be difficult.\\nUser 2: Yeah, but it's also really rewarding.\\nUser 1: I'm sure it is.\\nUser 2: So, what do you do for a living?\\nUser 1: I'm a stay at home mom.\\nUser 2: Oh, that must be really rewarding.\\nUser 1: It is. I love being with my kids and watching them grow up.\\nUser 2: That's great.\\nUser 1: What are your hobbies?\\nUser 2: I love to read, go to the movies, and spend time with my husband.\\nUser 1: Those are all great hobbies.\\nUser 2: Thanks. What are your hobbies?\\nUser 1: I love to read, go for walks, and watch movies.\\nUser 2: Those are all great hobbies.\\nUser 1: Thanks.\\nUser 2: So, what do you think of my salon?\\nUser 1: It's really nice! You did a great job with it.\\nUser 2: Thanks! I'm really proud of it.\\nUser 1: It looks like you have a lot of happy clients.\\nUser 2: Yeah, I do. I love making people feel good about themselves.\\nUser 1: That's great. I think you're doing a wonderful job.\\nUser 2: Thank you. That means a lot.\",\n          \"User 1: I'm from Russia too!\\nUser 2: Oh really? What part of Russia are you from?\\nUser 1: I'm from Moscow.\\nUser 2: That's cool! I've always wanted to go to Russia.\\nUser 1: You should! It's a beautiful country.\\nUser 2: Maybe I will someday.\\nUser 1: So, what do you do for a living?\\nUser 2: I'm a farmer.\\nUser 1: That's cool! I've always thought that would be a fun job.\\nUser 2: It is. I love working outdoors.\\nUser 1: Me too. I love going for walks in the woods.\\nUser 2: Do you have any pets?\\nUser 1: Yeah, I have a dog.\\nUser 2: What kind of dog?\\nUser 1: He's a golden retriever.\\nUser 2: Golden retrievers are so cute!\\nUser 1: They are! He's my best friend.\\nUser 2: So, what kind of music do you like?\\nUser 1: I like all kinds of music, but my favorite is rock.\\nUser 2: Me too! What are some of your favorite bands?\\nUser 1: I like the Beatles, the Rolling Stones, and Nirvana.\\nUser 2: Nice! I love the Beatles and the Rolling Stones. I haven't really listened to Nirvana much, but I've heard good things about them.\\nUser 1: You should check them out! They're one of my favorite bands.\\nUser 2: I will.\\nUser 1: So, what do you like to do for fun?\\nUser 2: I like to go hiking, photography, and fishing.\\nUser 1: That sounds like a lot of fun. I like hiking and photography too.\\nUser 2: We should go hiking together sometime.\\nUser 1: That would be fun!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = optimize_dimensionality(df, max_dim=50, n_samples=10000, epochs=5)\n",
        "for dim, loss in results:\n",
        "    print(f\"Dim {dim}: MSE loss = {loss:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "k0pfeDXhFTC3",
        "outputId": "5c107b7c-e4eb-474e-b0d4-6ee5d4dbecaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with embedding dim = 2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-753370631.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize_dimensionality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dim {dim}: MSE loss = {loss:.5f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-713399547.py\u001b[0m in \u001b[0;36moptimize_dimensionality\u001b[0;34m(df, max_dim, n_samples, epochs)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_dim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training with embedding dim = {dim}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Final MSE Loss: {final_loss:.6f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-713399547.py\u001b[0m in \u001b[0;36mtrain_embeddings\u001b[0;34m(pairs, vocab, dim, lr, epochs)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mW\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad_W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad_e1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad_e2\u001b[0m  \u001b[0;31m# Optional: allow e2 to adapt too\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blurbs = generate_blurbs(df)\n",
        "embedding_dict = init_embeds(df)\n",
        "\n",
        "blurb = blurbs[-1]\n",
        "tokens = re.findall(r'\\b\\w+\\b', blurb.lower())\n",
        "blob = get_blurb_embedding_blob(blurb, embedding_dict)\n",
        "\n",
        "update_embedding_dict_with_wave(tokens, blob, embedding_dict)\n",
        "blob2 = get_blurb_embedding_blob(blurb, embedding_dict)"
      ],
      "metadata": {
        "id": "Cx4aosG6CC-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([x[0] for x in blob])"
      ],
      "metadata": {
        "id": "e5ymkmgdDIh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([x[0] for x in blob2])"
      ],
      "metadata": {
        "id": "RpmttDlcEaUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blob"
      ],
      "metadata": {
        "id": "FjL2IbAMCJMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([1,2,1,0,3,5])"
      ],
      "metadata": {
        "id": "id1SuwQA-4Ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(arr)"
      ],
      "metadata": {
        "id": "KnB8Zstb_BRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(fit_wave(arr))"
      ],
      "metadata": {
        "id": "XsRcwcn-_CFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_split_blurbs(df, n_samples=50000, test_ratio=0.2):\n",
        "    blurbs = generate_blurbs(df, n_samples)\n",
        "    tokenized = []\n",
        "    vocab = set()\n",
        "\n",
        "    for blurb in blurbs:\n",
        "        tokens = re.findall(r'\\b\\w+\\b', blurb.lower())\n",
        "        if len(tokens) > 1:\n",
        "            tokenized.append(tokens)\n",
        "            vocab.update(tokens)\n",
        "\n",
        "    # Shuffle and split\n",
        "    random.shuffle(tokenized)\n",
        "    split = int(len(tokenized) * (1 - test_ratio))\n",
        "    train_blurbs = tokenized[:split]\n",
        "    test_blurbs = tokenized[split:]\n",
        "\n",
        "    return train_blurbs, test_blurbs, sorted(vocab)\n",
        "\n",
        "def build_pairs(tokenized_blurbs):\n",
        "    pairs = []\n",
        "    for tokens in tokenized_blurbs:\n",
        "        for i in range(len(tokens) - 1):\n",
        "            pairs.append((tokens[i], tokens[i + 1]))\n",
        "    return pairs\n",
        "def train_embeddings(pairs, vocab, dim, lr=0.01, epochs=10):\n",
        "    word_to_idx = {w: i for i, w in enumerate(vocab)}\n",
        "    E = np.random.randn(len(vocab), dim) * 0.1\n",
        "    W = np.random.randn(dim, dim) * 0.1\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        random.shuffle(pairs)\n",
        "        total_loss = 0\n",
        "\n",
        "        for w1, w2 in pairs:\n",
        "            i1, i2 = word_to_idx[w1], word_to_idx[w2]\n",
        "            e1, e2 = E[i1], E[i2]\n",
        "\n",
        "            pred = W @ e1\n",
        "            error = pred - e2\n",
        "            loss = np.sum(error ** 2)\n",
        "            total_loss += loss\n",
        "\n",
        "            # Backprop\n",
        "            W -= lr * np.outer(error, e1)\n",
        "            E[i1] -= lr * (W.T @ error)\n",
        "            E[i2] -= lr * (-error)  # allow target to adjust (optional)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Loss = {total_loss / len(pairs):.6f}\")\n",
        "\n",
        "    return E, W, word_to_idx\n",
        "def evaluate_embeddings(test_pairs, E, W, word_to_idx):\n",
        "    errors = []\n",
        "\n",
        "    for w1, w2 in test_pairs:\n",
        "        if w1 not in word_to_idx or w2 not in word_to_idx:\n",
        "            continue\n",
        "        i1, i2 = word_to_idx[w1], word_to_idx[w2]\n",
        "        pred = W @ E[i1]\n",
        "        true = E[i2]\n",
        "        mse = np.mean((pred - true) ** 2)\n",
        "        errors.append(mse)\n",
        "\n",
        "    avg_mse = np.mean(errors)\n",
        "    print(f\"\\nTest MSE: {avg_mse:.6f}\")\n",
        "    return avg_mse\n"
      ],
      "metadata": {
        "id": "7lypQqSz_LTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_blurbs, test_blurbs, vocab = tokenize_and_split_blurbs(df, n_samples=10000)\n",
        "train_pairs = build_pairs(train_blurbs)\n",
        "test_pairs = build_pairs(test_blurbs)\n",
        "\n",
        "dim = 1024\n",
        "E, W, word_to_idx = train_embeddings(train_pairs, vocab, dim, lr=0.01, epochs=100)\n",
        "\n",
        "test_loss = evaluate_embeddings(test_pairs, E, W, word_to_idx)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "9n2mvFDyy-d7",
        "outputId": "772cfdb0-dd8c-4f3e-a8f1-9d257a5f3956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2810613678.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-273497546.py\u001b[0m in \u001b[0;36mtrain_embeddings\u001b[0;34m(pairs, vocab, dim, lr, epochs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# Backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mW\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# allow target to adjust (optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/numeric.py\u001b[0m in \u001b[0;36mouter\u001b[0;34m(a, b, out)\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_embeddings_with_growing_sequence_length(\n",
        "    tokenized_blurbs,\n",
        "    vocab,\n",
        "    dim,\n",
        "    lr=0.01,\n",
        "    epochs=10,\n",
        "    min_len=5,\n",
        "    max_len=256,\n",
        "):\n",
        "    word_to_idx = {w: i for i, w in enumerate(vocab)}\n",
        "    E = np.random.randn(len(vocab), dim) * 0.1\n",
        "    W = np.random.randn(dim, dim) * 0.1\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Linearly increase max allowed blurb length\n",
        "        curr_max_len = int(min_len + (max_len - min_len) * (epoch / (epochs - 1)))\n",
        "\n",
        "        # Generate new training pairs for this epoch\n",
        "        pairs = []\n",
        "        for tokens in tokenized_blurbs:\n",
        "            if 2 <= len(tokens) <= curr_max_len:\n",
        "                for i in range(len(tokens) - 1):\n",
        "                    pairs.append((tokens[i], tokens[i + 1]))\n",
        "\n",
        "        random.shuffle(pairs)\n",
        "        total_loss = 0\n",
        "\n",
        "        for w1, w2 in pairs:\n",
        "            i1, i2 = word_to_idx[w1], word_to_idx[w2]\n",
        "            e1, e2 = E[i1], E[i2]\n",
        "\n",
        "            pred = W @ e1\n",
        "            error = pred - e2\n",
        "            loss = np.sum(error ** 2)\n",
        "            total_loss += loss\n",
        "\n",
        "            # Backprop\n",
        "            W -= lr * np.outer(error, e1)\n",
        "            E[i1] -= lr * (W.T @ error)\n",
        "            E[i2] -= lr * (-error)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Max len: {curr_max_len:3d} | Loss: {total_loss / len(pairs):.6f}\")\n",
        "\n",
        "    return E, W, word_to_idx\n"
      ],
      "metadata": {
        "id": "Y3z_tMtc0y9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_blurbs, test_blurbs, vocab = tokenize_and_split_blurbs(df, n_samples=10000)\n",
        "E, W, word_to_idx = train_embeddings_with_growing_sequence_length(\n",
        "    train_blurbs,\n",
        "    vocab,\n",
        "    dim=100,\n",
        "    lr=0.1,\n",
        "    epochs=10,\n",
        "    min_len=5,\n",
        "    max_len=256,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN_CN7Vmy_1F",
        "outputId": "45e0a57b-8772-4f24-86c4-9087fc666024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Max len:   5 | Loss: 0.243257\n",
            "Epoch 2/10 | Max len:  32 | Loss: 0.102546\n",
            "Epoch 3/10 | Max len:  60 | Loss: 0.046788\n",
            "Epoch 4/10 | Max len:  88 | Loss: 0.030427\n",
            "Epoch 5/10 | Max len: 116 | Loss: 0.021531\n",
            "Epoch 6/10 | Max len: 144 | Loss: 0.015909\n",
            "Epoch 7/10 | Max len: 172 | Loss: 0.012071\n",
            "Epoch 8/10 | Max len: 200 | Loss: 0.009321\n",
            "Epoch 9/10 | Max len: 228 | Loss: 0.007287\n",
            "Epoch 10/10 | Max len: 256 | Loss: 0.005748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pairs = build_pairs(test_blurbs)\n",
        "test_loss = evaluate_embeddings(test_pairs, E, W, word_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw4mdXCP02BV",
        "outputId": "54d6631e-56fa-4332-ecc4-3718790059a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test MSE: 0.000408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "E[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-JidYC21d9g",
        "outputId": "a9d1e7f8-d830-4ccb-9514-a11d3bc1d85d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.00753075,  0.0008178 , -0.00765929, -0.00109687,  0.00959058,\n",
              "       -0.0064074 , -0.00690113, -0.00745902,  0.00530447,  0.00244912,\n",
              "       -0.00290777, -0.00750715, -0.0067005 ,  0.00427543,  0.00366942,\n",
              "       -0.00541915,  0.00667741,  0.00031248, -0.00304764, -0.01040911,\n",
              "        0.00902738,  0.0128635 , -0.00966763,  0.00699592,  0.01205744,\n",
              "       -0.00019397,  0.00601374, -0.00176726, -0.00910873, -0.00527945,\n",
              "        0.00240791,  0.0117975 , -0.0043702 , -0.00461084,  0.00167314,\n",
              "        0.00524811,  0.00700562,  0.00505662,  0.00815436, -0.00964976,\n",
              "       -0.00113658,  0.00117697, -0.00255734, -0.0106756 , -0.01034122,\n",
              "       -0.00712607, -0.00658268,  0.00892598,  0.00711222,  0.00806651,\n",
              "        0.00290419,  0.00255786,  0.00865908, -0.00545585, -0.00017807,\n",
              "       -0.00295799, -0.0106818 , -0.01397543, -0.00423442,  0.00098638,\n",
              "        0.00211673, -0.00299921, -0.00784722,  0.00633694,  0.00743063,\n",
              "       -0.01327763, -0.00838752, -0.00932254, -0.01048124, -0.00698349,\n",
              "       -0.00422858, -0.00140937,  0.00752565, -0.00557151,  0.00299757,\n",
              "       -0.00117052,  0.00876903,  0.001747  ,  0.00675792, -0.00273959,\n",
              "       -0.00416246,  0.00073527,  0.01783663, -0.00275163, -0.00771785,\n",
              "       -0.00236249,  0.00732875,  0.00682615,  0.00092314, -0.00057702,\n",
              "       -0.003108  ,  0.01119756,  0.00334172,  0.00571346, -0.00526423,\n",
              "        0.00162693,  0.00840784, -0.00903216, -0.00476243, -0.00109032])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uG2OOlL_2cy2",
        "outputId": "cc89d101-d391-49d5-ba03-ee5250c57d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3361"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_context_sum_embeddings(tokenized_blurbs, vocab, dim=100, lr=0.01, epochs=10):\n",
        "    word_to_idx = {w: i for i, w in enumerate(vocab)}\n",
        "    E = np.random.uniform(-1, 1, size=(len(vocab), dim))\n",
        "    W = np.random.randn(dim, dim) * 0.1  # Linear projection from context to prediction\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        count = 0\n",
        "\n",
        "        for tokens in tokenized_blurbs:\n",
        "            if len(tokens) < 3:\n",
        "                continue\n",
        "\n",
        "            idxs = [word_to_idx[t] for t in tokens if t in word_to_idx]\n",
        "            for t in range(1, len(idxs) - 1):\n",
        "                # Context sum (scaled)\n",
        "                context_vec = np.sum(E[idxs[:t]], axis=0)\n",
        "                context_vec *= 1 / np.sqrt(t)\n",
        "\n",
        "                # Prediction target\n",
        "                target_idx = idxs[t]\n",
        "                target_vec = E[target_idx]\n",
        "\n",
        "                # Predict and compute loss\n",
        "                pred = W @ context_vec\n",
        "                error = pred - target_vec\n",
        "                loss = np.sum(error**2)\n",
        "                total_loss += loss\n",
        "                count += 1\n",
        "\n",
        "                # Backpropagation\n",
        "                grad_W = np.outer(error, context_vec)\n",
        "                grad_context = W.T @ error\n",
        "\n",
        "                W -= lr * grad_W\n",
        "                # Distribute gradient back to all context embeddings\n",
        "                grad_per_token = grad_context * (1 / np.sqrt(t))\n",
        "                for i in idxs[:t]:\n",
        "                    E[i] -= lr * grad_per_token\n",
        "                E[target_idx] -= lr * (-error)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Avg Loss: {total_loss / count:.6f}\")\n",
        "\n",
        "    return E, W, word_to_idx\n"
      ],
      "metadata": {
        "id": "uPtL9eIhXB7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_blurbs, vocab = tokenize_blurbs(df, n_samples=10000)\n",
        "E, W, word_to_idx = train_context_sum_embeddings(tokenized_blurbs, vocab, dim=100, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2xgyMy5YKqB",
        "outputId": "7f1917c7-7252-4d49-d3cc-b5ee3cc27cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Avg Loss: 9.761951\n",
            "Epoch 2/10 | Avg Loss: 4.867360\n",
            "Epoch 3/10 | Avg Loss: 3.758375\n",
            "Epoch 4/10 | Avg Loss: 3.152309\n",
            "Epoch 5/10 | Avg Loss: 2.748661\n",
            "Epoch 6/10 | Avg Loss: 2.452607\n",
            "Epoch 7/10 | Avg Loss: 2.222463\n",
            "Epoch 8/10 | Avg Loss: 2.036399\n",
            "Epoch 9/10 | Avg Loss: 1.881647\n",
            "Epoch 10/10 | Avg Loss: 1.750146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from prophet import Prophet\n",
        "\n",
        "model = Prophet()\n",
        "model.add_regressor('marketing_spend')  # optional\n",
        "model.fit(df_prophet)\n",
        "\n",
        "forecast = model.predict(future)\n"
      ],
      "metadata": {
        "id": "KB2IEnSZYMtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9r_M7ipFbLoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from prophet import Prophet\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from collections import defaultdict\n"
      ],
      "metadata": {
        "id": "x_ujh7-GbK-M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}