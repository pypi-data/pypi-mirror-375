Metadata-Version: 2.4
Name: llama-index-llms-azure-inference
Version: 0.5.1
Summary: Integration for model supporting Azure AI model inference API in llama-index
Author-email: Azure AI model inference group <azureml-inference@microsoft.com>
License-Expression: MIT
License-File: LICENSE
Requires-Python: <4.0,>=3.9
Requires-Dist: aiohttp<4,>=3.10.0
Requires-Dist: azure-ai-inference>=1.0.0b5
Requires-Dist: azure-identity<2,>=1.15.0
Requires-Dist: llama-index-core<0.15,>=0.13.0
Description-Content-Type: text/markdown

# LlamaIndex LLMs Integration: Azure AI model inference

The integration package `llama-index-llms-azure-inference` brings support for language models deployed in Azure AI, including Azure AI studio and Azure Machine Learning, to the `llama_index` ecosystem. Any model endpoint supporting the [Azure AI model inference API](https://aka.ms/azureai/modelinference) can be used with this integration.

For details and examples about how to use this integration, see [Getting starting with LlamaIndex and Azure AI](https://aka.ms/azureai/llamaindex).

## Changelog

- **0.2.4**:

  - Introduce `api_version` parameter in the `AzureAICompletionsModel` class to allow overriding of the default value.
  - Introduce support for [Azure AI model inference service](https://aka.ms/aiservices/infernece) which requires `azure-ai-inference>=1.0.0b5`.
