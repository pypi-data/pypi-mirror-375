use pyo3::prelude::*;
use pyo3::types::PyList;
use std::collections::HashSet;
use std::fs::{File, OpenOptions};
use std::io::{self,Read, Write};
use std::path::Path;
use memmap2::{Mmap, MmapMut};
use std::process::{Command, Stdio};
use std::thread;
use crossbeam::channel::{unbounded, Receiver, Sender};
use serde::{Deserialize, Serialize};
use std::env;
use rayon::prelude::*;
use std::sync::Arc;
use std::time::{Duration, Instant};
use std::sync::atomic::{AtomicBool, Ordering};
use chrono::Local;
use std::sync::Mutex;
use std::collections::HashMap;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskParam {
    pub date: i64,
    pub code: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TaskResult {
    pub date: i64,
    pub code: String,
    pub timestamp: i64,
    pub facs: Vec<f64>,
}

// æ—§çš„æ‰¹å¤„ç†ç»“æ„ä½“å·²åˆ é™¤ï¼Œåªä¿ç•™å•ä»»åŠ¡ç»“æ„ä½“

#[derive(Debug, Serialize, Deserialize)]
struct SingleTask {
    python_code: String,
    task: TaskParam,
    expected_result_length: usize,
}

// æ–°å¢ï¼šWorkerç›‘æ§ä¿¡æ¯
#[derive(Debug, Clone)]
#[allow(dead_code)]
struct WorkerMonitor {
    worker_id: usize,
    last_heartbeat: Instant,
    current_task: Option<TaskParam>,
    task_start_time: Option<Instant>,
    is_alive: bool,
    consecutive_failures: u32,
    process_id: Option<u32>,  // å­è¿›ç¨‹IDï¼Œç”¨äºè¿›ç¨‹å­˜æ´»æ£€æµ‹
}

impl WorkerMonitor {
    fn new(worker_id: usize) -> Self {
        Self {
            worker_id,
            last_heartbeat: Instant::now(),
            current_task: None,
            task_start_time: None,
            is_alive: true,
            consecutive_failures: 0,
            process_id: None,
        }
    }
    
    fn start_task(&mut self, task: TaskParam) {
        self.current_task = Some(task);
        self.task_start_time = Some(Instant::now());
    }
    
    fn finish_task(&mut self) {
        self.current_task = None;
        self.task_start_time = None;
        self.consecutive_failures = 0;  // é‡ç½®å¤±è´¥è®¡æ•°
    }
    
    fn update_heartbeat(&mut self) {
        self.last_heartbeat = Instant::now();
        self.is_alive = true;
    }
    
    fn set_process_id(&mut self, pid: u32) {
        self.process_id = Some(pid);
    }
    
    fn is_process_alive(&self) -> bool {
        if let Some(pid) = self.process_id {
            // åœ¨Linuxä¸Šï¼Œæ£€æŸ¥/proc/PIDç›®å½•æ˜¯å¦å­˜åœ¨
            #[cfg(target_os = "linux")]
            {
                std::path::Path::new(&format!("/proc/{}", pid)).exists()
            }
            
            // åœ¨å…¶ä»–ç³»ç»Ÿä¸Šï¼Œç®€åŒ–ä¸ºLinuxçš„æ–¹æ³•ï¼Œå› ä¸ºå¤§å¤šæ•°ç³»ç»Ÿéƒ½æœ‰/proc
            #[cfg(not(target_os = "linux"))]
            {
                // ç®€åŒ–å¤„ç†ï¼šåœ¨éLinuxç³»ç»Ÿä¹Ÿå°è¯•/procæ–¹æ³•ï¼Œå¦‚æœå¤±è´¥å°±å‡è®¾è¿›ç¨‹å­˜æ´»
                std::path::Path::new(&format!("/proc/{}", pid)).exists()
            }
        } else {
            true  // å¦‚æœæ²¡æœ‰è¿›ç¨‹IDï¼Œå‡è®¾è¿›ç¨‹å­˜æ´»
        }
    }
    
    fn is_stuck(&self, task_timeout: Duration, heartbeat_timeout: Duration) -> Option<&'static str> {
        // é¦–å…ˆæ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜æ´»ç€
        if !self.is_process_alive() {
            return Some("process_death");
        }
        
        // æ£€æŸ¥å¿ƒè·³è¶…æ—¶
        if self.last_heartbeat.elapsed() > heartbeat_timeout {
            return Some("heartbeat_timeout");
        }
        
        // æ£€æŸ¥ä»»åŠ¡æ‰§è¡Œè¶…æ—¶
        if let Some(start_time) = self.task_start_time {
            if start_time.elapsed() > task_timeout {
                return Some("task_timeout");
            }
        }
        
        None
    }
}

// æ–°å¢ï¼šè¯Šæ–­ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Clone)]
struct DiagnosticStats {
    total_stuck_detections: u32,
    total_force_kills: u32,
    total_restarts: u32,
    stuck_by_timeout: u32,
    stuck_by_heartbeat: u32,
    stuck_by_process_death: u32,
}

impl DiagnosticStats {
    fn new() -> Self {
        Self {
            total_stuck_detections: 0,
            total_force_kills: 0,
            total_restarts: 0,
            stuck_by_timeout: 0,
            stuck_by_heartbeat: 0,
            stuck_by_process_death: 0,
        }
    }
}

// å¡æ­»ä»»åŠ¡ä¿¡æ¯ç»“æ„ä½“
#[derive(Debug, Clone)]
struct StuckTaskInfo {
    date: i64,
    code: String,
    worker_id: usize,
    runtime: Duration,
    reason: String,
}

// æ–°å¢ï¼šWorkerç›‘æ§ç®¡ç†å™¨
#[derive(Debug)]
struct WorkerMonitorManager {
    monitors: Arc<Mutex<HashMap<usize, WorkerMonitor>>>,
    task_timeout: Duration,
    health_check_interval: Duration,
    debug_monitor: bool,
    stats: Arc<Mutex<DiagnosticStats>>,
    should_stop: Arc<AtomicBool>,
    stuck_tasks: Arc<Mutex<Vec<StuckTaskInfo>>>,
}

impl WorkerMonitorManager {
    fn new(task_timeout: Duration, health_check_interval: Duration, debug_monitor: bool) -> Self {
        Self {
            monitors: Arc::new(Mutex::new(HashMap::new())),
            task_timeout,
            health_check_interval,
            debug_monitor,
            stats: Arc::new(Mutex::new(DiagnosticStats::new())),
            should_stop: Arc::new(AtomicBool::new(false)),
            stuck_tasks: Arc::new(Mutex::new(Vec::new())),
        }
    }
    
    fn add_worker(&self, worker_id: usize) {
        if let Ok(mut monitors) = self.monitors.lock() {
            monitors.insert(worker_id, WorkerMonitor::new(worker_id));
            if self.debug_monitor {
                println!("ğŸ” ç›‘æ§å™¨: æ·»åŠ worker {}", worker_id);
            }
        }
    }
    
    fn set_worker_process_id(&self, worker_id: usize, pid: u32) {
        if let Ok(mut monitors) = self.monitors.lock() {
            if let Some(monitor) = monitors.get_mut(&worker_id) {
                monitor.set_process_id(pid);
                if self.debug_monitor {
                    println!("ğŸ” ç›‘æ§å™¨: Worker {} è®¾ç½®è¿›ç¨‹ID: {}", worker_id, pid);
                }
            }
        }
    }
    
    fn start_task(&self, worker_id: usize, task: TaskParam) {
        if let Ok(mut monitors) = self.monitors.lock() {
            if let Some(monitor) = monitors.get_mut(&worker_id) {
                monitor.start_task(task.clone());
                if self.debug_monitor {
                    println!("ğŸ” ç›‘æ§å™¨: Worker {} å¼€å§‹ä»»åŠ¡ date={}, code={}", 
                             worker_id, task.date, task.code);
                }
            }
        }
    }
    
    fn finish_task(&self, worker_id: usize) {
        if let Ok(mut monitors) = self.monitors.lock() {
            if let Some(monitor) = monitors.get_mut(&worker_id) {
                if self.debug_monitor && monitor.current_task.is_some() {
                    let task = monitor.current_task.as_ref().unwrap();
                    println!("ğŸ” ç›‘æ§å™¨: Worker {} å®Œæˆä»»åŠ¡ date={}, code={}", 
                             worker_id, task.date, task.code);
                }
                monitor.finish_task();
            }
        }
    }
    
    fn update_heartbeat(&self, worker_id: usize) {
        if let Ok(mut monitors) = self.monitors.lock() {
            if let Some(monitor) = monitors.get_mut(&worker_id) {
                monitor.update_heartbeat();
            }
        }
    }
    
    fn check_stuck_workers(&self) -> Vec<(usize, &'static str)> {
        let heartbeat_timeout = self.health_check_interval * 3; // 3ä¸ªæ£€æŸ¥å‘¨æœŸæ— å“åº”è§†ä¸ºå¡æ­»
        let mut stuck_workers = Vec::new();
        
        if let Ok(monitors) = self.monitors.lock() {
            for (worker_id, monitor) in monitors.iter() {
                // è·³è¿‡å·²ç»æ ‡è®°ä¸ºä¸å­˜æ´»æˆ–æ²¡æœ‰è¿›ç¨‹IDçš„worker
                if !monitor.is_alive || monitor.process_id.is_none() {
                    continue;
                }
                
                if let Some(stuck_reason) = monitor.is_stuck(self.task_timeout, heartbeat_timeout) {
                    stuck_workers.push((*worker_id, stuck_reason));
                    
                    // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                    if let Ok(mut stats) = self.stats.lock() {
                        stats.total_stuck_detections += 1;
                        match stuck_reason {
                            "task_timeout" => stats.stuck_by_timeout += 1,
                            "heartbeat_timeout" => stats.stuck_by_heartbeat += 1,
                            "process_death" => stats.stuck_by_process_death += 1,
                            _ => {}
                        }
                    }
                    
                    if self.debug_monitor {
                        println!("âš ï¸ ç›‘æ§å™¨: æ£€æµ‹åˆ°Worker {} å¡æ­» (åŸå› : {})", worker_id, stuck_reason);
                        if let Some(task) = &monitor.current_task {
                            println!("   æ­£åœ¨å¤„ç†ä»»åŠ¡: date={}, code={}", task.date, task.code);
                        }
                        println!("   æœ€åå¿ƒè·³: {:?}å‰", monitor.last_heartbeat.elapsed());
                        if let Some(start_time) = monitor.task_start_time {
                            println!("   ä»»åŠ¡è¿è¡Œæ—¶é—´: {:?}", start_time.elapsed());
                        }
                    }
                }
            }
        }
        
        stuck_workers
    }
    
    fn log_stuck_worker(&self, worker_id: usize, reason: &str) {
        if let Ok(monitors) = self.monitors.lock() {
            if let Some(monitor) = monitors.get(&worker_id) {
                // åªåœ¨debugæ¨¡å¼ä¸‹è¾“å‡ºè¯¦ç»†ä¿¡æ¯
                if self.debug_monitor {
                    println!("ğŸš¨ Worker {} è¢«æ ‡è®°ä¸ºå¡æ­»å¹¶å°†é‡å¯", worker_id);
                    if let Some(task) = &monitor.current_task {
                        println!("   è·³è¿‡ä»»åŠ¡: date={}, code={} (å·²è¿è¡Œ {:?})", 
                                 task.date, task.code,
                                 monitor.task_start_time.map(|t| t.elapsed()).unwrap_or(Duration::ZERO));
                    }
                    println!("   æœ€åå¿ƒè·³æ—¶é—´: {:?}å‰", monitor.last_heartbeat.elapsed());
                    if let Some(pid) = monitor.process_id {
                        println!("   è¿›ç¨‹ID: {}", pid);
                    }
                }
                
                // è®°å½•å¡æ­»ä»»åŠ¡ä¿¡æ¯
                if let Some(task) = &monitor.current_task {
                    let stuck_task = StuckTaskInfo {
                        date: task.date,
                        code: task.code.clone(),
                        worker_id,
                        runtime: monitor.task_start_time.map(|t| t.elapsed()).unwrap_or(Duration::ZERO),
                        reason: reason.to_string(),
                    };
                    
                    if let Ok(mut stuck_tasks) = self.stuck_tasks.lock() {
                        stuck_tasks.push(stuck_task);
                    }
                }
            }
        }
    }
    
    fn force_kill_worker(&self, worker_id: usize) -> bool {
        if let Ok(mut monitors) = self.monitors.lock() {
            if let Some(monitor) = monitors.get_mut(&worker_id) {
                if let Some(pid) = monitor.process_id {
                    // é¦–å…ˆæ£€æŸ¥è¿›ç¨‹æ˜¯å¦ä»ç„¶å­˜åœ¨
                    if !monitor.is_process_alive() {
                        if self.debug_monitor {
                            println!("ğŸ” Worker {} è¿›ç¨‹ {} å·²ä¸å­˜åœ¨ï¼Œæ¸…ç†ç›‘æ§è®°å½•", worker_id, pid);
                        }
                        // ç›´æ¥ç§»é™¤æ•´ä¸ªç›‘æ§è®°å½•
                        drop(monitors);  // é‡Šæ”¾é”
                        self.remove_worker(worker_id);
                        return true;
                    }
                    
                    if self.debug_monitor {
                        println!("ğŸ”¥ å¼ºåˆ¶ç»ˆæ­¢Worker {} è¿›ç¨‹ (PID: {})", worker_id, pid);
                    }
                    
                    // å°è¯•å¼ºåˆ¶æ€æ­»è¿›ç¨‹
                    #[cfg(target_os = "linux")]
                    {
                        use std::process::Command;
                        let output = Command::new("kill")
                            .arg("-9")  // SIGKILL
                            .arg(pid.to_string())
                            .output();
                        
                        match output {
                            Ok(result) => {
                                if result.status.success() {
                                    // println!("âœ… æˆåŠŸç»ˆæ­¢è¿›ç¨‹ {}", pid);
                                    monitor.process_id = None;  // æ¸…é™¤è¿›ç¨‹ID
                                    
                                    // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                                    if let Ok(mut stats) = self.stats.lock() {
                                        stats.total_force_kills += 1;
                                    }
                                    
                                    return true;
                                } else {
                                    let stderr = String::from_utf8_lossy(&result.stderr);
                                    // å¦‚æœæ˜¯"No such process"é”™è¯¯ï¼Œè¯´æ˜è¿›ç¨‹å·²ç»ä¸å­˜åœ¨äº†
                                    if stderr.contains("No such process") {
                                        if self.debug_monitor {
                                            println!("ğŸ” è¿›ç¨‹ {} å·²ä¸å­˜åœ¨ï¼Œæ¸…ç†ç›‘æ§è®°å½•", pid);
                                        }
                                        // ç›´æ¥ç§»é™¤æ•´ä¸ªç›‘æ§è®°å½•
                                        drop(monitors);  // é‡Šæ”¾é”
                                        self.remove_worker(worker_id);
                                        return true;
                                    } else {
                                        eprintln!("âŒ ç»ˆæ­¢è¿›ç¨‹å¤±è´¥: {}", stderr);
                                    }
                                }
                            }
                            Err(e) => {
                                eprintln!("âŒ æ‰§è¡Œkillå‘½ä»¤å¤±è´¥: {}", e);
                            }
                        }
                    }
                    
                    // éLinuxç³»ç»Ÿçš„å¤„ç†ï¼ˆç®€åŒ–ï¼‰
                    #[cfg(not(target_os = "linux"))]
                    {
                        println!("âš ï¸ éLinuxç³»ç»Ÿï¼Œæ— æ³•å¼ºåˆ¶ç»ˆæ­¢è¿›ç¨‹ {}", pid);
                        monitor.process_id = None;  // æ¸…é™¤è¿›ç¨‹IDï¼Œå‡è®¾è¿›ç¨‹å·²æ­»
                        return true;
                    }
                }
            }
        }
        false
    }
    
    #[allow(dead_code)]
    fn remove_worker(&self, worker_id: usize) {
        if let Ok(mut monitors) = self.monitors.lock() {
            monitors.remove(&worker_id);
            if self.debug_monitor {
                println!("ğŸ” ç›‘æ§å™¨: ç§»é™¤worker {}", worker_id);
            }
        }
    }
    
    fn stop_monitoring(&self) {
        self.should_stop.store(true, Ordering::SeqCst);
        if self.debug_monitor {
            println!("ğŸ” ç›‘æ§å™¨: æ¥æ”¶åˆ°åœæ­¢ä¿¡å·");
        }
    }
    
    fn should_stop_monitoring(&self) -> bool {
        self.should_stop.load(Ordering::SeqCst)
    }
    
    fn print_diagnostic_stats(&self) {
        // ä½¿ç”¨try_locké¿å…æ— é™ç­‰å¾…
        match self.stats.try_lock() {
            Ok(stats) => {
                if stats.total_stuck_detections > 0 {
                    println!("\nğŸ“Š ç›‘æ§å™¨è¯Šæ–­ç»Ÿè®¡:");
                    println!("   æ€»å¡æ­»æ£€æµ‹æ¬¡æ•°: {}", stats.total_stuck_detections);
                    println!("   ä»»åŠ¡è¶…æ—¶å¯¼è‡´: {}", stats.stuck_by_timeout);
                    println!("   å¿ƒè·³è¶…æ—¶å¯¼è‡´: {}", stats.stuck_by_heartbeat);
                    println!("   è¿›ç¨‹æ­»äº¡å¯¼è‡´: {}", stats.stuck_by_process_death);
                    println!("   å¼ºåˆ¶ç»ˆæ­¢æ¬¡æ•°: {}", stats.total_force_kills);
                    println!("   é‡å¯æ¬¡æ•°: {}", stats.total_restarts);
                } else {
                    println!("[{}] ğŸ“Š ç›‘æ§å™¨ç»Ÿè®¡: æœªæ£€æµ‹åˆ°ä»»ä½•workerå¡æ­»", Local::now().format("%Y-%m-%d %H:%M:%S"));
                }
            }
            Err(_) => {
                println!("âš ï¸ æ— æ³•è·å–è¯Šæ–­ç»Ÿè®¡é”ï¼Œè·³è¿‡ç»Ÿè®¡è¾“å‡º");
            }
        }
    }
    
    fn print_stuck_tasks_table(&self) {
        // ä½¿ç”¨try_locké¿å…æ— é™ç­‰å¾…ï¼Œå¹¶æ·»åŠ é”™è¯¯å¤„ç†
        match self.stuck_tasks.try_lock() {
            Ok(stuck_tasks) => {
                if stuck_tasks.is_empty() {
                    println!("\nâœ… æ²¡æœ‰ä»»åŠ¡å› è¶…æ—¶è¢«è·³è¿‡");
                } else {
                    println!("\nğŸ“‹ å¡æ­»ä»»åŠ¡ç»Ÿè®¡è¡¨");
                    println!("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
                    println!("â”‚   Date   â”‚   Code   â”‚ Worker  â”‚   Runtime    â”‚    Reason    â”‚");
                    println!("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");
                    
                    for task in stuck_tasks.iter() {
                        let runtime_str = if task.runtime.as_secs() > 0 {
                            format!("{:.1}s", task.runtime.as_secs_f64())
                        } else {
                            format!("{}ms", task.runtime.as_millis())
                        };
                        
                        println!("â”‚ {:8} â”‚ {:8} â”‚ {:7} â”‚ {:12} â”‚ {:12} â”‚",
                            task.date,
                            task.code,
                            task.worker_id,
                            runtime_str,
                            match task.reason.as_str() {
                                "task_timeout" => "ä»»åŠ¡è¶…æ—¶",
                                "heartbeat_timeout" => "å¿ƒè·³è¶…æ—¶", 
                                "process_death" => "è¿›ç¨‹æ­»äº¡",
                                _ => &task.reason
                            }
                        );
                    }
                    
                    println!("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜");
                    println!("å…± {} ä¸ªä»»åŠ¡å› è¶…æ—¶è¢«è·³è¿‡", stuck_tasks.len());
                }
            }
            Err(_) => {
                println!("âš ï¸ æ— æ³•è·å–å¡æ­»ä»»åŠ¡ç»Ÿè®¡é”ï¼Œè·³è¿‡ç»Ÿè®¡è¡¨æ‰“å°");
            }
        }
    }
    
    /// æ¸…ç†ç›‘æ§ç®¡ç†å™¨çš„æ‰€æœ‰èµ„æºï¼Œç¡®ä¿æ²¡æœ‰é—ç•™å¼•ç”¨
    fn cleanup(&self) {
        if self.debug_monitor {
            println!("ğŸ§¹ ç›‘æ§å™¨: å¼€å§‹æ¸…ç†èµ„æº...");
        }
        
        // æ¸…ç†æ‰€æœ‰monitorè®°å½•
        if let Ok(mut monitors) = self.monitors.try_lock() {
            monitors.clear();
            if self.debug_monitor {
                println!("ğŸ§¹ ç›‘æ§å™¨: å·²æ¸…ç†æ‰€æœ‰workerç›‘æ§è®°å½•");
            }
        } else if self.debug_monitor {
            println!("âš ï¸ ç›‘æ§å™¨: æ— æ³•è·å–monitorsé”è¿›è¡Œæ¸…ç†");
        }
        
        // æ¸…ç†å¡æ­»ä»»åŠ¡è®°å½•
        if let Ok(mut stuck_tasks) = self.stuck_tasks.try_lock() {
            stuck_tasks.clear();
            if self.debug_monitor {
                println!("ğŸ§¹ ç›‘æ§å™¨: å·²æ¸…ç†æ‰€æœ‰å¡æ­»ä»»åŠ¡è®°å½•");
            }
        } else if self.debug_monitor {
            println!("âš ï¸ ç›‘æ§å™¨: æ— æ³•è·å–stuck_tasksé”è¿›è¡Œæ¸…ç†");
        }
        
        // é‡ç½®ç»Ÿè®¡ä¿¡æ¯
        if let Ok(mut stats) = self.stats.try_lock() {
            *stats = DiagnosticStats::new();
            if self.debug_monitor {
                println!("ğŸ§¹ ç›‘æ§å™¨: å·²é‡ç½®è¯Šæ–­ç»Ÿè®¡ä¿¡æ¯");
            }
        } else if self.debug_monitor {
            println!("âš ï¸ ç›‘æ§å™¨: æ— æ³•è·å–statsé”è¿›è¡Œæ¸…ç†");
        }
        
        if self.debug_monitor {
            println!("âœ… ç›‘æ§å™¨: èµ„æºæ¸…ç†å®Œæˆ");
        }
    }
}

fn detect_python_interpreter() -> String {
    // 1. æ£€æŸ¥ç¯å¢ƒå˜é‡
    if let Ok(python_path) = env::var("PYTHON_INTERPRETER") {
        if Path::new(&python_path).exists() {
            return python_path;
        }
    }
    
    // 2. æ£€æŸ¥æ˜¯å¦åœ¨ conda ç¯å¢ƒä¸­
    if let Ok(conda_prefix) = env::var("CONDA_PREFIX") {
        let conda_python = format!("{}/bin/python", conda_prefix);
        if Path::new(&conda_python).exists() {
            return conda_python;
        }
    }
    
    // 3. æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ
    if let Ok(virtual_env) = env::var("VIRTUAL_ENV") {
        let venv_python = format!("{}/bin/python", virtual_env);
        if Path::new(&venv_python).exists() {
            return venv_python;
        }
    }
    
    // 4. å°è¯•å¸¸è§çš„ Python è§£é‡Šå™¨
    let candidates = ["python3", "python"];
    for candidate in &candidates {
        if Command::new("which")
            .arg(candidate)
            .output()
            .map(|output| output.status.success())
            .unwrap_or(false)
        {
            return candidate.to_string();
        }
    }
    
    // 5. é»˜è®¤å€¼
    "python".to_string()
}

fn read_existing_backup(file_path: &str) -> Result<HashSet<(i64, String)>, Box<dyn std::error::Error>> {
    read_existing_backup_with_filter(file_path, None)
}

fn read_existing_backup_with_filter(file_path: &str, date_filter: Option<&HashSet<i64>>) -> Result<HashSet<(i64, String)>, Box<dyn std::error::Error>> {
    let mut existing_tasks = HashSet::new();
    
    if !Path::new(file_path).exists() {
        return Ok(existing_tasks);
    }
    
    let file = File::open(file_path)?;
    let file_len = file.metadata()?.len() as usize;
    
    if file_len < HEADER_SIZE {
        // å›é€€åˆ°æ—§æ ¼å¼
        return read_existing_backup_legacy(file_path);
    }
    
    // å°è¯•æ–°æ ¼å¼
    let mmap = unsafe { Mmap::map(&file)? };
    
    // æ£€æŸ¥é­”æ•°
    let header = unsafe {
        &*(mmap.as_ptr() as *const FileHeader)
    };
    
    if &header.magic != b"RPBACKUP" {
        // ä¸æ˜¯æ–°æ ¼å¼ï¼Œå›é€€åˆ°æ—§æ ¼å¼
        return read_existing_backup_legacy(file_path);
    }
    
    let record_count = header.record_count as usize;
    let factor_count = header.factor_count as usize;
    let record_size = calculate_record_size(factor_count);
    let records_start = HEADER_SIZE;
    
    // æ£€æŸ¥ç‰ˆæœ¬å·
    if header.version == 2 {
        // æ–°çš„åŠ¨æ€æ ¼å¼
        for i in 0..record_count {
            let record_offset = records_start + i * record_size;
            let record_bytes = &mmap[record_offset..record_offset + record_size];
            
            match DynamicRecord::from_bytes(record_bytes, factor_count) {
                Ok(record) => {
                    // å¦‚æœæœ‰æ—¥æœŸè¿‡æ»¤å™¨ï¼Œåªæœ‰åŒ¹é…çš„æ—¥æœŸæ‰ä¼šè¢«åŒ…å«
                    if let Some(filter) = date_filter {
                        if !filter.contains(&record.date) {
                            continue;
                        }
                    }
                    let code_len = std::cmp::min(record.code_len as usize, 32);
                    let code = String::from_utf8_lossy(&record.code_bytes[..code_len]).to_string();
                    existing_tasks.insert((record.date, code));
                }
                Err(_) => {
                    // è®°å½•æŸåï¼Œè·³è¿‡
                    continue;
                }
            }
        }
    } else {
        // æ—§æ ¼å¼ï¼Œå›é€€åˆ°legacyå¤„ç†
        return read_existing_backup_legacy_with_filter(file_path, date_filter);
    }
    
    Ok(existing_tasks)
}

fn read_existing_backup_legacy(file_path: &str) -> Result<HashSet<(i64, String)>, Box<dyn std::error::Error>> {
    read_existing_backup_legacy_with_filter(file_path, None)
}

fn read_existing_backup_legacy_with_filter(file_path: &str, date_filter: Option<&HashSet<i64>>) -> Result<HashSet<(i64, String)>, Box<dyn std::error::Error>> {
    let mut existing_tasks = HashSet::new();
    let mut file = File::open(file_path)?;
    let mut buffer = Vec::new();
    file.read_to_end(&mut buffer)?;
    
    if buffer.is_empty() {
        return Ok(existing_tasks);
    }
    
    let mut cursor = 0;
    
    // å°è¯•æ–°çš„æ‰¹æ¬¡æ ¼å¼
    while cursor + 8 <= buffer.len() {
        let size_bytes = &buffer[cursor..cursor + 8];
        let batch_size = u64::from_le_bytes([
            size_bytes[0], size_bytes[1], size_bytes[2], size_bytes[3],
            size_bytes[4], size_bytes[5], size_bytes[6], size_bytes[7],
        ]) as usize;
        
        cursor += 8;
        
        if cursor + batch_size > buffer.len() {
            cursor -= 8;
            break;
        }
        
        match bincode::deserialize::<Vec<TaskResult>>(&buffer[cursor..cursor + batch_size]) {
            Ok(batch) => {
                for result in &batch {
                    // å¦‚æœæœ‰æ—¥æœŸè¿‡æ»¤å™¨ï¼Œåªæœ‰åŒ¹é…çš„æ—¥æœŸæ‰ä¼šè¢«åŒ…å«
                    if let Some(filter) = date_filter {
                        if !filter.contains(&result.date) {
                            continue;
                        }
                    }
                    existing_tasks.insert((result.date, result.code.clone()));
                }
                cursor += batch_size;
            }
            Err(_) => {
                cursor -= 8;
                break;
            }
        }
    }
    
    // å¦‚æœå¤±è´¥ï¼Œå°è¯•åŸå§‹æ ¼å¼
    if cursor < buffer.len() {
        while cursor < buffer.len() {
            match bincode::deserialize::<Vec<TaskResult>>(&buffer[cursor..]) {
                Ok(batch) => {
                    for result in &batch {
                        // å¦‚æœæœ‰æ—¥æœŸè¿‡æ»¤å™¨ï¼Œåªæœ‰åŒ¹é…çš„æ—¥æœŸæ‰ä¼šè¢«åŒ…å«
                        if let Some(filter) = date_filter {
                            if !filter.contains(&result.date) {
                                continue;
                            }
                        }
                        existing_tasks.insert((result.date, result.code.clone()));
                    }
                    let batch_size = bincode::serialized_size(&batch)? as usize;
                    cursor += batch_size;
                }
                Err(_) => {
                    cursor += std::cmp::min(64, buffer.len() - cursor);
                }
            }
        }
    }
    
    Ok(existing_tasks)
}

// åŠ¨æ€å› å­æ•°é‡æ”¯æŒ - åŸºäºexpected_result_lengthè®¡ç®—è®°å½•å¤§å°
const HEADER_SIZE: usize = 64;  // æ–‡ä»¶å¤´64å­—èŠ‚
const MAX_FACTORS: usize = 256; // ä¸´æ—¶å‘åå…¼å®¹å¸¸é‡
const RECORD_SIZE: usize = 2116; // ä¸´æ—¶å‘åå…¼å®¹å¸¸é‡ï¼ˆå¯¹åº”256ä¸ªå› å­ï¼‰

// åŠ¨æ€è®¡ç®—è®°å½•å¤§å°
fn calculate_record_size(factor_count: usize) -> usize {
    8 +        // date: i64
    8 +        // code_hash: u64 
    8 +        // timestamp: i64
    4 +        // factor_count: u32
    4 +        // code_len: u32
    32 +       // code_bytes: [u8; 32]
    factor_count * 8 +  // factors: [f64; factor_count]
    4          // checksum: u32
}

#[repr(C, packed)]
struct FileHeader {
    magic: [u8; 8],          // é­”æ•° "RPBACKUP"
    version: u32,            // ç‰ˆæœ¬å·
    record_count: u64,       // è®°å½•æ€»æ•°
    record_size: u32,        // å•æ¡è®°å½•å¤§å°
    factor_count: u32,       // å› å­æ•°é‡
    reserved: [u8; 36],      // ä¿ç•™å­—æ®µ
}

// ä¸´æ—¶å‘åå…¼å®¹çš„å›ºå®šè®°å½•ç»“æ„
#[repr(C, packed)]
struct FixedRecord {
    date: i64,
    code_hash: u64,
    timestamp: i64,
    factor_count: u32,
    code_len: u32,
    code_bytes: [u8; 32],
    factors: [f64; MAX_FACTORS],
    checksum: u32,
}

// åŠ¨æ€å¤§å°è®°å½•ç»“æ„
#[derive(Debug, Clone)]
struct DynamicRecord {
    date: i64,
    code_hash: u64,
    timestamp: i64,
    factor_count: u32,
    code_len: u32,
    code_bytes: [u8; 32],
    factors: Vec<f64>,  // åŠ¨æ€å¤§å°çš„å› å­æ•°ç»„
    checksum: u32,
}

impl DynamicRecord {
    fn from_task_result(result: &TaskResult) -> Self {
        let mut record = DynamicRecord {
            date: result.date,
            code_hash: calculate_hash(&result.code),
            timestamp: result.timestamp,
            factor_count: result.facs.len() as u32,
            code_len: 0,
            code_bytes: [0; 32],
            factors: result.facs.clone(),
            checksum: 0,
        };
        
        // å¤„ç†codeå­—ç¬¦ä¸²ï¼Œç¡®ä¿å®‰å…¨è®¿é—®
        let code_bytes = result.code.as_bytes();
        let safe_len = std::cmp::min(code_bytes.len(), 32);
        record.code_len = safe_len as u32;
        record.code_bytes[..safe_len].copy_from_slice(&code_bytes[..safe_len]);
        
        // è®¡ç®—æ ¡éªŒå’Œ
        record.checksum = record.calculate_checksum();
        
        record
    }
    
    // fn to_task_result(&self) -> TaskResult {
    //     let code = String::from_utf8_lossy(&self.code_bytes[..self.code_len as usize]).to_string();
    //     TaskResult {
    //         date: self.date,
    //         code,
    //         timestamp: self.timestamp,
    //         facs: self.factors.clone(),
    //     }
    // }
    
    fn calculate_checksum(&self) -> u32 {
        let mut sum = 0u32;
        sum = sum.wrapping_add(self.date as u32);
        sum = sum.wrapping_add((self.date >> 32) as u32);
        sum = sum.wrapping_add(self.code_hash as u32);
        sum = sum.wrapping_add((self.code_hash >> 32) as u32);
        sum = sum.wrapping_add(self.timestamp as u32);
        sum = sum.wrapping_add(self.factor_count);
        sum = sum.wrapping_add(self.code_len);
        
        for &factor in &self.factors {
            sum = sum.wrapping_add(factor.to_bits() as u32);
            sum = sum.wrapping_add((factor.to_bits() >> 32) as u32);
        }
        
        sum
    }
    
    // å°†è®°å½•åºåˆ—åŒ–ä¸ºå­—èŠ‚æ•°ç»„
    fn to_bytes(&self) -> Vec<u8> {
        let mut bytes = Vec::new();
        
        bytes.extend_from_slice(&self.date.to_le_bytes());
        bytes.extend_from_slice(&self.code_hash.to_le_bytes());
        bytes.extend_from_slice(&self.timestamp.to_le_bytes());
        bytes.extend_from_slice(&self.factor_count.to_le_bytes());
        bytes.extend_from_slice(&self.code_len.to_le_bytes());
        bytes.extend_from_slice(&self.code_bytes);
        
        for &factor in &self.factors {
            bytes.extend_from_slice(&factor.to_le_bytes());
        }
        
        bytes.extend_from_slice(&self.checksum.to_le_bytes());
        
        bytes
    }
    
    // ä»å­—èŠ‚æ•°ç»„ååºåˆ—åŒ–è®°å½•
    fn from_bytes(bytes: &[u8], expected_factor_count: usize) -> Result<Self, Box<dyn std::error::Error>> {
        if bytes.len() < calculate_record_size(expected_factor_count) {
            return Err("Insufficient bytes for record".into());
        }
        
        let mut offset = 0;
        
        let date = i64::from_le_bytes(bytes[offset..offset+8].try_into()?);
        offset += 8;
        
        let code_hash = u64::from_le_bytes(bytes[offset..offset+8].try_into()?);
        offset += 8;
        
        let timestamp = i64::from_le_bytes(bytes[offset..offset+8].try_into()?);
        offset += 8;
        
        let factor_count = u32::from_le_bytes(bytes[offset..offset+4].try_into()?);
        offset += 4;
        
        let code_len = u32::from_le_bytes(bytes[offset..offset+4].try_into()?);
        offset += 4;
        
        let mut code_bytes = [0u8; 32];
        code_bytes.copy_from_slice(&bytes[offset..offset+32]);
        offset += 32;
        
        let mut factors = Vec::with_capacity(expected_factor_count);
        for _ in 0..expected_factor_count {
            let factor = f64::from_le_bytes(bytes[offset..offset+8].try_into()?);
            factors.push(factor);
            offset += 8;
        }
        
        let checksum = u32::from_le_bytes(bytes[offset..offset+4].try_into()?);
        
        Ok(DynamicRecord {
            date,
            code_hash,
            timestamp,
            factor_count,
            code_len,
            code_bytes,
            factors,
            checksum,
        })
    }
}

fn calculate_hash(s: &str) -> u64 {
    // ç®€å•çš„å“ˆå¸Œå‡½æ•°
    let mut hash = 0u64;
    for byte in s.bytes() {
        hash = hash.wrapping_mul(31).wrapping_add(byte as u64);
    }
    hash
}

fn save_results_to_backup(results: &[TaskResult], backup_file: &str, expected_result_length: usize) -> Result<(), Box<dyn std::error::Error>> {
    if results.is_empty() {
        return Ok(());
    }
    
    let factor_count = expected_result_length;
    let record_size = calculate_record_size(factor_count);
    
    // æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ
    let file_path = Path::new(backup_file);
    let file_exists = file_path.exists();
    let file_valid = if file_exists {
        file_path.metadata().map(|m| m.len() >= HEADER_SIZE as u64).unwrap_or(false)
    } else {
        false
    };
    
    if !file_valid {
        // åˆ›å»ºæ–°æ–‡ä»¶ï¼Œå†™å…¥æ–‡ä»¶å¤´
        let mut file = OpenOptions::new()
            .create(true)
            .write(true)
            .truncate(true)  
            .open(backup_file)?;
        
        let header = FileHeader {
            magic: *b"RPBACKUP",
            version: 2,  // ç‰ˆæœ¬2è¡¨ç¤ºæ”¯æŒåŠ¨æ€å› å­æ•°é‡
            record_count: 0,
            record_size: record_size as u32,
            factor_count: factor_count as u32,
            reserved: [0; 36],
        };
        
        // å†™å…¥æ–‡ä»¶å¤´
        let header_bytes = unsafe {
            std::slice::from_raw_parts(
                &header as *const FileHeader as *const u8,
                std::mem::size_of::<FileHeader>(),
            )
        };
        
        file.write_all(header_bytes)?;
        file.flush()?;
    }
    
    // è¯»å–å½“å‰è®°å½•æ•°
    let mut file = OpenOptions::new()
        .create(true)
        .read(true)
        .write(true)
        .open(backup_file)?;
    
    let file_len = file.metadata()?.len() as usize;
    if file_len < HEADER_SIZE {
        return Err(format!("File is too small to contain valid header: {} < {}", file_len, HEADER_SIZE).into());
    }
    
    let mut header_bytes = [0u8; HEADER_SIZE];
    file.read_exact(&mut header_bytes)?;
    
    let header = unsafe {
        &mut *(header_bytes.as_mut_ptr() as *mut FileHeader)
    };
    
    // éªŒè¯å› å­æ•°é‡åŒ¹é…
    let file_factor_count = header.factor_count;
    if file_factor_count != factor_count as u32 {
        return Err(format!("Factor count mismatch: file has {}, expected {}", file_factor_count, factor_count).into());
    }
    
    let current_count = header.record_count;
    let new_count = current_count + results.len() as u64;
    
    // æ‰©å±•æ–‡ä»¶å¤§å°
    let new_file_size = HEADER_SIZE as u64 + new_count * record_size as u64;
    file.set_len(new_file_size)?;
    
    // ä½¿ç”¨å†…å­˜æ˜ å°„è¿›è¡Œé«˜é€Ÿå†™å…¥
    drop(file);
    let file = OpenOptions::new()
        .create(true)
        .read(true)
        .write(true)
        .open(backup_file)?;
    
    let mut mmap = unsafe { MmapMut::map_mut(&file)? };
    
    // æ›´æ–°æ–‡ä»¶å¤´ä¸­çš„è®°å½•æ•°é‡
    let header = unsafe {
        &mut *(mmap.as_mut_ptr() as *mut FileHeader)
    };
    header.record_count = new_count;
    
    // å†™å…¥æ–°è®°å½•
    let start_offset = HEADER_SIZE + current_count as usize * record_size;
    
    for (i, result) in results.iter().enumerate() {
        let record = DynamicRecord::from_task_result(result);
        let record_bytes = record.to_bytes();
        let record_offset = start_offset + i * record_size;
        
        // ç¡®ä¿è®°å½•å¤§å°æ­£ç¡®
        if record_bytes.len() != record_size {
            return Err(format!("Record size mismatch: got {}, expected {}", record_bytes.len(), record_size).into());
        }
        
        mmap[record_offset..record_offset + record_size].copy_from_slice(&record_bytes);
    }
    
    mmap.flush()?;
    
    Ok(())
}


fn create_persistent_worker_script() -> String {
    format!(r#"#!/usr/bin/env python3
import sys
import msgpack
import time
import struct
import math

def normalize_value(x):
    '''å°†å€¼æ ‡å‡†åŒ–ï¼Œå°† Noneã€infã€-infã€nan éƒ½è½¬æ¢ä¸º nan'''
    if x is None:
        return float('nan')
    try:
        val = float(x)
        if math.isinf(val) or math.isnan(val):
            return float('nan')
        return val
    except (ValueError, TypeError):
        return float('nan')

def execute_task(func_code, date, code, expected_length):
    '''æ‰§è¡Œå•ä¸ªä»»åŠ¡ï¼Œè¿”å›ç»“æœæˆ–NaN'''
    try:
        namespace = {{'__builtins__': __builtins__}}
        exec(func_code, namespace)
        
        # æ‰¾åˆ°ç”¨æˆ·å®šä¹‰çš„å‡½æ•°ï¼ˆéå†…ç½®å‡½æ•°ï¼‰
        user_functions = [name for name, obj in namespace.items() 
                         if callable(obj) and not name.startswith('_') and name != 'execute_task']
        
        if not user_functions:
            return [float('nan')] * expected_length
            
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªç”¨æˆ·å®šä¹‰çš„å‡½æ•°
        func = namespace[user_functions[0]]
        result = func(date, code)
        
        if isinstance(result, list):
            # ä½¿ç”¨ normalize_value å‡½æ•°å¤„ç†æ‰€æœ‰ç‰¹æ®Šå€¼
            return [normalize_value(x) for x in result]
        else:
            return [float('nan')] * expected_length
            
    except Exception as e:
        print(f"Task error for {{date}}, {{code}}: {{e}}", file=sys.stderr)
        return [float('nan')] * expected_length

def read_message():
    '''ä»stdinè¯»å–ä¸€æ¡æ¶ˆæ¯ï¼Œè¿”å›é•¿åº¦+æ•°æ®'''
    # è¯»å–4å­—èŠ‚é•¿åº¦å‰ç¼€
    length_bytes = sys.stdin.buffer.read(4)
    if len(length_bytes) != 4:
        return None
    
    length = struct.unpack('<I', length_bytes)[0]
    if length == 0:
        return None
    
    # è¯»å–å®é™…æ•°æ®
    data = sys.stdin.buffer.read(length)
    if len(data) != length:
        return None
    
    return data

def write_message(data):
    '''å‘stdoutå†™å…¥ä¸€æ¡æ¶ˆæ¯ï¼Œå¸¦é•¿åº¦å‰ç¼€'''
    length = len(data)
    length_bytes = struct.pack('<I', length)
    sys.stdout.buffer.write(length_bytes)
    sys.stdout.buffer.write(data)
    sys.stdout.buffer.flush()

def main():
    print("ğŸš€ Persistent worker started", file=sys.stderr)
    
    # æŒç»­å¤„ç†ä»»åŠ¡ï¼Œç›´åˆ°æ”¶åˆ°ç©ºæ¶ˆæ¯
    while True:
        try:
            # è¯»å–ä»»åŠ¡æ¶ˆæ¯
            message_data = read_message()
            if message_data is None:
                break
            
            task_data = msgpack.unpackb(message_data, raw=False)
            
            if not isinstance(task_data, dict):
                print(f"Error: Expected dict, got {{type(task_data)}}: {{task_data}}", file=sys.stderr)
                continue
            
            func_code = task_data['python_code']
            task = task_data['task']
            expected_length = task_data['expected_result_length']
            
            # æ‰§è¡Œå•ä¸ªä»»åŠ¡
            timestamp = int(time.time() * 1000)
            date = task['date']
            code = task['code']
            
            facs = execute_task(func_code, date, code, expected_length)
            
            result = {{
                'date': date,
                'code': code,
                'timestamp': timestamp,
                'facs': facs
            }}
            
            # ä½¿ç”¨MessagePackåºåˆ—åŒ–å¹¶å‘é€ç»“æœ
            output = {{'result': result}}
            packed_output = msgpack.packb(output, use_bin_type=True)
            write_message(packed_output)

        except Exception as e:
            print(f"Failed to process task: {{e}}", file=sys.stderr)
            # å‘é€é”™è¯¯ç»“æœ
            error_result = {{
                'result': {{
                    'date': 0,
                    'code': '',
                    'timestamp': int(time.time() * 1000),
                    'facs': [float('nan')] * 1
                }}
            }}
            packed_error = msgpack.packb(error_result, use_bin_type=True)
            write_message(packed_error)

    print("ğŸ Persistent worker finished", file=sys.stderr)

if __name__ == '__main__':
    main()
"#)
}


fn extract_python_function_code(py_func: &PyObject) -> PyResult<String> {
    Python::with_gil(|py| {
        // å°è¯•è·å–å‡½æ•°çš„æºä»£ç 
        let inspect = py.import("inspect")?;
        
        match inspect.call_method1("getsource", (py_func,)) {
            Ok(source) => {
                let source_str: String = source.extract()?;
                Ok(source_str)
            }
            Err(_) => {
                // å¦‚æœæ— æ³•è·å–æºä»£ç ï¼Œå°è¯•ä½¿ç”¨pickle
                let pickle = py.import("pickle")?;
                match pickle.call_method1("dumps", (py_func,)) {
                    Ok(pickled) => {
                        let bytes: Vec<u8> = pickled.extract()?;
                        let base64 = py.import("base64")?;
                        let encoded = base64.call_method1("b64encode", (bytes,))?;
                        let encoded_str: String = encoded.call_method0("decode")?.extract()?;
                        
                        Ok(format!(r#"
import pickle
import base64
_func_data = base64.b64decode('{}')
user_function = pickle.loads(_func_data)
"#, encoded_str))
                    }
                    Err(_) => {
                        Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
                            "Cannot serialize the Python function. Please ensure the function can be pickled or provide source code."
                        ))
                    }
                }
            }
        }
    })
}







fn read_backup_results(file_path: &str) -> PyResult<PyObject> {
    read_backup_results_with_filter(file_path, None, None)
}

fn read_backup_results_with_filter(file_path: &str, date_filter: Option<&HashSet<i64>>, code_filter: Option<&HashSet<String>>) -> PyResult<PyObject> {
    if !Path::new(file_path).exists() {
        return Python::with_gil(|py| Ok(py.None()));
    }
    
    let file = File::open(file_path)
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("Failed to open backup file: {}", e)))?;
    
    let file_len = file.metadata()
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("Failed to get file metadata: {}", e)))?
        .len() as usize;
    
    if file_len < HEADER_SIZE {
        // å°è¯•æ—§æ ¼å¼çš„å›é€€å¤„ç†
        return read_legacy_backup_results_with_filter(file_path, date_filter, code_filter);
    }
    
    // ä½¿ç”¨å†…å­˜æ˜ å°„è¿›è¡Œè¶…é«˜é€Ÿè¯»å–
    let mmap = unsafe { 
        Mmap::map(&file)
            .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("Failed to memory map file: {}", e)))?
    };
    let mmap = Arc::new(mmap);
    
    // è¯»å–æ–‡ä»¶å¤´
    let header = unsafe {
        &*(mmap.as_ptr() as *const FileHeader)
    };
    
    // éªŒè¯é­”æ•°
    if &header.magic != b"RPBACKUP" {
        // ä¸æ˜¯æ–°æ ¼å¼ï¼Œå°è¯•æ—§æ ¼å¼
        return read_legacy_backup_results_with_filter(file_path, date_filter, code_filter);
    }
    
    let record_count = header.record_count as usize;
    if record_count == 0 {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            "No records found in backup file"
        ));
    }
    
    // æ£€æŸ¥ç‰ˆæœ¬å¹¶è®¡ç®—é¢„æœŸæ–‡ä»¶å¤§å°
    let factor_count = header.factor_count as usize;
    let record_size = if header.version == 2 {
        calculate_record_size(factor_count)
    } else {
        RECORD_SIZE  // æ—§æ ¼å¼ä½¿ç”¨å›ºå®šå¤§å°
    };
    
    let expected_size = HEADER_SIZE + record_count * record_size;
    if file_len < expected_size {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            "Backup file appears to be truncated"
        ));
    }
    
    // é¢„è®¡ç®—çŸ©é˜µç»´åº¦
    let factor_count = header.factor_count as usize;
    let num_cols = 3 + factor_count;
    
    // æ ¹æ®ç‰ˆæœ¬é€‰æ‹©ä¸åŒçš„è¯»å–æ–¹å¼
    let parallel_results: Result<Vec<_>, _> = if header.version == 2 {
        // æ–°çš„åŠ¨æ€æ ¼å¼è¯»å–
        (0..record_count)
            .collect::<Vec<_>>()
            .chunks(std::cmp::max(64, record_count / rayon::current_num_threads()))
            .map(|chunk| chunk.to_vec())
            .collect::<Vec<_>>()
            .par_iter()
            .map(|chunk| {
                let mut chunk_data = Vec::with_capacity(chunk.len() * num_cols);
                let records_start = HEADER_SIZE;
                
                for &i in chunk {
                    let record_offset = records_start + i * record_size;
                    let record_bytes = &mmap[record_offset..record_offset + record_size];
                    
                    match DynamicRecord::from_bytes(record_bytes, factor_count) {
                        Ok(record) => {
                            // æ£€æŸ¥æ—¥æœŸè¿‡æ»¤å™¨
                            if let Some(date_filter) = date_filter {
                                if !date_filter.contains(&record.date) {
                                    continue;
                                }
                            }
                            
                            // æ£€æŸ¥ä»£ç è¿‡æ»¤å™¨
                            let code_len = std::cmp::min(record.code_len as usize, 32);
                            let code_str = String::from_utf8_lossy(&record.code_bytes[..code_len]);
                            if let Some(code_filter) = code_filter {
                                if !code_filter.contains(code_str.as_ref()) {
                                    continue;
                                }
                            }
                            
                            chunk_data.push(record.date as f64);
                            
                            // å®‰å…¨çš„codeè½¬æ¢
                            let code_num = if let Ok(num) = code_str.parse::<f64>() {
                                num
                            } else {
                                f64::NAN
                            };
                            chunk_data.push(code_num);
                            
                            chunk_data.push(record.timestamp as f64);
                            
                            // å¤åˆ¶å› å­æ•°æ®
                            for j in 0..factor_count {
                                if j < record.factors.len() {
                                    chunk_data.push(record.factors[j]);
                                } else {
                                    chunk_data.push(f64::NAN);
                                }
                            }
                        }
                        Err(_) => {
                            // è®°å½•æŸåï¼Œå¡«å……NaN
                            for _ in 0..num_cols {
                                chunk_data.push(f64::NAN);
                            }
                        }
                    }
                }
                
                Ok(chunk_data)
            })
            .collect()
    } else {
        // æ—§æ ¼å¼ï¼Œä½¿ç”¨FixedRecord
        (0..record_count)
            .collect::<Vec<_>>()
            .chunks(std::cmp::max(64, record_count / rayon::current_num_threads()))
            .map(|chunk| chunk.to_vec())
            .collect::<Vec<_>>()
            .par_iter()
            .map(|chunk| {
                let mut chunk_data = Vec::with_capacity(chunk.len() * num_cols);
                let records_start = HEADER_SIZE;
                
                for &i in chunk {
                    let record_offset = records_start + i * RECORD_SIZE;
                    let record = unsafe {
                        &*(mmap.as_ptr().add(record_offset) as *const FixedRecord)
                    };
                    
                    // æ£€æŸ¥æ—¥æœŸè¿‡æ»¤å™¨
                    if let Some(date_filter) = date_filter {
                        let date = record.date; // å¤åˆ¶åˆ°æœ¬åœ°å˜é‡é¿å…unaligned reference
                        if !date_filter.contains(&date) {
                            continue;
                        }
                    }
                    
                    // æ£€æŸ¥ä»£ç è¿‡æ»¤å™¨
                    let code_len = std::cmp::min(record.code_len as usize, 32);
                    let code_str = unsafe {
                        std::str::from_utf8_unchecked(&record.code_bytes[..code_len])
                    };
                    if let Some(code_filter) = code_filter {
                        if !code_filter.contains(code_str) {
                            continue;
                        }
                    }
                    
                    // ç›´æ¥å¤åˆ¶æ•°æ®åˆ°è¾“å‡ºæ•°ç»„
                    chunk_data.push(record.date as f64);
                    
                    // å°è¯•å¿«é€Ÿè§£ææ•°å­—ï¼Œå¤±è´¥åˆ™ä½¿ç”¨NaN
                    let code_num = if let Ok(num) = code_str.parse::<f64>() {
                        num
                    } else {
                        // å¯¹äºéæ•°å­—è‚¡ç¥¨ä»£ç ï¼Œå¯ä»¥ä½¿ç”¨å“ˆå¸Œå€¼æˆ–ç›´æ¥ä½¿ç”¨NaN
                        record.code_hash as f64
                    };
                    chunk_data.push(code_num);
                    
                    chunk_data.push(record.timestamp as f64);
                    
                    // æ‰¹é‡å¤åˆ¶å› å­æ•°æ®
                    let actual_factor_count = std::cmp::min(
                        std::cmp::min(record.factor_count as usize, MAX_FACTORS),
                        factor_count
                    );
                    
                    // ç›´æ¥å†…å­˜å¤åˆ¶å› å­æ•°æ®ï¼ˆæ›´å¿«ï¼‰
                    for j in 0..actual_factor_count {
                        chunk_data.push(record.factors[j]);
                    }
                    
                    // å¦‚æœå› å­æ•°é‡ä¸è¶³ï¼Œå¡«å……NaN
                    for _ in actual_factor_count..factor_count {
                        chunk_data.push(f64::NAN);
                    }
                }
                
                Ok(chunk_data)
            })
            .collect()
    };
    
    let all_chunk_data = parallel_results
        .map_err(|e: String| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(e))?;
    
    // åˆå¹¶æ‰€æœ‰chunkçš„æ•°æ®
    let mut flat_data = Vec::with_capacity(record_count * num_cols);
    for chunk_data in all_chunk_data {
        flat_data.extend(chunk_data);
    }
    
    // è®¡ç®—å®é™…çš„è¡Œæ•°ï¼ˆè€ƒè™‘è¿‡æ»¤ï¼‰
    let actual_row_count = flat_data.len() / num_cols;
    
    // è¶…é«˜é€Ÿè½¬æ¢ï¼šç›´æ¥ä»å†…å­˜æ˜ å°„åˆ›å»ºnumpyæ•°ç»„
    Python::with_gil(|py| {
        let numpy = py.import("numpy")?;
        
        // åˆ›å»ºnumpyæ•°ç»„å¹¶reshapeï¼ˆä½¿ç”¨å®é™…è¡Œæ•°ï¼‰
        let array = numpy.call_method1("array", (flat_data,))?;
        let reshaped = array.call_method1("reshape", ((actual_row_count, num_cols),))?;
        
        Ok(reshaped.into())
    })
}

// å‘åå…¼å®¹çš„æ—§æ ¼å¼è¯»å–å‡½æ•°
#[allow(dead_code)]
fn read_legacy_backup_results(file_path: &str) -> PyResult<PyObject> {
    read_legacy_backup_results_with_filter(file_path, None, None)
}

fn read_legacy_backup_results_with_filter(file_path: &str, date_filter: Option<&HashSet<i64>>, code_filter: Option<&HashSet<String>>) -> PyResult<PyObject> {
    let mut file = File::open(file_path)
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("Failed to open backup file: {}", e)))?;
    
    let mut buffer = Vec::new();
    file.read_to_end(&mut buffer)
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("Failed to read backup file: {}", e)))?;
    
    if buffer.is_empty() {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            "Backup file is empty"
        ));
    }
    
    let mut all_results = Vec::new();
    let mut cursor = 0;
    
    // å°è¯•æ–°çš„æ‰¹æ¬¡æ ¼å¼ï¼ˆå¸¦å¤§å°å¤´ï¼‰
    while cursor + 8 <= buffer.len() {
        let size_bytes = &buffer[cursor..cursor + 8];
        let batch_size = u64::from_le_bytes([
            size_bytes[0], size_bytes[1], size_bytes[2], size_bytes[3],
            size_bytes[4], size_bytes[5], size_bytes[6], size_bytes[7],
        ]) as usize;
        
        cursor += 8;
        
        if cursor + batch_size > buffer.len() {
            cursor -= 8;
            break;
        }
        
        match bincode::deserialize::<Vec<TaskResult>>(&buffer[cursor..cursor + batch_size]) {
            Ok(batch) => {
                for result in batch {
                    // æ£€æŸ¥æ—¥æœŸè¿‡æ»¤å™¨
                    if let Some(date_filter) = date_filter {
                        if !date_filter.contains(&result.date) {
                            continue;
                        }
                    }
                    
                    // æ£€æŸ¥ä»£ç è¿‡æ»¤å™¨
                    if let Some(code_filter) = code_filter {
                        if !code_filter.contains(&result.code) {
                            continue;
                        }
                    }
                    
                    all_results.push(result);
                }
                cursor += batch_size;
            }
            Err(_) => {
                cursor -= 8;
                break;
            }
        }
    }
    
    // å¦‚æœå¤±è´¥ï¼Œå°è¯•åŸå§‹æ ¼å¼
    if cursor < buffer.len() {
        while cursor < buffer.len() {
            match bincode::deserialize::<Vec<TaskResult>>(&buffer[cursor..]) {
                Ok(batch) => {
                    let batch_size = bincode::serialized_size(&batch)
                        .map_err(|e| PyErr::new::<pyo3::exceptions::PyValueError, _>(format!("Serialization error: {}", e)))? as usize;
                    for result in batch {
                        // æ£€æŸ¥æ—¥æœŸè¿‡æ»¤å™¨
                        if let Some(date_filter) = date_filter {
                            if !date_filter.contains(&result.date) {
                                continue;
                            }
                        }
                        
                        // æ£€æŸ¥ä»£ç è¿‡æ»¤å™¨
                        if let Some(code_filter) = code_filter {
                            if !code_filter.contains(&result.code) {
                                continue;
                            }
                        }
                        
                        all_results.push(result);
                    }
                    cursor += batch_size;
                }
                Err(_) => {
                    cursor += std::cmp::min(64, buffer.len() - cursor);
                }
            }
        }
    }
    
    if all_results.is_empty() {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            "No valid results found in backup file"
        ));
    }
    
    convert_results_to_py_dict(&all_results)
}

// å°†TaskResultåˆ‡ç‰‡è½¬æ¢ä¸ºåŒ…å«Numpyæ•°ç»„çš„Pythonå­—å…¸
fn convert_results_to_py_dict(results: &[TaskResult]) -> PyResult<PyObject> {
    if results.is_empty() {
        return Python::with_gil(|py| Ok(pyo3::types::PyDict::new(py).into()));
    }
    
    Python::with_gil(|py| {
        let numpy = py.import("numpy")?;
        let dict = pyo3::types::PyDict::new(py);

        let num_rows = results.len();
        let factor_count = results.get(0).map_or(0, |r| r.facs.len());

        let mut dates = Vec::with_capacity(num_rows);
        let mut codes = Vec::with_capacity(num_rows);
        let mut timestamps = Vec::with_capacity(num_rows);
        let mut factors_flat = Vec::with_capacity(num_rows * factor_count);

        for result in results {
            dates.push(result.date);
            codes.push(result.code.clone());
            timestamps.push(result.timestamp);
            factors_flat.extend_from_slice(&result.facs);
        }

        dict.set_item("date", numpy.call_method1("array", (dates,))?)?;
        dict.set_item("code", numpy.call_method1("array", (codes,))?)?;
        dict.set_item("timestamp", numpy.call_method1("array", (timestamps,))?)?;
        
        let factors_array = numpy.call_method1("array", (factors_flat,))?;
        
        if num_rows > 0 && factor_count > 0 {
            let factors_reshaped = factors_array.call_method1("reshape", ((num_rows, factor_count),))?;
            dict.set_item("factors", factors_reshaped)?;
        } else {
            dict.set_item("factors", factors_array)?;
        }

        Ok(dict.into())
    })
}

#[pyfunction]
#[pyo3(signature = (backup_file,))]
pub fn query_backup(backup_file: String) -> PyResult<PyObject> {
    read_backup_results(&backup_file)
}

/// é«˜é€Ÿå¹¶è¡Œå¤‡ä»½æŸ¥è¯¢å‡½æ•°ï¼Œä¸“é—¨ä¼˜åŒ–å¤§æ–‡ä»¶è¯»å–
#[pyfunction]
#[pyo3(signature = (backup_file, num_threads=None, dates=None, codes=None))]
pub fn query_backup_fast(backup_file: String, num_threads: Option<usize>, dates: Option<Vec<i64>>, codes: Option<Vec<String>>) -> PyResult<PyObject> {
    // å°†Vecè½¬æ¢ä¸ºHashSetä»¥æé«˜æŸ¥æ‰¾æ€§èƒ½
    let date_filter: Option<HashSet<i64>> = dates.map(|v| v.into_iter().collect());
    let code_filter: Option<HashSet<String>> = codes.map(|v| v.into_iter().collect());
    
    // ä½¿ç”¨è‡ªå®šä¹‰çº¿ç¨‹æ± è€Œä¸æ˜¯å…¨å±€çº¿ç¨‹æ± 
    if let Some(threads) = num_threads {
        let pool = rayon::ThreadPoolBuilder::new()
            .num_threads(threads)
            .build()
            .map_err(|e| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(format!("Failed to create thread pool: {}", e)))?;
        
        pool.install(|| read_backup_results_ultra_fast_v4_with_filter(
            &backup_file, 
            date_filter.as_ref(), 
            code_filter.as_ref()
        ))
    } else {
        read_backup_results_ultra_fast_v4_with_filter(
            &backup_file, 
            date_filter.as_ref(), 
            code_filter.as_ref()
        )
    }
}




/// è¯»å–å¤‡ä»½æ–‡ä»¶ä¸­çš„æŒ‡å®šåˆ—
/// column_index: è¦è¯»å–çš„å› å­åˆ—ç´¢å¼•ï¼ˆ0è¡¨ç¤ºç¬¬ä¸€åˆ—å› å­å€¼ï¼‰
/// è¿”å›ä¸‰åˆ—ï¼šdate, code, æŒ‡å®šåˆ—çš„å› å­å€¼
fn read_backup_results_single_column(file_path: &str, column_index: usize) -> PyResult<PyObject> {
    read_backup_results_single_column_with_filter(file_path, column_index, None, None)
}

fn read_backup_results_single_column_with_filter(file_path: &str, column_index: usize, date_filter: Option<&HashSet<i64>>, code_filter: Option<&HashSet<String>>) -> PyResult<PyObject> {
    if !Path::new(file_path).exists() {
        return Err(PyErr::new::<pyo3::exceptions::PyFileNotFoundError, _>(
            "å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨"
        ));
    }
    
    let file = File::open(file_path)
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("æ— æ³•æ‰“å¼€å¤‡ä»½æ–‡ä»¶: {}", e)))?;
    
    let file_len = file.metadata()
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("æ— æ³•è·å–æ–‡ä»¶å…ƒæ•°æ®: {}", e)))?
        .len() as usize;
    
    if file_len < HEADER_SIZE {
        return read_legacy_backup_results_single_column_with_filter(file_path, column_index, date_filter, code_filter);
    }
    
    // å†…å­˜æ˜ å°„
    let mmap = unsafe { 
        Mmap::map(&file)
            .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("æ— æ³•æ˜ å°„æ–‡ä»¶åˆ°å†…å­˜: {}", e)))?
    };
    let mmap = Arc::new(mmap);
    
    // è¯»å–æ–‡ä»¶å¤´
    let header = unsafe {
        &*(mmap.as_ptr() as *const FileHeader)
    };
    
    if &header.magic != b"RPBACKUP" {
        return read_legacy_backup_results_single_column_with_filter(file_path, column_index, date_filter, code_filter);
    }
    
    let record_count = header.record_count as usize;
    if record_count == 0 {
        return Python::with_gil(|py| {
            let numpy = py.import("numpy")?;
            let dict = pyo3::types::PyDict::new(py);
            dict.set_item("date", numpy.call_method1("array", (Vec::<i64>::new(),))?)?;
            dict.set_item("code", numpy.call_method1("array", (Vec::<String>::new(),))?)?;
            dict.set_item("factor", numpy.call_method1("array", (Vec::<f64>::new(),))?)?;
            Ok(dict.into())
        });
    }
    
    let record_size = header.record_size as usize;
    let factor_count = header.factor_count as usize;
    
    // æ£€æŸ¥åˆ—ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
    if column_index >= factor_count {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            format!("åˆ—ç´¢å¼• {} è¶…å‡ºèŒƒå›´ï¼Œå› å­åˆ—æ•°ä¸º {}", column_index, factor_count)
        ));
    }
    
    let calculated_record_size = calculate_record_size(factor_count);
    if record_size != calculated_record_size {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
           format!("è®°å½•å¤§å°ä¸åŒ¹é…: æ–‡ä»¶å¤´æ˜¾ç¤º {}, è®¡ç®—å¾—åˆ° {}. æ–‡ä»¶å¯èƒ½æŸå.", record_size, calculated_record_size)
       ));
    }

    let expected_size = HEADER_SIZE + record_count * record_size;
    if file_len < expected_size {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            "å¤‡ä»½æ–‡ä»¶ä¼¼ä¹è¢«æˆªæ–­äº†"
        ));
    }
    
    // ä½¿ç”¨è‡ªå®šä¹‰çº¿ç¨‹æ± å¹¶ç›´æ¥ä»mmapè¯»å–ï¼Œé¿å…å¤§é‡å†…å­˜å¤åˆ¶
    let pool = rayon::ThreadPoolBuilder::new()
        .num_threads(std::cmp::min(rayon::current_num_threads(), 8))
        .build()
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(format!("åˆ›å»ºçº¿ç¨‹æ± å¤±è´¥: {}", e)))?;
    
    let records_start = HEADER_SIZE;
    let results: Vec<_> = pool.install(|| {
        (0..record_count)
            .into_par_iter()
            .filter_map(|i| {
                let record_offset = records_start + i * record_size;
                let record_bytes = &mmap[record_offset..record_offset + record_size];
                
                match DynamicRecord::from_bytes(record_bytes, factor_count) {
                    Ok(record) => {
                        // æ£€æŸ¥æ—¥æœŸè¿‡æ»¤å™¨
                        if let Some(date_filter) = date_filter {
                            if !date_filter.contains(&record.date) {
                                return None;
                            }
                        }
                        
                        let code_len = std::cmp::min(record.code_len as usize, 32);
                        let code = String::from_utf8_lossy(&record.code_bytes[..code_len]).to_string();
                        
                        // æ£€æŸ¥ä»£ç è¿‡æ»¤å™¨
                        if let Some(code_filter) = code_filter {
                            if !code_filter.contains(&code) {
                                return None;
                            }
                        }
                        
                        // è·å–æŒ‡å®šåˆ—çš„å› å­å€¼
                        let factor_value = if column_index < record.factors.len() {
                            record.factors[column_index]
                        } else {
                            f64::NAN
                        };
                        
                        Some((record.date, code, factor_value))
                    }
                    Err(_) => {
                        // è®°å½•æŸåï¼Œè¿”å›None
                        None
                    }
                }
            })
            .collect::<Vec<_>>()
    });
    
    // æ˜¾å¼é‡Šæ”¾mmap
    drop(mmap);
        
    let num_rows = results.len();
    let mut dates = Vec::with_capacity(num_rows);
    let mut codes = Vec::with_capacity(num_rows);
    let mut factors = Vec::with_capacity(num_rows);

    for (date, code, factor_value) in results {
        dates.push(date);
        codes.push(code);
        factors.push(factor_value);
    }

    // åˆ›å»ºPythonå­—å…¸
    Python::with_gil(|py| {
        let numpy = py.import("numpy")?;
        let dict = pyo3::types::PyDict::new(py);

        dict.set_item("date", numpy.call_method1("array", (dates,))?)?;
        dict.set_item("code", numpy.call_method1("array", (codes,))?)?;
        dict.set_item("factor", numpy.call_method1("array", (factors,))?)?;

        Ok(dict.into())
    })
}

fn read_backup_results_columns_range_with_filter(file_path: &str, column_start: usize, column_end: usize, date_filter: Option<&HashSet<i64>>, code_filter: Option<&HashSet<String>>) -> PyResult<PyObject> {
    if !Path::new(file_path).exists() {
        return Err(PyErr::new::<pyo3::exceptions::PyFileNotFoundError, _>(
            "å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨"
        ));
    }
    
    let file = File::open(file_path)
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("æ— æ³•æ‰“å¼€å¤‡ä»½æ–‡ä»¶: {}", e)))?;
    
    let file_len = file.metadata()
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("æ— æ³•è·å–æ–‡ä»¶å…ƒæ•°æ®: {}", e)))?
        .len() as usize;
    
    if file_len < HEADER_SIZE {
        return read_legacy_backup_results_columns_range_with_filter(file_path, column_start, column_end, date_filter, code_filter);
    }
    
    // å†…å­˜æ˜ å°„
    let mmap = unsafe { 
        Mmap::map(&file)
            .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("æ— æ³•æ˜ å°„æ–‡ä»¶åˆ°å†…å­˜: {}", e)))?
    };
    let mmap = Arc::new(mmap);
    
    // è¯»å–æ–‡ä»¶å¤´
    let header = unsafe {
        &*(mmap.as_ptr() as *const FileHeader)
    };
    
    if &header.magic != b"RPBACKUP" {
        return read_legacy_backup_results_columns_range_with_filter(file_path, column_start, column_end, date_filter, code_filter);
    }
    
    let record_count = header.record_count as usize;
    if record_count == 0 {
        return Python::with_gil(|py| {
            let numpy = py.import("numpy")?;
            let dict = pyo3::types::PyDict::new(py);
            dict.set_item("date", numpy.call_method1("array", (Vec::<i64>::new(),))?)?;
            dict.set_item("code", numpy.call_method1("array", (Vec::<String>::new(),))?)?;
            dict.set_item("factors", numpy.call_method1("array", (Vec::<Vec<f64>>::new(),))?)?;
            Ok(dict.into())
        });
    }
    
    let record_size = header.record_size as usize;
    let factor_count = header.factor_count as usize;
    
    // æ£€æŸ¥åˆ—ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
    if column_start >= factor_count {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            format!("èµ·å§‹åˆ—ç´¢å¼• {} è¶…å‡ºèŒƒå›´ï¼Œå› å­åˆ—æ•°ä¸º {}", column_start, factor_count)
        ));
    }
    
    if column_end >= factor_count {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            format!("ç»“æŸåˆ—ç´¢å¼• {} è¶…å‡ºèŒƒå›´ï¼Œå› å­åˆ—æ•°ä¸º {}", column_end, factor_count)
        ));
    }
    
    let calculated_record_size = calculate_record_size(factor_count);
    if record_size != calculated_record_size {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
           format!("è®°å½•å¤§å°ä¸åŒ¹é…: æ–‡ä»¶å¤´æ˜¾ç¤º {}, è®¡ç®—å¾—åˆ° {}. æ–‡ä»¶å¯èƒ½æŸå.", record_size, calculated_record_size)
       ));
    }

    let expected_size = HEADER_SIZE + record_count * record_size;
    if file_len < expected_size {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            "å¤‡ä»½æ–‡ä»¶ä¼¼ä¹è¢«æˆªæ–­äº†"
        ));
    }
    
    // å¹¶è¡Œè¯»å–æŒ‡å®šåˆ—èŒƒå›´
    let records_start = HEADER_SIZE;
    let num_columns = column_end - column_start + 1;
    let results: Vec<_> = (0..record_count)
        .into_par_iter()
        .filter_map(|i| {
            let record_offset = records_start + i * record_size;
            let record_bytes = &mmap[record_offset..record_offset + record_size];
            
            match DynamicRecord::from_bytes(record_bytes, factor_count) {
                Ok(record) => {
                    // æ£€æŸ¥æ—¥æœŸè¿‡æ»¤å™¨
                    if let Some(date_filter) = date_filter {
                        if !date_filter.contains(&record.date) {
                            return None;
                        }
                    }
                    
                    let code_len = std::cmp::min(record.code_len as usize, 32);
                    let code = String::from_utf8_lossy(&record.code_bytes[..code_len]).to_string();
                    
                    // æ£€æŸ¥ä»£ç è¿‡æ»¤å™¨
                    if let Some(code_filter) = code_filter {
                        if !code_filter.contains(&code) {
                            return None;
                        }
                    }
                    
                    // è·å–æŒ‡å®šåˆ—èŒƒå›´çš„å› å­å€¼
                    let mut factor_values = Vec::with_capacity(num_columns);
                    for col_idx in column_start..=column_end {
                        let factor_value = if col_idx < record.factors.len() {
                            record.factors[col_idx]
                        } else {
                            f64::NAN
                        };
                        factor_values.push(factor_value);
                    }
                    
                    Some((record.date, code, factor_values))
                }
                Err(_) => {
                    // è®°å½•æŸåï¼Œè¿”å›None
                    None
                }
            }
        })
        .collect();
        
    let num_rows = results.len();
    let mut dates = Vec::with_capacity(num_rows);
    let mut codes = Vec::with_capacity(num_rows);
    let mut factors = Vec::with_capacity(num_rows);

    for (date, code, factor_values) in results {
        dates.push(date);
        codes.push(code);
        factors.push(factor_values);
    }

    // åˆ›å»ºPythonå­—å…¸
    Python::with_gil(|py| {
        let numpy = py.import("numpy")?;
        let dict = pyo3::types::PyDict::new(py);

        dict.set_item("date", numpy.call_method1("array", (dates,))?)?;
        dict.set_item("code", numpy.call_method1("array", (codes,))?)?;
        dict.set_item("factors", numpy.call_method1("array", (factors,))?)?;

        Ok(dict.into())
    })
}

fn read_legacy_backup_results_columns_range_with_filter(file_path: &str, column_start: usize, column_end: usize, date_filter: Option<&HashSet<i64>>, code_filter: Option<&HashSet<String>>) -> PyResult<PyObject> {
    let mut file = File::open(file_path)
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("æ— æ³•æ‰“å¼€å¤‡ä»½æ–‡ä»¶: {}", e)))?;
    
    let mut buffer = Vec::new();
    file.read_to_end(&mut buffer)
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("æ— æ³•è¯»å–å¤‡ä»½æ–‡ä»¶: {}", e)))?;
    
    if buffer.is_empty() {
        return Python::with_gil(|py| {
            let numpy = py.import("numpy")?;
            let dict = pyo3::types::PyDict::new(py);
            dict.set_item("date", numpy.call_method1("array", (Vec::<i64>::new(),))?)?;
            dict.set_item("code", numpy.call_method1("array", (Vec::<String>::new(),))?)?;
            dict.set_item("factors", numpy.call_method1("array", (Vec::<Vec<f64>>::new(),))?)?;
            Ok(dict.into())
        });
    }
    
    let mut cursor = 0;
    let mut all_results = Vec::new();
    
    // å°è¯•æ–°çš„æ‰¹æ¬¡æ ¼å¼
    while cursor + 8 <= buffer.len() {
        let size_bytes = &buffer[cursor..cursor + 8];
        let batch_size = u64::from_le_bytes([
            size_bytes[0], size_bytes[1], size_bytes[2], size_bytes[3],
            size_bytes[4], size_bytes[5], size_bytes[6], size_bytes[7],
        ]) as usize;
        
        cursor += 8;
        
        if cursor + batch_size > buffer.len() {
            cursor -= 8;
            break;
        }
        
        match bincode::deserialize::<Vec<TaskResult>>(&buffer[cursor..cursor + batch_size]) {
            Ok(batch) => {
                for result in batch {
                    // æ£€æŸ¥æ—¥æœŸè¿‡æ»¤å™¨
                    if let Some(date_filter) = date_filter {
                        if !date_filter.contains(&result.date) {
                            continue;
                        }
                    }
                    
                    // æ£€æŸ¥ä»£ç è¿‡æ»¤å™¨
                    if let Some(code_filter) = code_filter {
                        if !code_filter.contains(&result.code) {
                            continue;
                        }
                    }
                    
                    // æ£€æŸ¥åˆ—ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
                    if column_start >= result.facs.len() {
                        continue;
                    }
                    
                    let actual_end = std::cmp::min(column_end, result.facs.len() - 1);
                    if actual_end < column_start {
                        continue;
                    }
                    
                    let num_columns = actual_end - column_start + 1;
                    let mut factor_values = Vec::with_capacity(num_columns);
                    for col_idx in column_start..=actual_end {
                        factor_values.push(result.facs[col_idx]);
                    }
                    
                    all_results.push((result.date, result.code, factor_values));
                }
                cursor += batch_size;
            }
            Err(_) => {
                cursor -= 8;
                break;
            }
        }
    }
    
    // å¦‚æœå¤±è´¥ï¼Œå°è¯•åŸå§‹æ ¼å¼
    if cursor < buffer.len() {
        while cursor < buffer.len() {
            match bincode::deserialize::<Vec<TaskResult>>(&buffer[cursor..]) {
                Ok(batch) => {
                    let batch_size = bincode::serialized_size(&batch).unwrap_or(0) as usize;
                    
                    for result in batch {
                        // æ£€æŸ¥æ—¥æœŸè¿‡æ»¤å™¨
                        if let Some(date_filter) = date_filter {
                            if !date_filter.contains(&result.date) {
                                continue;
                            }
                        }
                        
                        // æ£€æŸ¥ä»£ç è¿‡æ»¤å™¨
                        if let Some(code_filter) = code_filter {
                            if !code_filter.contains(&result.code) {
                                continue;
                            }
                        }
                        
                        // æ£€æŸ¥åˆ—ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
                        if column_start >= result.facs.len() {
                            continue;
                        }
                        
                        let actual_end = std::cmp::min(column_end, result.facs.len() - 1);
                        if actual_end < column_start {
                            continue;
                        }
                        
                        let num_columns = actual_end - column_start + 1;
                        let mut factor_values = Vec::with_capacity(num_columns);
                        for col_idx in column_start..=actual_end {
                            factor_values.push(result.facs[col_idx]);
                        }
                        
                        all_results.push((result.date, result.code, factor_values));
                    }
                    cursor += batch_size;
                }
                Err(_) => {
                    cursor += std::cmp::min(64, buffer.len() - cursor);
                }
            }
        }
    }
    
    // æ•´ç†ç»“æœ
    let num_rows = all_results.len();
    let mut dates = Vec::with_capacity(num_rows);
    let mut codes = Vec::with_capacity(num_rows);
    let mut factors = Vec::with_capacity(num_rows);
    
    for (date, code, factor_values) in all_results {
        dates.push(date);
        codes.push(code);
        factors.push(factor_values);
    }
    
    // åˆ›å»ºPythonå­—å…¸
    Python::with_gil(|py| {
        let numpy = py.import("numpy")?;
        let dict = pyo3::types::PyDict::new(py);

        dict.set_item("date", numpy.call_method1("array", (dates,))?)?;
        dict.set_item("code", numpy.call_method1("array", (codes,))?)?;
        dict.set_item("factors", numpy.call_method1("array", (factors,))?)?;

        Ok(dict.into())
    })
}

// æ”¯æŒæ—§æ ¼å¼çš„å•åˆ—è¯»å–
fn read_legacy_backup_results_single_column_with_filter(file_path: &str, column_index: usize, date_filter: Option<&HashSet<i64>>, code_filter: Option<&HashSet<String>>) -> PyResult<PyObject> {
    let mut file = File::open(file_path)
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("æ— æ³•æ‰“å¼€å¤‡ä»½æ–‡ä»¶: {}", e)))?;
    
    let mut buffer = Vec::new();
    file.read_to_end(&mut buffer)
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("æ— æ³•è¯»å–å¤‡ä»½æ–‡ä»¶: {}", e)))?;
    
    if buffer.is_empty() {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            "å¤‡ä»½æ–‡ä»¶ä¸ºç©º"
        ));
    }
    
    let mut all_results = Vec::new();
    let mut cursor = 0;
    
    // å°è¯•æ–°çš„æ‰¹æ¬¡æ ¼å¼ï¼ˆå¸¦å¤§å°å¤´ï¼‰
    while cursor + 8 <= buffer.len() {
        let size_bytes = &buffer[cursor..cursor + 8];
        let batch_size = u64::from_le_bytes([
            size_bytes[0], size_bytes[1], size_bytes[2], size_bytes[3],
            size_bytes[4], size_bytes[5], size_bytes[6], size_bytes[7],
        ]) as usize;
        
        cursor += 8;
        
        if cursor + batch_size > buffer.len() {
            cursor -= 8;
            break;
        }
        
        match bincode::deserialize::<Vec<TaskResult>>(&buffer[cursor..cursor + batch_size]) {
            Ok(batch) => {
                for result in batch {
                    // æ£€æŸ¥æ—¥æœŸè¿‡æ»¤å™¨
                    if let Some(date_filter) = date_filter {
                        if !date_filter.contains(&result.date) {
                            continue;
                        }
                    }
                    
                    // æ£€æŸ¥ä»£ç è¿‡æ»¤å™¨
                    if let Some(code_filter) = code_filter {
                        if !code_filter.contains(&result.code) {
                            continue;
                        }
                    }
                    
                    all_results.push(result);
                }
                cursor += batch_size;
            }
            Err(_) => {
                cursor -= 8;
                break;
            }
        }
    }
    
    // å¦‚æœå¤±è´¥ï¼Œå°è¯•åŸå§‹æ ¼å¼
    if cursor < buffer.len() {
        while cursor < buffer.len() {
            match bincode::deserialize::<Vec<TaskResult>>(&buffer[cursor..]) {
                Ok(batch) => {
                    let batch_size = bincode::serialized_size(&batch)
                        .map_err(|e| PyErr::new::<pyo3::exceptions::PyValueError, _>(format!("åºåˆ—åŒ–é”™è¯¯: {}", e)))? as usize;
                    for result in batch {
                        // æ£€æŸ¥æ—¥æœŸè¿‡æ»¤å™¨
                        if let Some(date_filter) = date_filter {
                            if !date_filter.contains(&result.date) {
                                continue;
                            }
                        }
                        
                        // æ£€æŸ¥ä»£ç è¿‡æ»¤å™¨
                        if let Some(code_filter) = code_filter {
                            if !code_filter.contains(&result.code) {
                                continue;
                            }
                        }
                        
                        all_results.push(result);
                    }
                    cursor += batch_size;
                }
                Err(_) => {
                    cursor += std::cmp::min(64, buffer.len() - cursor);
                }
            }
        }
    }
    
    if all_results.is_empty() {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            "å¤‡ä»½æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆç»“æœ"
        ));
    }
    
    // æ£€æŸ¥åˆ—ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
    if let Some(first_result) = all_results.first() {
        if column_index >= first_result.facs.len() {
            return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
                format!("åˆ—ç´¢å¼• {} è¶…å‡ºèŒƒå›´ï¼Œå› å­åˆ—æ•°ä¸º {}", column_index, first_result.facs.len())
            ));
        }
    }
    
    // æå–æŒ‡å®šåˆ—çš„æ•°æ®
    let mut dates = Vec::with_capacity(all_results.len());
    let mut codes = Vec::with_capacity(all_results.len());
    let mut factors = Vec::with_capacity(all_results.len());
    
    for result in all_results {
        dates.push(result.date);
        codes.push(result.code);
        let factor_value = if column_index < result.facs.len() {
            result.facs[column_index]
        } else {
            f64::NAN
        };
        factors.push(factor_value);
    }
    
    // åˆ›å»ºPythonå­—å…¸
    Python::with_gil(|py| {
        let numpy = py.import("numpy")?;
        let dict = pyo3::types::PyDict::new(py);

        dict.set_item("date", numpy.call_method1("array", (dates,))?)?;
        dict.set_item("code", numpy.call_method1("array", (codes,))?)?;
        dict.set_item("factor", numpy.call_method1("array", (factors,))?)?;

        Ok(dict.into())
    })
}

/// ç»ˆæç‰ˆæœ¬ï¼šçº¿ç¨‹å®‰å…¨çš„å¹¶è¡Œ+é›¶åˆ†é…+ç¼“å­˜ä¼˜åŒ–
#[allow(dead_code)]
fn read_backup_results_ultra_fast_v4(file_path: &str) -> PyResult<PyObject> {
    read_backup_results_ultra_fast_v4_with_filter(file_path, None, None)
}

fn read_backup_results_ultra_fast_v4_with_filter(file_path: &str, date_filter: Option<&HashSet<i64>>, code_filter: Option<&HashSet<String>>) -> PyResult<PyObject> {
    if !Path::new(file_path).exists() {
        return Err(PyErr::new::<pyo3::exceptions::PyFileNotFoundError, _>(
            "Backup file not found"
        ));
    }
    
    let file = File::open(file_path)
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("Failed to open backup file: {}", e)))?;
    
    let file_len = file.metadata()
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("Failed to get file metadata: {}", e)))?
        .len() as usize;
    
    if file_len < HEADER_SIZE {
        return read_legacy_backup_results_with_filter(file_path, date_filter, code_filter);
    }
    
    // å†…å­˜æ˜ å°„
    let mmap = unsafe { 
        Mmap::map(&file)
            .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("Failed to memory map file: {}", e)))?
    };
    let mmap = Arc::new(mmap);
    
    // è¯»å–æ–‡ä»¶å¤´
    let header = unsafe {
        &*(mmap.as_ptr() as *const FileHeader)
    };
    
    if &header.magic != b"RPBACKUP" {
        return read_legacy_backup_results_with_filter(file_path, date_filter, code_filter);
    }
    
    let record_count = header.record_count as usize;
    if record_count == 0 {
        return Python::with_gil(|py| Ok(pyo3::types::PyDict::new(py).into()));
    }
    
    // --- BUGä¿®å¤ï¼šä½¿ç”¨æ–‡ä»¶å¤´ä¸­çš„ record_size ---
    let record_size = header.record_size as usize;
    let factor_count = header.factor_count as usize;

    let calculated_record_size = calculate_record_size(factor_count);
    if record_size != calculated_record_size {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
           format!("Record size mismatch: header says {}, calculated {}. File may be corrupt.", record_size, calculated_record_size)
       ));
    }

    let expected_size = HEADER_SIZE + record_count * record_size;
    if file_len < expected_size {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            "Backup file appears to be truncated"
        ));
    }
    
    // --- è¿”å›ç±»å‹ä¿®æ”¹ï¼šå¹¶è¡Œæ”¶é›†ä¸ºå…ƒç»„ï¼Œå†è½¬æ¢ä¸ºPythonå­—å…¸ ---
    let records_start = HEADER_SIZE;
    let results: Vec<_> = (0..record_count)
        .into_par_iter()
        .filter_map(|i| {
            let record_offset = records_start + i * record_size;
            let record_bytes = &mmap[record_offset..record_offset + record_size];
            
            match DynamicRecord::from_bytes(record_bytes, factor_count) {
                Ok(record) => {
                    // æ£€æŸ¥æ—¥æœŸè¿‡æ»¤å™¨
                    if let Some(date_filter) = date_filter {
                        if !date_filter.contains(&record.date) {
                            return None;
                        }
                    }
                    
                    let code_len = std::cmp::min(record.code_len as usize, 32);
                    let code = String::from_utf8_lossy(&record.code_bytes[..code_len]).to_string();
                    
                    // æ£€æŸ¥ä»£ç è¿‡æ»¤å™¨
                    if let Some(code_filter) = code_filter {
                        if !code_filter.contains(&code) {
                            return None;
                        }
                    }
                    
                    Some((record.date, code, record.timestamp, record.factors))
                }
                Err(_) => {
                    // è®°å½•æŸåï¼Œè¿”å›Noneè€Œä¸æ˜¯é»˜è®¤å€¼
                    None
                }
            }
        })
        .collect();
        
    let num_rows = results.len();
    let mut dates = Vec::with_capacity(num_rows);
    let mut codes = Vec::with_capacity(num_rows);
    let mut timestamps = Vec::with_capacity(num_rows);
    let mut factors_flat = Vec::with_capacity(num_rows * factor_count);

    for (date, code, timestamp, facs) in results {
        dates.push(date);
        codes.push(code);
        timestamps.push(timestamp);
        if facs.len() == factor_count {
            factors_flat.extend_from_slice(&facs);
        } else {
            factors_flat.resize(factors_flat.len() + factor_count, f64::NAN);
        }
    }

    // åˆ›å»ºNumpyæ•°ç»„å­—å…¸
    Python::with_gil(|py| {
        let numpy = py.import("numpy")?;
        let dict = pyo3::types::PyDict::new(py);

        dict.set_item("date", numpy.call_method1("array", (dates,))?)?;
        dict.set_item("code", numpy.call_method1("array", (codes,))?)?;
        dict.set_item("timestamp", numpy.call_method1("array", (timestamps,))?)?;
        
        let factors_array = numpy.call_method1("array", (factors_flat,))?;
        
        if num_rows > 0 && factor_count > 0 {
            let factors_reshaped = factors_array.call_method1("reshape", ((num_rows, factor_count),))?;
            dict.set_item("factors", factors_reshaped)?;
        } else {
            dict.set_item("factors", factors_array)?;
        }

        Ok(dict.into())
    })
}

fn run_persistent_task_worker(
    worker_id: usize,
    task_queue: Receiver<TaskParam>,
    python_code: String,
    expected_result_length: usize,
    python_path: String,
    result_sender: Sender<TaskResult>,
    restart_flag: Arc<AtomicBool>,
    monitor_manager: Arc<WorkerMonitorManager>,
) {
    // å‘ç›‘æ§ç®¡ç†å™¨æ³¨å†Œworker
    monitor_manager.add_worker(worker_id);
    
    loop { // å¾ªç¯ä»¥æ”¯æŒworkeré‡å¯
        if restart_flag.compare_exchange(true, false, Ordering::SeqCst, Ordering::Relaxed).is_ok() {
            // println!("ğŸ”„ Worker {} æ£€æµ‹åˆ°é‡å¯ä¿¡å·ï¼Œæ­£åœ¨é‡å¯...", worker_id);
        }

        // println!("ğŸš€ Persistent Worker {} å¯åŠ¨ï¼Œåˆ›å»ºæŒä¹…Pythonè¿›ç¨‹", worker_id);
        
        let script_content = create_persistent_worker_script();
        let script_path = format!("/tmp/persistent_worker_{}.py", worker_id);
        
        // åˆ›å»ºworkerè„šæœ¬
        if let Err(e) = std::fs::write(&script_path, script_content) {
            eprintln!("âŒ Worker {} åˆ›å»ºè„šæœ¬å¤±è´¥: {}", worker_id, e);
            continue; // ç»§ç»­å¤–å±‚å¾ªç¯ï¼Œå°è¯•é‡æ–°åˆ›å»ºè„šæœ¬
        }
        
        // å¯åŠ¨æŒä¹…çš„Pythonå­è¿›ç¨‹
        let mut child = match Command::new(&python_path)
            .arg(&script_path)
            .stdin(Stdio::piped())
            .stdout(Stdio::piped())
            .stderr(Stdio::piped())
            .spawn()
        {
            Ok(child) => child,
            Err(e) => {
                eprintln!("âŒ Worker {} å¯åŠ¨Pythonè¿›ç¨‹å¤±è´¥: {}", worker_id, e);
                continue; // ç»§ç»­å¤–å±‚å¾ªç¯ï¼Œå°è¯•é‡æ–°å¯åŠ¨è¿›ç¨‹
            }
        };
        
        // è®¾ç½®å­è¿›ç¨‹IDåˆ°ç›‘æ§ç®¡ç†å™¨
        let pid = child.id();
        monitor_manager.set_worker_process_id(worker_id, pid);
        monitor_manager.update_heartbeat(worker_id);
        
        let mut stdin = child.stdin.take().expect("Failed to get stdin");
        let mut stdout = child.stdout.take().expect("Failed to get stdout");
        
        let mut task_count = 0;
        let mut needs_restart = false;

        // æŒç»­ä»é˜Ÿåˆ—ä¸­å–ä»»åŠ¡å¹¶å‘é€ç»™Pythonè¿›ç¨‹
        while let Ok(task) = task_queue.recv() {
            // åœ¨å¤„ç†ä»»åŠ¡å‰æ£€æŸ¥é‡å¯æ ‡å¿—
            if restart_flag.load(Ordering::Relaxed) {
                needs_restart = true;
                break;
            }

            task_count += 1;
            
            // é€šçŸ¥ç›‘æ§ç®¡ç†å™¨å¼€å§‹å¤„ç†ä»»åŠ¡
            monitor_manager.start_task(worker_id, task.clone());
            monitor_manager.update_heartbeat(worker_id);
            
            // åˆ›å»ºå•ä»»åŠ¡æ•°æ®
            let single_task = SingleTask {
                python_code: python_code.clone(),
                task: task.clone(),
                expected_result_length,
            };
            
            // åºåˆ—åŒ–ä»»åŠ¡æ•°æ®
            let packed_data = match rmp_serde::to_vec_named(&single_task) {
                Ok(data) => data,
                Err(_e) => {
                    // eprintln!("âŒ Worker {} ä»»åŠ¡ #{} åºåˆ—åŒ–å¤±è´¥: {}", worker_id, task_count, e);
                    continue;
                }
            };
            
            // å‘é€ä»»åŠ¡åˆ°Pythonè¿›ç¨‹ï¼ˆå¸¦é•¿åº¦å‰ç¼€ï¼‰
            let length = packed_data.len() as u32;
            let length_bytes = length.to_le_bytes();
            
            if let Err(_e) = stdin.write_all(&length_bytes) {
                // eprintln!("âŒ Worker {} å‘é€é•¿åº¦å‰ç¼€å¤±è´¥: {}", worker_id, e);
                needs_restart = true;
                break;
            }
            
            if let Err(_e) = stdin.write_all(&packed_data) {
                // eprintln!("âŒ Worker {} å‘é€ä»»åŠ¡æ•°æ®å¤±è´¥: {}", worker_id, e);
                needs_restart = true;
                break;
            }
            
            if let Err(_e) = stdin.flush() {
                // eprintln!("âŒ Worker {} flushå¤±è´¥: {}", worker_id, e);
                needs_restart = true;
                break;
            }
            
            // è¯»å–ç»“æœï¼ˆå¸¦é•¿åº¦å‰ç¼€ï¼‰
            let mut length_bytes = [0u8; 4];
            if let Err(_e) = stdout.read_exact(&mut length_bytes) {
                // eprintln!("âŒ Worker {} è¯»å–ç»“æœé•¿åº¦å¤±è´¥: {}", worker_id, e);
                needs_restart = true;
                break;
            }
            
            let length = u32::from_le_bytes(length_bytes) as usize;
            let mut result_data = vec![0u8; length];
            
            if let Err(_e) = stdout.read_exact(&mut result_data) {
                // eprintln!("âŒ Worker {} è¯»å–ç»“æœæ•°æ®å¤±è´¥: {}", worker_id, e);
                needs_restart = true;
                break;
            }
            
            // è§£æç»“æœ
            #[derive(Debug, Serialize, Deserialize)]
            struct SingleResult {
                result: TaskResult,
            }
            
            match rmp_serde::from_slice::<SingleResult>(&result_data) {
                Ok(single_result) => {
                    // å‘é€ç»“æœ
                    if let Err(e) = result_sender.send(single_result.result) {
                        eprintln!("âŒ Worker {} ä»»åŠ¡ #{} ç»“æœå‘é€å¤±è´¥: {}", worker_id, task_count, e);
                        // ç»“æœå‘é€å¤±è´¥å¯èƒ½æ˜¯æ”¶é›†å™¨å·²é€€å‡ºï¼Œä½†ä¸å½±å“å…¶ä»–workerï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªä»»åŠ¡
                        // ä¸è®¾ç½®needs_restartï¼Œé¿å…ä¸å¿…è¦çš„å­è¿›ç¨‹é‡å¯
                    }
                    // é€šçŸ¥ç›‘æ§ç®¡ç†å™¨ä»»åŠ¡å·²å®Œæˆ
                    monitor_manager.finish_task(worker_id);
                    monitor_manager.update_heartbeat(worker_id);
                }
                Err(e) => {
                    eprintln!("âŒ Worker {} ä»»åŠ¡ #{} ç»“æœè§£æå¤±è´¥: {}", worker_id, task_count, e);
                    
                    // å‘é€NaNç»“æœ
                    let error_result = TaskResult {
                        date: task.date,
                        code: task.code,
                        timestamp: chrono::Utc::now().timestamp_millis(),
                        facs: vec![f64::NAN; expected_result_length],
                    };
                    
                    if let Err(e) = result_sender.send(error_result) {
                        eprintln!("âŒ Worker {} é”™è¯¯ç»“æœå‘é€å¤±è´¥: {}", worker_id, e);
                        // é”™è¯¯ç»“æœå‘é€å¤±è´¥ä¹Ÿä¸å½±å“å…¶ä»–workerï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªä»»åŠ¡
                        // ä¸è®¾ç½®needs_restartï¼Œé¿å…ä¸å¿…è¦çš„å­è¿›ç¨‹é‡å¯
                    }
                    // é€šçŸ¥ç›‘æ§ç®¡ç†å™¨ä»»åŠ¡å·²å®Œæˆï¼ˆå³ä½¿å¤±è´¥ï¼‰
                    monitor_manager.finish_task(worker_id);
                    monitor_manager.update_heartbeat(worker_id);
                }
            }
        }
        
        // å‘é€ç»“æŸä¿¡å·ï¼ˆé•¿åº¦ä¸º0ï¼‰
        let _ = stdin.write_all(&[0u8; 4]);
        let _ = stdin.flush();
        
        // ç­‰å¾…å­è¿›ç¨‹ç»“æŸ
        let _ = child.wait();
        
        // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        let _ = std::fs::remove_file(&script_path);
        // println!("ğŸ Persistent Worker {} ç»“æŸï¼Œå…±å¤„ç† {} ä¸ªä»»åŠ¡", worker_id, task_count);
        
        if !needs_restart {
            // å¦‚æœä¸æ˜¯å› ä¸ºé‡å¯ä¿¡å·è€Œé€€å‡ºï¼Œè¯´æ˜æ‰€æœ‰ä»»åŠ¡éƒ½å®Œæˆäº†
            break;
        }
    }
    
    // Workerå®Œå…¨ç»“æŸæ—¶ï¼Œä»ç›‘æ§å™¨ä¸­ç§»é™¤è®°å½•
    monitor_manager.remove_worker(worker_id);
}


#[pyfunction]
#[pyo3(signature = (python_function, args, n_jobs, backup_file, expected_result_length, restart_interval=None, update_mode=None, return_results=None, task_timeout=None, health_check_interval=None, debug_monitor=None))]
pub fn run_pools_queue(
    python_function: PyObject,
    args: &PyList,
    n_jobs: usize,
    backup_file: String,
    expected_result_length: usize,
    restart_interval: Option<usize>,
    update_mode: Option<bool>,
    return_results: Option<bool>,
    task_timeout: Option<u64>,
    health_check_interval: Option<u64>,
    debug_monitor: Option<bool>,
) -> PyResult<PyObject> {
    // å¤„ç† restart_interval å‚æ•°
    let restart_interval_value = restart_interval.unwrap_or(200);
    if restart_interval_value == 0 {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            "restart_interval must be greater than 0"
        ));
    }
    
    // å¤„ç† update_mode å‚æ•°
    let update_mode_enabled = update_mode.unwrap_or(false);
    
    // å¤„ç† return_results å‚æ•°
    let return_results_enabled = return_results.unwrap_or(true);
    
    // å¤„ç†æ–°çš„ç›‘æ§å‚æ•°
    let task_timeout_secs = task_timeout.unwrap_or(120);
    let health_check_interval_secs = health_check_interval.unwrap_or(120);
    let debug_monitor_enabled = debug_monitor.unwrap_or(false);
    
    let task_timeout_duration = Duration::from_secs(task_timeout_secs);
    let health_check_duration = Duration::from_secs(health_check_interval_secs);
    
    if debug_monitor_enabled {
        println!("ğŸ” ç›‘æ§é…ç½®: ä»»åŠ¡è¶…æ—¶={}s, å¥åº·æ£€æŸ¥é—´éš”={}s", 
                 task_timeout_secs, health_check_interval_secs);
    }
    
    // è§£æå‚æ•°
    let mut all_tasks = Vec::new();
    for item in args.iter() {
        let task_args: &PyList = item.extract()?;
        if task_args.len() != 2 {
            return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
                "Each task should have exactly 2 parameters: date and code"
            ));
        }
        
        let date: i64 = task_args.get_item(0)?.extract()?;
        let code: String = task_args.get_item(1)?.extract()?;
        
        all_tasks.push(TaskParam { date, code });
    }
    
    // ä¿å­˜æ‰€æœ‰ä»»åŠ¡çš„å‰¯æœ¬ä»¥ä¾¿åç»­ä½¿ç”¨
    let all_tasks_clone = all_tasks.clone();
    
    // è¯»å–ç°æœ‰å¤‡ä»½ï¼Œè¿‡æ»¤å·²å®Œæˆçš„ä»»åŠ¡
    let existing_tasks = if update_mode_enabled {
        // update_modeå¼€å¯æ—¶ï¼Œåªè¯»å–ä¼ å…¥å‚æ•°ä¸­æ¶‰åŠçš„æ—¥æœŸ
        let task_dates: HashSet<i64> = all_tasks.iter().map(|t| t.date).collect();
        read_existing_backup_with_filter(&backup_file, Some(&task_dates))
            .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("Failed to read backup: {}", e)))?
    } else {
        // æ­£å¸¸æ¨¡å¼ï¼Œè¯»å–æ‰€æœ‰å¤‡ä»½æ•°æ®
        read_existing_backup(&backup_file)
            .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("Failed to read backup: {}", e)))?
    };
    
    let pending_tasks: Vec<TaskParam> = all_tasks
        .into_iter()
        .filter(|task| !existing_tasks.contains(&(task.date, task.code.clone())))
        .collect();
    
    if pending_tasks.is_empty() {
        // æ‰€æœ‰ä»»åŠ¡éƒ½å·²å®Œæˆï¼Œç›´æ¥è¿”å›ç»“æœ
        return if return_results_enabled {
            // ä½¿ç”¨è‡ªå®šä¹‰çº¿ç¨‹æ± é¿å…èµ„æºç«äº‰
            let pool = rayon::ThreadPoolBuilder::new()
                .num_threads(std::cmp::min(rayon::current_num_threads(), 4))
                .build()
                .map_err(|e| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(format!("åˆ›å»ºè¯»å–çº¿ç¨‹æ± å¤±è´¥: {}", e)))?;
            
            pool.install(|| {
                if update_mode_enabled {
                    // update_modeä¸‹ï¼Œåªè¿”å›ä¼ å…¥å‚æ•°ä¸­æ¶‰åŠçš„æ—¥æœŸå’Œä»£ç 
                    let task_dates: HashSet<i64> = all_tasks_clone.iter().map(|t| t.date).collect();
                    let task_codes: HashSet<String> = all_tasks_clone.iter().map(|t| t.code.clone()).collect();
                    read_backup_results_with_filter(&backup_file, Some(&task_dates), Some(&task_codes))
                } else {
                    read_backup_results(&backup_file)
                }
            })
        } else {
            println!("âœ… æ‰€æœ‰ä»»åŠ¡éƒ½å·²å®Œæˆï¼Œä¸è¿”å›ç»“æœ");
            Python::with_gil(|py| Ok(py.None()))
        };
    }
    
    let start_time = Instant::now();
    if update_mode_enabled {
        // update_modeä¸‹ï¼Œåªæ˜¾ç¤ºä¼ å…¥ä»»åŠ¡çš„ç»Ÿè®¡ä¿¡æ¯
        println!("[{}] ğŸ“‹ ä¼ å…¥ä»»åŠ¡æ•°: {}, å¾…å¤„ç†: {}, å·²å®Œæˆ: {}", 
                 Local::now().format("%Y-%m-%d %H:%M:%S"),
                 all_tasks_clone.len(), pending_tasks.len(), existing_tasks.len());
    } else {
        // æ­£å¸¸æ¨¡å¼ï¼Œæ˜¾ç¤ºæ€»çš„ç»Ÿè®¡ä¿¡æ¯
        println!("[{}] ğŸ“‹ æ€»ä»»åŠ¡æ•°: {}, å¾…å¤„ç†: {}, å·²å®Œæˆ: {}", 
                 Local::now().format("%Y-%m-%d %H:%M:%S"),
                 pending_tasks.len() + existing_tasks.len(), pending_tasks.len(), existing_tasks.len());
    }
    
    // æå–Pythonå‡½æ•°ä»£ç 
    let python_code = extract_python_function_code(&python_function)?;
    
    // è·å–Pythonè§£é‡Šå™¨è·¯å¾„
    let python_path = detect_python_interpreter();
    
    // åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—å’Œç»“æœæ”¶é›†é€šé“
    let (task_sender, task_receiver) = unbounded::<TaskParam>();
    let (result_sender, result_receiver) = unbounded::<TaskResult>();
    
    // å°†æ‰€æœ‰å¾…å¤„ç†ä»»åŠ¡æ”¾å…¥é˜Ÿåˆ—
    for task in pending_tasks.clone() {
        if let Err(e) = task_sender.send(task) {
            return Err(PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(
                format!("Failed to send task to queue: {}", e)
            ));
        }
    }
    drop(task_sender); // å…³é—­ä»»åŠ¡é˜Ÿåˆ—ï¼Œworkerä¼šåœ¨é˜Ÿåˆ—ç©ºæ—¶é€€å‡º
    
    let restart_flag = Arc::new(AtomicBool::new(false));
    
    // åˆ›å»ºç›‘æ§ç®¡ç†å™¨
    let monitor_manager = Arc::new(WorkerMonitorManager::new(
        task_timeout_duration,
        health_check_duration,
        debug_monitor_enabled,
    ));
    
    println!("[{}] ğŸš€ å¯åŠ¨ {} ä¸ªworkerå¤„ç† {} ä¸ªä»»åŠ¡", Local::now().format("%Y-%m-%d %H:%M:%S"), n_jobs, pending_tasks.len());
    
    // å¯åŠ¨workerçº¿ç¨‹
    let mut worker_handles = Vec::new();
    for i in 0..n_jobs {
        let worker_task_receiver = task_receiver.clone();
        let worker_python_code = python_code.clone();
        let worker_python_path = python_path.clone();
        let worker_result_sender = result_sender.clone();
        let worker_restart_flag = restart_flag.clone();
        let worker_monitor_manager = monitor_manager.clone();
        
        let handle = thread::spawn(move || {
            run_persistent_task_worker(
                i,
                worker_task_receiver,
                worker_python_code,
                expected_result_length,
                worker_python_path,
                worker_result_sender,
                worker_restart_flag,
                worker_monitor_manager,
            );
        });
        
        worker_handles.push(handle);
    }
    
    // å…³é—­ä¸»çº¿ç¨‹çš„result_sender
    drop(result_sender);
    
    // å¯åŠ¨ç›‘æ§çº¿ç¨‹
    let monitor_manager_clone = monitor_manager.clone();
    let monitor_restart_flag = restart_flag.clone();
    let monitor_handle = thread::spawn(move || {
        loop {
            // æ£€æŸ¥æ˜¯å¦åº”è¯¥é€€å‡ºç›‘æ§å¾ªç¯
            if monitor_manager_clone.should_stop_monitoring() {
                println!("[{}] ğŸ” ç›‘æ§å™¨: æ¥æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨é€€å‡ºç›‘æ§å¾ªç¯", 
                         Local::now().format("%Y-%m-%d %H:%M:%S"));
                break;
            }
            
            // æ£€æŸ¥å¡æ­»çš„worker
            let stuck_workers = monitor_manager_clone.check_stuck_workers();
            if !stuck_workers.is_empty() {
                for (worker_id, reason) in stuck_workers {
                    monitor_manager_clone.log_stuck_worker(worker_id, reason);
                    
                    // å°è¯•å¼ºåˆ¶ç»ˆæ­¢å¡æ­»çš„workerè¿›ç¨‹
                    if monitor_manager_clone.force_kill_worker(worker_id) {
                        // ç®€åŒ–è¾“å‡ºï¼Œé¿å…é¢‘ç¹æ‰“æ–­è¿è¡Œæµç¨‹
                        if monitor_manager_clone.debug_monitor {
                            println!("ğŸ”„ å·²å¼ºåˆ¶ç»ˆæ­¢Worker {} (åŸå› : {}), workerå°†è‡ªåŠ¨é‡å¯", worker_id, reason);
                        }
                    }
                }
                
                // è§¦å‘é‡å¯ï¼ˆé€šè¿‡è®¾ç½®é‡å¯æ ‡å¿—ï¼Œworkerä¼šæ£€æµ‹åˆ°å¹¶é‡å¯ï¼‰
                monitor_restart_flag.store(true, Ordering::SeqCst);
                
                // ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©workeræ£€æµ‹åˆ°é‡å¯ä¿¡å·
                thread::sleep(Duration::from_millis(100));
                
                // é‡ç½®é‡å¯æ ‡å¿—ï¼Œä¸ºä¸‹æ¬¡ç›‘æ§åšå‡†å¤‡
                monitor_restart_flag.store(false, Ordering::SeqCst);
            }
            
            // ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
            thread::sleep(monitor_manager_clone.health_check_interval);
        }
    });
    
    // å¯åŠ¨ç»“æœæ”¶é›†å™¨
    let backup_file_clone = backup_file.clone();
    let expected_result_length_clone = expected_result_length;
    let pending_tasks_len = pending_tasks.len();
    let collector_restart_flag = restart_flag.clone();
    let restart_interval_clone = restart_interval_value;
    let collector_handle = thread::spawn(move || {
        let mut batch_results = Vec::new();
        let mut total_collected = 0;
        let mut batch_count = 0;
        let mut batch_count_this_chunk = 0;
        let total_batches = (pending_tasks_len + 999) / 1000;
        
        println!("[{}] ğŸ”„ ç»“æœæ”¶é›†å™¨å¯åŠ¨ï¼Œç­‰å¾…workerç»“æœ...", Local::now().format("%Y-%m-%d %H:%M:%S"));
        
        while let Ok(result) = result_receiver.recv() {
            total_collected += 1;
            batch_results.push(result);
            
            // println!("ğŸ“¥ æ”¶åˆ°ä»»åŠ¡ç»“æœ: date={}, code={}, å½“å‰æ‰¹æ¬¡: {}, æ€»æ”¶é›†: {}", 
            //          batch_results.last().unwrap().date,
            //          batch_results.last().unwrap().code,
            //          batch_results.len(), 
            //          total_collected);
            
            // æ¯1000ä¸ªç»“æœå¤‡ä»½ä¸€æ¬¡
            if batch_results.len() >= 1000 {
                batch_count += 1;
                batch_count_this_chunk += 1;
                
                let elapsed = start_time.elapsed();
                let elapsed_secs = elapsed.as_secs();
                let elapsed_h = elapsed_secs / 3600;
                let elapsed_m = (elapsed_secs % 3600) / 60;
                let elapsed_s = elapsed_secs % 60;

                let progress = if total_batches > 0 { batch_count as f64 / total_batches as f64 } else { 1.0 };
                let estimated_total_secs = if progress > 0.0 && progress <= 1.0 { elapsed.as_secs_f64() / progress } else { elapsed.as_secs_f64() };
                let remaining_secs = if estimated_total_secs > elapsed.as_secs_f64() { (estimated_total_secs - elapsed.as_secs_f64()) as u64 } else { 0 };

                let remaining_h = remaining_secs / 3600;
                let remaining_m = (remaining_secs % 3600) / 60;
                let remaining_s = remaining_secs % 60;
                
                let current_time = Local::now().format("%Y-%m-%d %H:%M:%S");
                print!("\r[{}] ğŸ’¾ ç¬¬ {}/{} æ¬¡å¤‡ä»½ã€‚å·²ç”¨{}å°æ—¶{}åˆ†é’Ÿ{}ç§’ï¼Œé¢„ä½™{}å°æ—¶{}åˆ†é’Ÿ{}ç§’", 
                       current_time, batch_count, total_batches, 
                       elapsed_h, elapsed_m, elapsed_s,
                       remaining_h, remaining_m, remaining_s);
                io::stdout().flush().unwrap(); // å¼ºåˆ¶åˆ·æ–°è¾“å‡ºç¼“å†²åŒº
                
                match save_results_to_backup(&batch_results, &backup_file_clone, expected_result_length_clone) {
                    Ok(()) => {
                        // println!("âœ… ç¬¬{}æ¬¡å¤‡ä»½æˆåŠŸï¼", batch_count);
                    }
                    Err(e) => {
                        eprintln!("âŒ ç¬¬{}æ¬¡å¤‡ä»½å¤±è´¥: {}", batch_count, e);
                    }
                }
                batch_results.clear();

                if batch_count_this_chunk >= restart_interval_clone {
                    // println!("\nğŸ”„ è¾¾åˆ°{}æ¬¡å¤‡ä»½ï¼Œè§¦å‘ workers é‡å¯...", restart_interval_clone);
                    collector_restart_flag.store(true, Ordering::SeqCst);
                    batch_count_this_chunk = 0;
                }
            }
        }
        
        // ä¿å­˜å‰©ä½™ç»“æœ
        if !batch_results.is_empty() {
            batch_count += 1;
            println!("[{}] ğŸ’¾ ä¿å­˜æœ€ç»ˆå‰©ä½™ç»“æœ: {} ä¸ª", Local::now().format("%Y-%m-%d %H:%M:%S"), batch_results.len());
            
            match save_results_to_backup(&batch_results, &backup_file_clone, expected_result_length_clone) {
                Ok(()) => {
                    println!("[{}] âœ… æœ€ç»ˆå¤‡ä»½æˆåŠŸï¼", Local::now().format("%Y-%m-%d %H:%M:%S"));
                }
                Err(e) => {
                    eprintln!("âŒ æœ€ç»ˆå¤‡ä»½å¤±è´¥: {}", e);
                }
            }
        }
        
        println!("[{}] ğŸ“Š æ”¶é›†å™¨ç»Ÿè®¡: æ€»æ”¶é›†{}ä¸ªç»“æœï¼Œè¿›è¡Œäº†{}æ¬¡å¤‡ä»½", Local::now().format("%Y-%m-%d %H:%M:%S"), total_collected, batch_count);

    });
    
    // ç­‰å¾…æ‰€æœ‰workerå®Œæˆ
    println!("[{}] â³ ç­‰å¾…æ‰€æœ‰workerå®Œæˆ...", Local::now().format("%Y-%m-%d %H:%M:%S"));
    for (i, handle) in worker_handles.into_iter().enumerate() {
        match handle.join() {
            Ok(()) => {},
            Err(e) => eprintln!("âŒ Worker {} å¼‚å¸¸: {:?}", i, e),
        }
    }
    
    // ç«‹å³åœæ­¢ç›‘æ§çº¿ç¨‹ï¼Œé¿å…æ£€æŸ¥å·²æ­»è¿›ç¨‹
    if debug_monitor_enabled {
        println!("ğŸ” ç›‘æ§å™¨: æ‰€æœ‰workerå·²å®Œæˆï¼Œç«‹å³åœæ­¢ç›‘æ§");
    }
    monitor_manager.stop_monitoring();
    
    // ç­‰å¾…ç›‘æ§çº¿ç¨‹ç»“æŸ
    println!("[{}] â³ ç­‰å¾…ç›‘æ§çº¿ç¨‹ç»“æŸ...", Local::now().format("%Y-%m-%d %H:%M:%S"));
    match monitor_handle.join() {
        Ok(()) => {
            if debug_monitor_enabled {
                println!("âœ… ç›‘æ§çº¿ç¨‹å·²å®‰å…¨é€€å‡º");
            }
        },
        Err(e) => eprintln!("âŒ ç›‘æ§çº¿ç¨‹å¼‚å¸¸: {:?}", e),
    }
    
    // ç­‰å¾…æ”¶é›†å™¨å®Œæˆ
    println!("[{}] â³ ç­‰å¾…ç»“æœæ”¶é›†å™¨å®Œæˆ...", Local::now().format("%Y-%m-%d %H:%M:%S"));
    match collector_handle.join() {
        Ok(()) => {
            println!("[{}] âœ… ç»“æœæ”¶é›†å™¨å·²å®Œæˆ", Local::now().format("%Y-%m-%d %H:%M:%S"));
            // ç¡®ä¿å¤‡ä»½æ–‡ä»¶çš„æ‰€æœ‰å†™å…¥æ“ä½œå·²åŒæ­¥åˆ°ç£ç›˜
            println!("[{}] ğŸ”„ åŒæ­¥å¤‡ä»½æ–‡ä»¶åˆ°ç£ç›˜...", Local::now().format("%Y-%m-%d %H:%M:%S"));
            if let Ok(file) = std::fs::File::open(&backup_file) {
                let _ = file.sync_all();
            }
        },
        Err(e) => eprintln!("âŒ ç»“æœæ”¶é›†å™¨å¼‚å¸¸: {:?}", e),
    }
    
    // æ‰“å°ç›‘æ§è¯Šæ–­ç»Ÿè®¡
    monitor_manager.print_diagnostic_stats();
    
    // æ‰“å°å¡æ­»ä»»åŠ¡ç»Ÿè®¡è¡¨
    monitor_manager.print_stuck_tasks_table();
    
    // æ˜¾å¼æ¸…ç†ç›‘æ§ç®¡ç†å™¨èµ„æºï¼Œé¿å…ä¸åç»­æ“ä½œå†²çª
    println!("[{}] ğŸ§¹ æ¸…ç†ç›‘æ§å™¨èµ„æº...", Local::now().format("%Y-%m-%d %H:%M:%S"));
    monitor_manager.cleanup();
    
    // æ˜¾å¼é‡Šæ”¾monitor_managerï¼Œç¡®ä¿æ‰€æœ‰Arcå¼•ç”¨è¢«æ¸…ç†
    drop(monitor_manager);
    
    // ç­‰å¾…çŸ­æš‚æ—¶é—´ï¼Œç¡®ä¿æ‰€æœ‰èµ„æºå®Œå…¨é‡Šæ”¾ï¼Œé¿å…æ–‡ä»¶è®¿é—®å†²çª
    println!("[{}] â³ ç­‰å¾…èµ„æºå®Œå…¨é‡Šæ”¾...", Local::now().format("%Y-%m-%d %H:%M:%S"));
    thread::sleep(Duration::from_millis(100));
    
    // è¯»å–å¹¶è¿”å›æœ€ç»ˆç»“æœ
    if return_results_enabled {
        println!("[{}] ğŸ“– è¯»å–æœ€ç»ˆå¤‡ä»½ç»“æœ...", Local::now().format("%Y-%m-%d %H:%M:%S"));
        
        // ç›´æ¥è¯»å–å¤‡ä»½æ–‡ä»¶ï¼Œé¿å…çº¿ç¨‹æ± å†²çª
        println!("[{}] ğŸ” å¼€å§‹è¯»å–å¤‡ä»½æ–‡ä»¶: {}", Local::now().format("%Y-%m-%d %H:%M:%S"), backup_file);
        let start_read_time = Instant::now();
        
        let result = if update_mode_enabled {
            // update_modeä¸‹ï¼Œåªè¿”å›ä¼ å…¥å‚æ•°ä¸­æ¶‰åŠçš„æ—¥æœŸå’Œä»£ç 
            let task_dates: HashSet<i64> = all_tasks_clone.iter().map(|t| t.date).collect();
            let task_codes: HashSet<String> = all_tasks_clone.iter().map(|t| t.code.clone()).collect();
            println!("[{}] ğŸ” ä½¿ç”¨è¿‡æ»¤æ¨¡å¼è¯»å– {} ä¸ªæ—¥æœŸå’Œ {} ä¸ªä»£ç ", 
                    Local::now().format("%Y-%m-%d %H:%M:%S"), 
                    task_dates.len(), 
                    task_codes.len());
            read_backup_results_with_filter(&backup_file, Some(&task_dates), Some(&task_codes))
        } else {
            println!("[{}] ğŸ” è¯»å–å®Œæ•´å¤‡ä»½æ–‡ä»¶", Local::now().format("%Y-%m-%d %H:%M:%S"));
            read_backup_results(&backup_file)
        };
        
        println!("[{}] âœ… å¤‡ä»½æ–‡ä»¶è¯»å–å®Œæˆï¼Œè€—æ—¶: {:?}", 
                 Local::now().format("%Y-%m-%d %H:%M:%S"), 
                 start_read_time.elapsed());
        result
    } else {
        println!("âœ… ä»»åŠ¡å®Œæˆï¼Œä¸è¿”å›ç»“æœ");
        Python::with_gil(|py| Ok(py.None()))
    }
}

/// æŸ¥è¯¢å¤‡ä»½æ–‡ä»¶ä¸­çš„æŒ‡å®šåˆ—
/// 
/// å‚æ•°:
/// - backup_file: å¤‡ä»½æ–‡ä»¶è·¯å¾„
/// - column_index: è¦è¯»å–çš„å› å­åˆ—ç´¢å¼•ï¼ˆ0è¡¨ç¤ºç¬¬ä¸€åˆ—å› å­å€¼ï¼‰
/// 
/// è¿”å›:
/// åŒ…å«ä¸‰ä¸ªnumpyæ•°ç»„çš„å­—å…¸: {"date": æ—¥æœŸæ•°ç»„, "code": ä»£ç æ•°ç»„, "factor": æŒ‡å®šåˆ—çš„å› å­å€¼æ•°ç»„}
#[pyfunction]
#[pyo3(signature = (backup_file, column_index))]
pub fn query_backup_single_column(backup_file: String, column_index: usize) -> PyResult<PyObject> {
    // ä¼˜å…ˆä½¿ç”¨è¶…é«˜é€Ÿç‰ˆæœ¬
    read_backup_results_single_column_ultra_fast_v2(&backup_file, column_index)
}

/// æŸ¥è¯¢å¤‡ä»½æ–‡ä»¶ä¸­çš„æŒ‡å®šåˆ—ï¼Œæ”¯æŒè¿‡æ»¤
/// 
/// å‚æ•°:
/// - backup_file: å¤‡ä»½æ–‡ä»¶è·¯å¾„
/// - column_index: è¦è¯»å–çš„å› å­åˆ—ç´¢å¼•ï¼ˆ0è¡¨ç¤ºç¬¬ä¸€åˆ—å› å­å€¼ï¼‰
/// - dates: å¯é€‰çš„æ—¥æœŸè¿‡æ»¤åˆ—è¡¨
/// - codes: å¯é€‰çš„ä»£ç è¿‡æ»¤åˆ—è¡¨
/// 
/// è¿”å›:
/// åŒ…å«ä¸‰ä¸ªnumpyæ•°ç»„çš„å­—å…¸: {"date": æ—¥æœŸæ•°ç»„, "code": ä»£ç æ•°ç»„, "factor": æŒ‡å®šåˆ—çš„å› å­å€¼æ•°ç»„}
#[pyfunction]
#[pyo3(signature = (backup_file, column_index, dates=None, codes=None))]
pub fn query_backup_single_column_with_filter(backup_file: String, column_index: usize, dates: Option<Vec<i64>>, codes: Option<Vec<String>>) -> PyResult<PyObject> {
    // å°†Vecè½¬æ¢ä¸ºHashSetä»¥æé«˜æŸ¥æ‰¾æ€§èƒ½
    let date_filter: Option<HashSet<i64>> = dates.map(|v| v.into_iter().collect());
    let code_filter: Option<HashSet<String>> = codes.map(|v| v.into_iter().collect());
    
    read_backup_results_single_column_with_filter(&backup_file, column_index, date_filter.as_ref(), code_filter.as_ref())
}

/// æŸ¥è¯¢å¤‡ä»½æ–‡ä»¶ä¸­çš„æŒ‡å®šåˆ—èŒƒå›´ï¼Œæ”¯æŒè¿‡æ»¤
/// 
/// å‚æ•°:
/// - backup_file: å¤‡ä»½æ–‡ä»¶è·¯å¾„
/// - column_start: å¼€å§‹åˆ—ç´¢å¼•ï¼ˆåŒ…å«ï¼‰
/// - column_end: ç»“æŸåˆ—ç´¢å¼•ï¼ˆåŒ…å«ï¼‰
/// - dates: å¯é€‰çš„æ—¥æœŸè¿‡æ»¤åˆ—è¡¨
/// - codes: å¯é€‰çš„ä»£ç è¿‡æ»¤åˆ—è¡¨
/// 
/// è¿”å›:
/// åŒ…å«numpyæ•°ç»„çš„å­—å…¸: {"date": æ—¥æœŸæ•°ç»„, "code": ä»£ç æ•°ç»„, "factors": æŒ‡å®šåˆ—èŒƒå›´çš„å› å­å€¼æ•°ç»„}
#[pyfunction]
#[pyo3(signature = (backup_file, column_start, column_end, dates=None, codes=None))]
pub fn query_backup_columns_range_with_filter(backup_file: String, column_start: usize, column_end: usize, dates: Option<Vec<i64>>, codes: Option<Vec<String>>) -> PyResult<PyObject> {
    // æ£€æŸ¥å‚æ•°æœ‰æ•ˆæ€§
    if column_start > column_end {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            "column_start must be <= column_end"
        ));
    }
    
    // å°†Vecè½¬æ¢ä¸ºHashSetä»¥æé«˜æŸ¥æ‰¾æ€§èƒ½
    let date_filter: Option<HashSet<i64>> = dates.map(|v| v.into_iter().collect());
    let code_filter: Option<HashSet<String>> = codes.map(|v| v.into_iter().collect());
    
    read_backup_results_columns_range_with_filter(&backup_file, column_start, column_end, date_filter.as_ref(), code_filter.as_ref())
}

/// è¯»å–å¤‡ä»½æ–‡ä»¶ä¸­çš„æŒ‡å®šåˆ—å› å­å€¼ï¼ˆçº¯å› å­å€¼æ•°ç»„ï¼‰
/// column_index: è¦è¯»å–çš„å› å­åˆ—ç´¢å¼•ï¼ˆ0è¡¨ç¤ºç¬¬ä¸€åˆ—å› å­å€¼ï¼‰
/// è¿”å›: åªåŒ…å«å› å­å€¼çš„numpyæ•°ç»„
fn read_backup_results_factor_only(file_path: &str, column_index: usize) -> PyResult<PyObject> {
    read_backup_results_factor_only_with_filter(file_path, column_index, None, None)
}

fn read_backup_results_factor_only_with_filter(file_path: &str, column_index: usize, date_filter: Option<&HashSet<i64>>, code_filter: Option<&HashSet<String>>) -> PyResult<PyObject> {
    if !Path::new(file_path).exists() {
        return Err(PyErr::new::<pyo3::exceptions::PyFileNotFoundError, _>(
            "å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨"
        ));
    }
    
    let file = File::open(file_path)
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("æ— æ³•æ‰“å¼€å¤‡ä»½æ–‡ä»¶: {}", e)))?;
    
    let file_len = file.metadata()
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("æ— æ³•è·å–æ–‡ä»¶å…ƒæ•°æ®: {}", e)))?
        .len() as usize;
    
    if file_len < HEADER_SIZE {
        return read_legacy_backup_results_factor_only_with_filter(file_path, column_index, date_filter, code_filter);
    }
    
    // å†…å­˜æ˜ å°„
    let mmap = unsafe { 
        Mmap::map(&file)
            .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("æ— æ³•æ˜ å°„æ–‡ä»¶åˆ°å†…å­˜: {}", e)))?
    };
    let mmap = Arc::new(mmap);
    
    // è¯»å–æ–‡ä»¶å¤´
    let header = unsafe {
        &*(mmap.as_ptr() as *const FileHeader)
    };
    
    if &header.magic != b"RPBACKUP" {
        return read_legacy_backup_results_factor_only_with_filter(file_path, column_index, date_filter, code_filter);
    }
    
    let record_count = header.record_count as usize;
    if record_count == 0 {
        return Python::with_gil(|py| {
            let numpy = py.import("numpy")?;
            Ok(numpy.call_method1("array", (Vec::<f64>::new(),))?.into())
        });
    }
    
    let record_size = header.record_size as usize;
    let factor_count = header.factor_count as usize;
    
    // æ£€æŸ¥åˆ—ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
    if column_index >= factor_count {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            format!("åˆ—ç´¢å¼• {} è¶…å‡ºèŒƒå›´ï¼Œå› å­åˆ—æ•°ä¸º {}", column_index, factor_count)
        ));
    }
    
    let calculated_record_size = calculate_record_size(factor_count);
    if record_size != calculated_record_size {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
           format!("è®°å½•å¤§å°ä¸åŒ¹é…: æ–‡ä»¶å¤´æ˜¾ç¤º {}, è®¡ç®—å¾—åˆ° {}. æ–‡ä»¶å¯èƒ½æŸå.", record_size, calculated_record_size)
       ));
    }

    let expected_size = HEADER_SIZE + record_count * record_size;
    if file_len < expected_size {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            "å¤‡ä»½æ–‡ä»¶ä¼¼ä¹è¢«æˆªæ–­äº†"
        ));
    }
    
    // ä½¿ç”¨è‡ªå®šä¹‰çº¿ç¨‹æ± é¿å…èµ„æºç«äº‰å’Œæ³„æ¼
    let pool = rayon::ThreadPoolBuilder::new()
        .num_threads(std::cmp::min(rayon::current_num_threads(), 8))
        .build()
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(format!("åˆ›å»ºçº¿ç¨‹æ± å¤±è´¥: {}", e)))?;
    
    // å¹¶è¡Œè¯»å–åªè·å–å› å­å€¼
    let records_start = HEADER_SIZE;
    let factors: Vec<f64> = pool.install(|| {
        (0..record_count)
            .into_par_iter()
            .filter_map(|i| {
                let record_offset = records_start + i * record_size;
                let record_bytes = &mmap[record_offset..record_offset + record_size];
                
                match DynamicRecord::from_bytes(record_bytes, factor_count) {
                    Ok(record) => {
                        // æ£€æŸ¥æ—¥æœŸè¿‡æ»¤å™¨
                        if let Some(date_filter) = date_filter {
                            if !date_filter.contains(&record.date) {
                                return None;
                            }
                        }
                        
                        // æ£€æŸ¥ä»£ç è¿‡æ»¤å™¨
                        if let Some(code_filter) = code_filter {
                            let code_len = std::cmp::min(record.code_len as usize, 32);
                            let code = String::from_utf8_lossy(&record.code_bytes[..code_len]).to_string();
                            
                            if !code_filter.contains(&code) {
                                return None;
                            }
                        }
                        
                        // åªè¿”å›æŒ‡å®šåˆ—çš„å› å­å€¼
                        if column_index < record.factors.len() {
                            Some(record.factors[column_index])
                        } else {
                            Some(f64::NAN)
                        }
                    }
                    Err(_) => {
                        // è®°å½•æŸåï¼Œè¿”å›NaN
                        Some(f64::NAN)
                    }
                }
            })
            .collect()
    });
    
    // æ˜¾å¼é‡Šæ”¾mmap
    drop(mmap);

    // åˆ›å»ºnumpyæ•°ç»„
    Python::with_gil(|py| {
        let numpy = py.import("numpy")?;
        Ok(numpy.call_method1("array", (factors,))?.into())
    })
}

// æ”¯æŒæ—§æ ¼å¼çš„çº¯å› å­å€¼è¯»å–
fn read_legacy_backup_results_factor_only_with_filter(file_path: &str, column_index: usize, date_filter: Option<&HashSet<i64>>, code_filter: Option<&HashSet<String>>) -> PyResult<PyObject> {
    let mut file = File::open(file_path)
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("æ— æ³•æ‰“å¼€å¤‡ä»½æ–‡ä»¶: {}", e)))?;
    
    let mut buffer = Vec::new();
    file.read_to_end(&mut buffer)
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("æ— æ³•è¯»å–å¤‡ä»½æ–‡ä»¶: {}", e)))?;
    
    if buffer.is_empty() {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            "å¤‡ä»½æ–‡ä»¶ä¸ºç©º"
        ));
    }
    
    let mut all_results = Vec::new();
    let mut cursor = 0;
    
    // å°è¯•æ–°çš„æ‰¹æ¬¡æ ¼å¼ï¼ˆå¸¦å¤§å°å¤´ï¼‰
    while cursor + 8 <= buffer.len() {
        let size_bytes = &buffer[cursor..cursor + 8];
        let batch_size = u64::from_le_bytes([
            size_bytes[0], size_bytes[1], size_bytes[2], size_bytes[3],
            size_bytes[4], size_bytes[5], size_bytes[6], size_bytes[7],
        ]) as usize;
        
        cursor += 8;
        
        if cursor + batch_size > buffer.len() {
            cursor -= 8;
            break;
        }
        
        match bincode::deserialize::<Vec<TaskResult>>(&buffer[cursor..cursor + batch_size]) {
            Ok(batch) => {
                for result in batch {
                    // æ£€æŸ¥æ—¥æœŸè¿‡æ»¤å™¨
                    if let Some(date_filter) = date_filter {
                        if !date_filter.contains(&result.date) {
                            continue;
                        }
                    }
                    
                    // æ£€æŸ¥ä»£ç è¿‡æ»¤å™¨
                    if let Some(code_filter) = code_filter {
                        if !code_filter.contains(&result.code) {
                            continue;
                        }
                    }
                    
                    all_results.push(result);
                }
                cursor += batch_size;
            }
            Err(_) => {
                cursor -= 8;
                break;
            }
        }
    }
    
    // å¦‚æœå¤±è´¥ï¼Œå°è¯•åŸå§‹æ ¼å¼
    if cursor < buffer.len() {
        while cursor < buffer.len() {
            match bincode::deserialize::<Vec<TaskResult>>(&buffer[cursor..]) {
                Ok(batch) => {
                    let batch_size = bincode::serialized_size(&batch)
                        .map_err(|e| PyErr::new::<pyo3::exceptions::PyValueError, _>(format!("åºåˆ—åŒ–é”™è¯¯: {}", e)))? as usize;
                    for result in batch {
                        // æ£€æŸ¥æ—¥æœŸè¿‡æ»¤å™¨
                        if let Some(date_filter) = date_filter {
                            if !date_filter.contains(&result.date) {
                                continue;
                            }
                        }
                        
                        // æ£€æŸ¥ä»£ç è¿‡æ»¤å™¨
                        if let Some(code_filter) = code_filter {
                            if !code_filter.contains(&result.code) {
                                continue;
                            }
                        }
                        
                        all_results.push(result);
                    }
                    cursor += batch_size;
                }
                Err(_) => {
                    cursor += std::cmp::min(64, buffer.len() - cursor);
                }
            }
        }
    }
    
    if all_results.is_empty() {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            "å¤‡ä»½æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆç»“æœ"
        ));
    }
    
    // æ£€æŸ¥åˆ—ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
    if let Some(first_result) = all_results.first() {
        if column_index >= first_result.facs.len() {
            return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
                format!("åˆ—ç´¢å¼• {} è¶…å‡ºèŒƒå›´ï¼Œå› å­åˆ—æ•°ä¸º {}", column_index, first_result.facs.len())
            ));
        }
    }
    
    // åªæå–æŒ‡å®šåˆ—çš„å› å­å€¼
    let factors: Vec<f64> = all_results
        .into_iter()
        .map(|result| {
            if column_index < result.facs.len() {
                result.facs[column_index]
            } else {
                f64::NAN
            }
        })
        .collect();
    
    // åˆ›å»ºnumpyæ•°ç»„
    Python::with_gil(|py| {
        let numpy = py.import("numpy")?;
        Ok(numpy.call_method1("array", (factors,))?.into())
    })
}

/// æŸ¥è¯¢å¤‡ä»½æ–‡ä»¶ä¸­çš„æŒ‡å®šåˆ—å› å­å€¼ï¼ˆçº¯å› å­å€¼æ•°ç»„ï¼‰
/// 
/// å‚æ•°:
/// - backup_file: å¤‡ä»½æ–‡ä»¶è·¯å¾„
/// - column_index: è¦è¯»å–çš„å› å­åˆ—ç´¢å¼•ï¼ˆ0è¡¨ç¤ºç¬¬ä¸€åˆ—å› å­å€¼ï¼‰
/// 
/// è¿”å›:
/// åªåŒ…å«å› å­å€¼çš„numpyæ•°ç»„
#[pyfunction]
#[pyo3(signature = (backup_file, column_index))]
pub fn query_backup_factor_only(backup_file: String, column_index: usize) -> PyResult<PyObject> {
    read_backup_results_factor_only(&backup_file, column_index)
}

/// æŸ¥è¯¢å¤‡ä»½æ–‡ä»¶ä¸­çš„æŒ‡å®šåˆ—å› å­å€¼ï¼ˆçº¯å› å­å€¼æ•°ç»„ï¼‰ï¼Œæ”¯æŒè¿‡æ»¤
/// 
/// å‚æ•°:
/// - backup_file: å¤‡ä»½æ–‡ä»¶è·¯å¾„
/// - column_index: è¦è¯»å–çš„å› å­åˆ—ç´¢å¼•ï¼ˆ0è¡¨ç¤ºç¬¬ä¸€åˆ—å› å­å€¼ï¼‰
/// - dates: å¯é€‰çš„æ—¥æœŸè¿‡æ»¤åˆ—è¡¨
/// - codes: å¯é€‰çš„ä»£ç è¿‡æ»¤åˆ—è¡¨
/// 
/// è¿”å›:
/// åªåŒ…å«å› å­å€¼çš„numpyæ•°ç»„
#[pyfunction]
#[pyo3(signature = (backup_file, column_index, dates=None, codes=None))]
pub fn query_backup_factor_only_with_filter(backup_file: String, column_index: usize, dates: Option<Vec<i64>>, codes: Option<Vec<String>>) -> PyResult<PyObject> {
    // å°†Vecè½¬æ¢ä¸ºHashSetä»¥æé«˜æŸ¥æ‰¾æ€§èƒ½
    let date_filter: Option<HashSet<i64>> = dates.map(|v| v.into_iter().collect());
    let code_filter: Option<HashSet<String>> = codes.map(|v| v.into_iter().collect());
    
    read_backup_results_factor_only_with_filter(&backup_file, column_index, date_filter.as_ref(), code_filter.as_ref())
}

/// è¶…é«˜é€Ÿå› å­å€¼è¯»å–ï¼ˆç›´æ¥å­—èŠ‚åç§»ç‰ˆæœ¬ï¼‰
fn read_backup_results_factor_only_ultra_fast(file_path: &str, column_index: usize) -> PyResult<PyObject> {
    if !Path::new(file_path).exists() {
        return Err(PyErr::new::<pyo3::exceptions::PyFileNotFoundError, _>(
            "å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨"
        ));
    }
    
    let file = File::open(file_path)
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("æ— æ³•æ‰“å¼€å¤‡ä»½æ–‡ä»¶: {}", e)))?;
    
    let file_len = file.metadata()
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("æ— æ³•è·å–æ–‡ä»¶å…ƒæ•°æ®: {}", e)))?
        .len() as usize;
    
    if file_len < HEADER_SIZE {
        return read_backup_results_factor_only(&file_path, column_index);
    }
    
    // å†…å­˜æ˜ å°„
    let mmap = unsafe { 
        Mmap::map(&file)
            .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("æ— æ³•æ˜ å°„æ–‡ä»¶åˆ°å†…å­˜: {}", e)))?
    };
    
    // è¯»å–æ–‡ä»¶å¤´
    let header = unsafe {
        &*(mmap.as_ptr() as *const FileHeader)
    };
    
    if &header.magic != b"RPBACKUP" {
        return read_backup_results_factor_only(&file_path, column_index);
    }
    
    let record_count = header.record_count as usize;
    if record_count == 0 {
        return Python::with_gil(|py| {
            let numpy = py.import("numpy")?;
            Ok(numpy.call_method1("array", (Vec::<f64>::new(),))?.into())
        });
    }
    
    let record_size = header.record_size as usize;
    let factor_count = header.factor_count as usize;
    
    // æ£€æŸ¥åˆ—ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
    if column_index >= factor_count {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            format!("åˆ—ç´¢å¼• {} è¶…å‡ºèŒƒå›´ï¼Œå› å­åˆ—æ•°ä¸º {}", column_index, factor_count)
        ));
    }
    
    let calculated_record_size = calculate_record_size(factor_count);
    if record_size != calculated_record_size {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
           format!("è®°å½•å¤§å°ä¸åŒ¹é…: æ–‡ä»¶å¤´æ˜¾ç¤º {}, è®¡ç®—å¾—åˆ° {}. æ–‡ä»¶å¯èƒ½æŸå.", record_size, calculated_record_size)
       ));
    }

    let expected_size = HEADER_SIZE + record_count * record_size;
    if file_len < expected_size {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            "å¤‡ä»½æ–‡ä»¶ä¼¼ä¹è¢«æˆªæ–­äº†"
        ));
    }
    
    // ç›´æ¥åç§»è¯»å–å› å­å€¼
    let records_start = HEADER_SIZE;
    
    // è®¡ç®—å› å­å€¼åœ¨è®°å½•ä¸­çš„åç§»é‡
    // è®°å½•æ ¼å¼: date(8) + code_hash(8) + timestamp(8) + factor_count(4) + code_len(4) + code_bytes(32) + factors(factor_count * 8)
    let factor_base_offset = 8 + 8 + 8 + 4 + 4 + 32; // date + code_hash + timestamp + factor_count + code_len + code_bytes
    let factor_offset = factor_base_offset + column_index * 8;
    
    // ä½¿ç”¨è‡ªå®šä¹‰çº¿ç¨‹æ± é¿å…èµ„æºç«äº‰å’Œæ³„æ¼
    let pool = rayon::ThreadPoolBuilder::new()
        .num_threads(std::cmp::min(rayon::current_num_threads(), 16))
        .build()
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(format!("åˆ›å»ºçº¿ç¨‹æ± å¤±è´¥: {}", e)))?;
    
    // å¹¶è¡Œè¯»å–æ‰€æœ‰å› å­å€¼
    let factors: Vec<f64> = pool.install(|| {
        (0..record_count)
            .into_par_iter()
            .map(|i| {
                let record_offset = records_start + i * record_size;
                
                // ç›´æ¥è¯»å–å› å­å€¼ï¼Œå®Œå…¨è·³è¿‡å…¶ä»–å­—æ®µçš„è§£æ
                unsafe {
                    let factor_ptr = mmap.as_ptr().add(record_offset + factor_offset) as *const f64;
                    *factor_ptr
                }
            })
            .collect()
    });
    
    // æ˜¾å¼é‡Šæ”¾mmap
    drop(mmap);
    
    // åˆ›å»ºnumpyæ•°ç»„
    Python::with_gil(|py| {
        let numpy = py.import("numpy")?;
        Ok(numpy.call_method1("array", (factors,))?.into())
    })
}

/// è¶…é«˜é€ŸæŸ¥è¯¢å¤‡ä»½æ–‡ä»¶ä¸­çš„æŒ‡å®šåˆ—å› å­å€¼
/// 
/// å‚æ•°:
/// - backup_file: å¤‡ä»½æ–‡ä»¶è·¯å¾„
/// - column_index: è¦è¯»å–çš„å› å­åˆ—ç´¢å¼•ï¼ˆ0è¡¨ç¤ºç¬¬ä¸€åˆ—å› å­å€¼ï¼‰
/// 
/// è¿”å›:
/// åªåŒ…å«å› å­å€¼çš„numpyæ•°ç»„
#[pyfunction]
#[pyo3(signature = (backup_file, column_index))]
pub fn query_backup_factor_only_ultra_fast(backup_file: String, column_index: usize) -> PyResult<PyObject> {
    read_backup_results_factor_only_ultra_fast(&backup_file, column_index)
}

/// è¶…é«˜é€ŸæŸ¥è¯¢å¤‡ä»½æ–‡ä»¶ä¸­çš„æŒ‡å®šåˆ—ï¼ˆå®Œæ•´ç‰ˆæœ¬v2ï¼‰
/// ç›´æ¥å­—èŠ‚åç§»è¯»å–ï¼Œé¿å…å®Œæ•´è®°å½•è§£æ
fn read_backup_results_single_column_ultra_fast_v2(file_path: &str, column_index: usize) -> PyResult<PyObject> {
    if !Path::new(file_path).exists() {
        return Err(PyErr::new::<pyo3::exceptions::PyFileNotFoundError, _>(
            "å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨"
        ));
    }
    
    let file = File::open(file_path)
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("æ— æ³•æ‰“å¼€å¤‡ä»½æ–‡ä»¶: {}", e)))?;
    
    let file_len = file.metadata()
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("æ— æ³•è·å–æ–‡ä»¶å…ƒæ•°æ®: {}", e)))?
        .len() as usize;
    
    if file_len < HEADER_SIZE {
        return read_backup_results_single_column(&file_path, column_index);
    }
    
    // å†…å­˜æ˜ å°„
    let mmap = unsafe { 
        Mmap::map(&file)
            .map_err(|e| PyErr::new::<pyo3::exceptions::PyIOError, _>(format!("æ— æ³•æ˜ å°„æ–‡ä»¶åˆ°å†…å­˜: {}", e)))?
    };
    
    // è¯»å–æ–‡ä»¶å¤´
    let header = unsafe {
        &*(mmap.as_ptr() as *const FileHeader)
    };
    
    if &header.magic != b"RPBACKUP" {
        return read_backup_results_single_column(&file_path, column_index);
    }
    
    let record_count = header.record_count as usize;
    if record_count == 0 {
        return Python::with_gil(|py| {
            let numpy = py.import("numpy")?;
            let dict = pyo3::types::PyDict::new(py);
            dict.set_item("date", numpy.call_method1("array", (Vec::<i64>::new(),))?)?;
            dict.set_item("code", numpy.call_method1("array", (Vec::<String>::new(),))?)?;
            dict.set_item("factor", numpy.call_method1("array", (Vec::<f64>::new(),))?)?;
            Ok(dict.into())
        });
    }
    
    let record_size = header.record_size as usize;
    let factor_count = header.factor_count as usize;
    
    // æ£€æŸ¥åˆ—ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
    if column_index >= factor_count {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            format!("åˆ—ç´¢å¼• {} è¶…å‡ºèŒƒå›´ï¼Œå› å­åˆ—æ•°ä¸º {}", column_index, factor_count)
        ));
    }
    
    let calculated_record_size = calculate_record_size(factor_count);
    if record_size != calculated_record_size {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
           format!("è®°å½•å¤§å°ä¸åŒ¹é…: æ–‡ä»¶å¤´æ˜¾ç¤º {}, è®¡ç®—å¾—åˆ° {}. æ–‡ä»¶å¯èƒ½æŸå.", record_size, calculated_record_size)
       ));
    }

    let expected_size = HEADER_SIZE + record_count * record_size;
    if file_len < expected_size {
        return Err(PyErr::new::<pyo3::exceptions::PyValueError, _>(
            "å¤‡ä»½æ–‡ä»¶ä¼¼ä¹è¢«æˆªæ–­äº†"
        ));
    }
    
    // è®¡ç®—å„å­—æ®µåœ¨è®°å½•ä¸­çš„åç§»é‡
    // è®°å½•æ ¼å¼: date(8) + code_hash(8) + timestamp(8) + factor_count(4) + code_len(4) + code_bytes(32) + factors(factor_count * 8)
    let date_offset = 0;
    let code_len_offset = 8 + 8 + 8 + 4; // date + code_hash + timestamp + factor_count
    let code_bytes_offset = code_len_offset + 4; // + code_len
    let factor_base_offset = 8 + 8 + 8 + 4 + 4 + 32; // date + code_hash + timestamp + factor_count + code_len + code_bytes
    let factor_offset = factor_base_offset + column_index * 8;
    
    let records_start = HEADER_SIZE;
    
    // ä½¿ç”¨æ›´å¤§çš„çº¿ç¨‹æ± ä»¥æé«˜å¹¶è¡Œåº¦
    let pool = rayon::ThreadPoolBuilder::new()
        .num_threads(std::cmp::min(rayon::current_num_threads(), 16))
        .build()
        .map_err(|e| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(format!("åˆ›å»ºçº¿ç¨‹æ± å¤±è´¥: {}", e)))?;
    
    // é¢„å…ˆåˆ†é…Vecé¿å…å¤šæ¬¡é‡æ–°åˆ†é…
    let mut dates = Vec::with_capacity(record_count);
    let mut codes = Vec::with_capacity(record_count);
    let mut factors = Vec::with_capacity(record_count);
    
    // ä½¿ç”¨æ›´å¤§çš„æ‰¹æ¬¡æ¥å‡å°‘åŒæ­¥å¼€é”€
    const BATCH_SIZE: usize = 10000;
    let num_batches = (record_count + BATCH_SIZE - 1) / BATCH_SIZE;
    
    pool.install(|| {
        // å¹¶è¡Œå¤„ç†æ¯ä¸ªæ‰¹æ¬¡
        let batch_results: Vec<Vec<(i64, String, f64)>> = (0..num_batches)
            .into_par_iter()
            .map(|batch_idx| {
                let start_idx = batch_idx * BATCH_SIZE;
                let end_idx = std::cmp::min(start_idx + BATCH_SIZE, record_count);
                let mut batch_data = Vec::with_capacity(end_idx - start_idx);
                
                for i in start_idx..end_idx {
                    let record_offset = records_start + i * record_size;
                    
                    // ç›´æ¥è¯»å–æ—¥æœŸ
                    let date = unsafe {
                        let date_ptr = mmap.as_ptr().add(record_offset + date_offset) as *const i64;
                        *date_ptr
                    };
                    
                    // ç›´æ¥è¯»å–ä»£ç é•¿åº¦
                    let code_len = unsafe {
                        let code_len_ptr = mmap.as_ptr().add(record_offset + code_len_offset) as *const u32;
                        std::cmp::min(*code_len_ptr as usize, 32)
                    };
                    
                    // ç›´æ¥è¯»å–ä»£ç å­—èŠ‚
                    let code = unsafe {
                        let code_bytes_ptr = mmap.as_ptr().add(record_offset + code_bytes_offset);
                        let code_slice = std::slice::from_raw_parts(code_bytes_ptr, code_len);
                        String::from_utf8_lossy(code_slice).into_owned()
                    };
                    
                    // ç›´æ¥è¯»å–å› å­å€¼
                    let factor = unsafe {
                        let factor_ptr = mmap.as_ptr().add(record_offset + factor_offset) as *const f64;
                        *factor_ptr
                    };
                    
                    batch_data.push((date, code, factor));
                }
                
                batch_data
            })
            .collect();
        
        // åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡ç»“æœ
        for batch in batch_results {
            for (date, code, factor) in batch {
                dates.push(date);
                codes.push(code);
                factors.push(factor);
            }
        }
    });
    
    // æ˜¾å¼é‡Šæ”¾mmap
    drop(mmap);
    
    // åˆ›å»ºPythonå­—å…¸
    Python::with_gil(|py| {
        let numpy = py.import("numpy")?;
        let dict = pyo3::types::PyDict::new(py);

        dict.set_item("date", numpy.call_method1("array", (dates,))?)?;
        dict.set_item("code", numpy.call_method1("array", (codes,))?)?;
        dict.set_item("factor", numpy.call_method1("array", (factors,))?)?;

        Ok(dict.into())
    })
}