{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1d42b33e-2478-496c-844a-0828baead407",
   "metadata": {},
   "source": [
    "dataset/\n",
    "├── daisy/\n",
    "│   ├── img1.jpg\n",
    "│   ├── img2.jpg\n",
    "├── rose/\n",
    "│   ├── img3.jpg\n",
    "├── tulip/\n",
    "│   ├── img4.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e0b81d-421d-40dd-828c-9981081938d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. PyTorch Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1b94b0-2935-4e9f-9574-c90a1837c5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset_path = r\"Dataset\"\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(dataset.classes)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4cd738fb-59f3-4d8b-b026-22c06a925092",
   "metadata": {},
   "source": [
    "2. TensorFlow/Keras Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec13664-fd81-48f9-864b-3f784d52d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dataset_path = r\"Dataset\"\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(train_ds.class_names)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "641bd949-4908-4685-920d-38b505a74ad4",
   "metadata": {},
   "source": [
    "dataset/\n",
    "├── train/\n",
    "│   ├── cats/\n",
    "│   └── dogs/\n",
    "├── val/\n",
    "│   ├── cats/\n",
    "│   └── dogs/\n",
    "└── test/\n",
    "    ├── cats/\n",
    "    └── dogs/"
   ]
  },
  {
   "cell_type": "raw",
   "id": "654addfa-a0a3-412d-a9a0-7bc395e8489d",
   "metadata": {},
   "source": [
    "1. Keras: image_dataset_from_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d849171a-a9ea-4b1d-ae3b-d3114fcbd55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"dataset/train\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"dataset/val\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"dataset/test\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7462834-d3fb-4e25-8783-61fc72cb2da1",
   "metadata": {},
   "source": [
    "2. Keras: load_img() + img_to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94e104f-6a13-4d30-a342-82870afacbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import os\n",
    "\n",
    "train_dir = \"dataset/train/cats\"\n",
    "for file in os.listdir(train_dir):\n",
    "    img = load_img(os.path.join(train_dir, file), target_size=(224, 224))\n",
    "    img_array = img_to_array(img)\n",
    "    print(img_array.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "026d9a82-4182-4054-a0e2-b15de5ab2f2f",
   "metadata": {},
   "source": [
    "3. OpenCV (cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5503b804-f8f3-4cd7-a456-014be0cca786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "\n",
    "train_dir = \"dataset/train/dogs\"\n",
    "for file in os.listdir(train_dir):\n",
    "    img = cv2.imread(os.path.join(train_dir, file))\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    print(img.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef43b949-ca39-4b67-ba01-3191e683559a",
   "metadata": {},
   "source": [
    "4. PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f177c9-5f59-489b-b28d-7e8a0551c78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "val_dir = \"dataset/val/cats\"\n",
    "for file in os.listdir(val_dir):\n",
    "    img = Image.open(os.path.join(val_dir, file)).resize((224, 224))\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55011c13-c1ec-4329-8764-1ad40e3448b8",
   "metadata": {},
   "source": [
    "5. Keras ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf3afd9-7bbe-41e7-b783-5fb0117f2c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    \"dataset/train\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    \"dataset/val\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_gen = datagen.flow_from_directory(\n",
    "    \"dataset/test\",\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1e24547-5d8b-4a23-aafb-40683eea3191",
   "metadata": {},
   "source": [
    "6. PyTorch (torchvision + DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58cd557-829c-4877-a79c-b7075c69ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = datasets.ImageFolder(\"dataset/train\", transform=transform)\n",
    "val_data   = datasets.ImageFolder(\"dataset/val\", transform=transform)\n",
    "test_data  = datasets.ImageFolder(\"dataset/test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "test_loader  = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35ded701-4a97-4513-ab0a-81f3f0678de8",
   "metadata": {},
   "source": [
    "7. Custom Dataset (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0799119-49f5-408f-938f-cce0c47d6fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.files, self.labels = [], []\n",
    "        self.transform = transform\n",
    "        classes = os.listdir(root_dir)\n",
    "\n",
    "        for label, cls in enumerate(classes):\n",
    "            cls_folder = os.path.join(root_dir, cls)\n",
    "            for f in os.listdir(cls_folder):\n",
    "                self.files.append(os.path.join(cls_folder, f))\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self): return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.files[idx]).convert(\"RGB\")\n",
    "        if self.transform: img = self.transform(img)\n",
    "        return img, self.labels[idx]\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])\n",
    "\n",
    "train_set = CustomDataset(\"dataset/train\", transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75dced80-cabf-4366-afbb-01ed9a100514",
   "metadata": {},
   "source": [
    "dataset/\n",
    "├── cats/\n",
    "│   ├── cat1.jpg\n",
    "│   ├── cat2.jpg\n",
    "├── dogs/\n",
    "│   ├── dog1.jpg\n",
    "│   ├── dog2.jpg"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eab1bc9f-362d-46ca-a1fc-a7c10c397e12",
   "metadata": {},
   "source": [
    "1. Keras: image_dataset_from_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f0915b-5a20-4dcd-87f5-5292a1f58094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"dataset\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"dataset\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ba50372-bb83-4e3a-81a2-4689f93c7332",
   "metadata": {},
   "source": [
    "2. Keras: load_img() + img_to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94259a6e-4974-4fe6-bb94-d192b7f5629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import os\n",
    "\n",
    "cat_dir = \"dataset/cats\"\n",
    "for f in os.listdir(cat_dir):\n",
    "    img = load_img(os.path.join(cat_dir, f), target_size=(224,224))\n",
    "    arr = img_to_array(img)\n",
    "    print(arr.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6fe2ee61-8371-4b92-9b16-5c4bd05cd787",
   "metadata": {},
   "source": [
    "3. OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db34c646-d85b-4337-8fb7-b828d48cc36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "\n",
    "dog_dir = \"dataset/dogs\"\n",
    "for f in os.listdir(dog_dir):\n",
    "    img = cv2.imread(os.path.join(dog_dir, f))\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    print(img.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f30d625-720a-47fb-9d30-cca3db879262",
   "metadata": {},
   "source": [
    "4. PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a015757-5327-4ace-abb2-0cb42890ee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "cat_dir = \"dataset/cats\"\n",
    "for f in os.listdir(cat_dir):\n",
    "    img = Image.open(os.path.join(cat_dir, f)).resize((224,224))\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5505e51f-7d32-4050-a131-7dd3248c004c",
   "metadata": {},
   "source": [
    "5. ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2810b7f4-4602-43ed-b2ff-0af52198e24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    \"dataset\",\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    \"dataset\",\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75c3bab0-205b-46f8-a323-0547294c2945",
   "metadata": {},
   "source": [
    "6. PyTorch (ImageFolder + DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16988fd-7a73-4877-a71d-b646039d13ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])\n",
    "dataset = datasets.ImageFolder(\"dataset\", transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_data, val_data = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_data, batch_size=32, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
