{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/xp/stereo_toolbox/')\n",
    "from stereo_toolbox.datasets import *\n",
    "from stereo_toolbox.models import *\n",
    "from stereo_toolbox.evaluation import *\n",
    "from stereo_toolbox.loss_functions import *\n",
    "\n",
    "import os\n",
    "os.environ['HTTP_PROXY'] = 'http://10.13.73.98:7890'\n",
    "os.environ['HTTPS_PROXY'] = 'http://10.13.73.98:7890'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "torch.backends.cudnn.benchmark = True\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = 'cuda:0'\n",
    "model = load_checkpoint_flexible(IGEVStereo(),\n",
    "                                 '/home/xp/BaCon/checkpoint/c1_p1e1_s1e-2_ms_mo_lr2e-4/iteration_00036500.pth',\n",
    "                                 'model_student'\n",
    "                                 )\n",
    "model = nn.DataParallel(model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/home/xp/BaCon/')\n",
    "from dataloader import BaCon_Dataset\n",
    "\n",
    "dataset = BaCon_Dataset(split='split1_mini', training=True, root_dir='/data1/xp/Carla/data6/')\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "occlusion_threshold = 0.1\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for i, data in enumerate(tqdm(dataloader)):\n",
    "\n",
    "    student_flip_flag = data['student_flip_flag'].to(device)\n",
    "    \n",
    "    left = data['left_student'].to(device)\n",
    "    right = data['right_student'].to(device)\n",
    "    # gt_disp = data['gt_disp'].to(device).unsqueeze(1)\n",
    "    raw_left = data['raw_left_student'].to(device)\n",
    "    raw_right = data['raw_right_student'].to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = model(left, right)\n",
    "\n",
    "\n",
    "    # assert pred.shape == gt_disp.shape, f\"Predicted shape {pred.shape} does not match ground truth shape {gt_disp.shape}\"\n",
    "\n",
    "    raw_left_np = raw_left.squeeze().permute(1,2,0).cpu().numpy()\n",
    "    raw_right_np = raw_right.squeeze().permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    for occlusion in [True]:\n",
    "        for stationary in [False]:\n",
    "            for occlusion_threshold in [0.05, 0.1, 0.2, 0.4]:\n",
    "                occ_mask = auto_mask(raw_left, raw_right, pred, stationary=stationary, occlusion=occlusion, occlusion_threshold=occlusion_threshold, reverse=student_flip_flag)\n",
    "                occ_mask = occ_mask.squeeze().cpu().numpy()[..., np.newaxis]\n",
    "                masked_raw_left = raw_left_np * (occ_mask) + raw_left_np * (1-occ_mask) * 0.65 + (1-occ_mask) * [1.0, 1.0, 0] * 0.35\n",
    "                # 给 occ_mask 设置透明度 并叠加到 raw_left 上\n",
    "                plt.imshow(masked_raw_left, alpha=1.0)\n",
    "                plt.title(f'{occlusion_threshold}')\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "    plt.imshow(raw_left_np)\n",
    "    plt.axis('off')\n",
    "    plt.show()        \n",
    "    plt.imshow(raw_right_np)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "\n",
    "    if i > 10: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/home/xp/BaCon/')\n",
    "from dataloader import BaCon_Dataset\n",
    "\n",
    "dataset = BaCon_Dataset(split='split1_mini', training=True, root_dir='/data1/xp/Carla/data6/', crop_size=[512,960])\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "def conditional_flip_vectorized(images, flip_flag):\n",
    "    flipped_images = torch.flip(images, dims=[-1])\n",
    "    result = flip_flag * flipped_images + (1 - flip_flag) * images\n",
    "    return result\n",
    "    \n",
    "\n",
    "for i, data in enumerate(tqdm(dataloader)):\n",
    "    if i <= 300: # 77 122\n",
    "        continue\n",
    "\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406], device=device).view(1, 3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225], device=device).view(1, 3, 1, 1)\n",
    "\n",
    "    ref_s = data['raw_left_student'].to(device)\n",
    "    tgt_s = data['raw_right_student'].to(device)\n",
    "    ref_s = (ref_s - mean) / std\n",
    "    tgt_s = (tgt_s - mean) / std\n",
    "    ref_t = data['left_teacher'].to(device)\n",
    "    tgt_t = data['right_teacher'].to(device)\n",
    "\n",
    "    student_flip_flag = data['student_flip_flag'].to(device).reshape(-1, 1, 1, 1)\n",
    "    teacher_flip_flag = data['teacher_flip_flag'].to(device).reshape(-1, 1, 1, 1)\n",
    "\n",
    "    if student_flip_flag.item() == teacher_flip_flag.item():\n",
    "        continue\n",
    "\n",
    "    print('index', i)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_s = model(conditional_flip_vectorized(ref_s, student_flip_flag), conditional_flip_vectorized(tgt_s, student_flip_flag))\n",
    "        pred_t = model(conditional_flip_vectorized(ref_t, teacher_flip_flag), conditional_flip_vectorized(tgt_t, teacher_flip_flag))\n",
    "\n",
    "    pred_s = conditional_flip_vectorized(pred_s, student_flip_flag)\n",
    "    pred_t = conditional_flip_vectorized(pred_t, teacher_flip_flag)\n",
    "\n",
    "    ref_s = (ref_s * std + mean).clamp(min=0., max=1.)\n",
    "    tgt_s = (tgt_s * std + mean).clamp(min=0., max=1.)\n",
    "    ref_t = (ref_t * std + mean).clamp(min=0., max=1.)\n",
    "    tgt_t = (tgt_t * std + mean).clamp(min=0., max=1.)\n",
    "\n",
    "    mask_t = auto_mask(ref_t, tgt_t, pred_t, \n",
    "                        denorm=False, stationary=False, occlusion=True, \n",
    "                        occlusion_threshold=0.2, reverse=teacher_flip_flag)\n",
    "    \n",
    "    mask_s = auto_mask(ref_s, tgt_s, pred_s, \n",
    "                        denorm=False, stationary=False, occlusion=True, \n",
    "                        occlusion_threshold=0.2, reverse=student_flip_flag)\n",
    "    \n",
    "    ref_t = ref_t.squeeze().permute(1,2,0).cpu().numpy()\n",
    "    tgt_t = tgt_t.squeeze().permute(1,2,0).cpu().numpy()\n",
    "    tgt_s = tgt_s.squeeze().permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    mask_t = mask_t.squeeze().cpu().numpy()[..., np.newaxis]\n",
    "    mask_s = mask_s.squeeze().cpu().numpy()[..., np.newaxis]\n",
    "\n",
    "    mask_0 = 1 - mask_t\n",
    "    mask_1 = mask_t * mask_s\n",
    "    mask_2 = mask_t * (1 - mask_s)\n",
    "\n",
    "    # Generate a pseudo-color image by assigning different colors to mask_0, mask_1, and mask_2\n",
    "    pseudo_color_image = (\n",
    "        mask_0 * [1.0, 0.0, 0.0] +  # Red for mask_0\n",
    "        mask_1 * [0.0, 0.0, 0.0] +  # NULL for mask_1\n",
    "        mask_2 * [0.0, 1.0, 0.0]    # Green for mask_2\n",
    "    )\n",
    "\n",
    "    # Overlay the pseudo-color image on ref_t\n",
    "    overlay_image = ref_t * 0.75 + pseudo_color_image * 0.25\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    if teacher_flip_flag.item():\n",
    "        axes[0].imshow(tgt_t)\n",
    "        axes[0].axis('off')\n",
    "        axes[0].set_title(\"tgt teacher\")\n",
    "\n",
    "        axes[1].imshow(overlay_image)\n",
    "        axes[1].axis('off')\n",
    "        axes[1].set_title(\"ref, green a=2, red a=0, others a=1\")\n",
    "\n",
    "        axes[2].imshow(tgt_s)\n",
    "        axes[2].axis('off')\n",
    "        axes[2].set_title(\"tgt student\")\n",
    "    else:\n",
    "        axes[0].imshow(tgt_s)\n",
    "        axes[0].axis('off')\n",
    "        axes[0].set_title(\"tgt student\")\n",
    "\n",
    "        axes[1].imshow(overlay_image)\n",
    "        axes[1].axis('off')\n",
    "        axes[1].set_title(\"ref, green a=2, red a=0, others a=1\")\n",
    "\n",
    "        axes[2].imshow(tgt_t)\n",
    "        axes[2].axis('off')\n",
    "        axes[2].set_title(\"tgt teacher\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if i > 450:\n",
    "        break\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
