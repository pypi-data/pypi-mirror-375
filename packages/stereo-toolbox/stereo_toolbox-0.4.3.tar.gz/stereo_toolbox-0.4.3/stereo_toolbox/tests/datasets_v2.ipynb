{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/xp/stereo_toolbox/')\n",
    "# auto reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from stereo_toolbox.datasets_v2 import *\n",
    "from stereo_toolbox.visualization import *\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "torch.backends.cudnn.benchmark = True\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_figures(left, right, colored_disp=None, noc_mask=None, raw_left=None, raw_right=None):\n",
    "    if colored_disp is None:\n",
    "        colored_disp = np.zeros((left.shape[1], left.shape[2], 3), dtype=np.uint8)\n",
    "    if noc_mask is None:\n",
    "        noc_mask = torch.zeros((left.shape[1], left.shape[2]))\n",
    "\n",
    "    left, right = left.squeeze().cpu().numpy(), right.squeeze().cpu().numpy()\n",
    "    noc_mask = noc_mask.squeeze().cpu().numpy()\n",
    "    raw_left, raw_right = raw_left.squeeze().cpu().numpy(), raw_right.squeeze().cpu().numpy()\n",
    "\n",
    "    left = (left - left.min()) / (left.max() - left.min())\n",
    "    right = (right - right.min()) / (right.max() - right.min())\n",
    "\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.title('Left Image')\n",
    "    plt.imshow(left.transpose(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.title('Right Image')\n",
    "    plt.imshow(right.transpose(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.title('Colored Disparity')\n",
    "    plt.imshow(colored_disp)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.title('Raw Left Image')\n",
    "    plt.imshow(raw_left.transpose(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 3, 5)\n",
    "    plt.title('Raw Right Image')\n",
    "    plt.imshow(raw_right.transpose(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 3, 6)\n",
    "    plt.title('NOC Mask')\n",
    "    plt.imshow((noc_mask * 255.0).astype(np.uint8), vmin=0, vmax=255, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KITTI 2015 dataloader test\n",
    "from tqdm import tqdm\n",
    "\n",
    "splits = ['train', 'test',]\n",
    "batch_size = 1\n",
    "\n",
    "for split in splits:\n",
    "    for training in [True, False]:\n",
    "        dataset = KITTI2015_Dataset(split=split, training=training,requests=['ref','tgt','gt_disp','noc_mask','raw_ref','raw_tgt', 'ref_filename'])\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "        for i, data in tqdm(enumerate(dataloader)):\n",
    "            print('split: ', split, ' training: ', training, ' samples: ', dataset.__len__(), ' left shape: ', data['ref'].shape)\n",
    "\n",
    "            if 'gt_disp' in data:\n",
    "                colored_disp = colored_disparity_map_KITTI(data['gt_disp'][0])\n",
    "                colored_disp = cv2.cvtColor(colored_disp, cv2.COLOR_BGR2RGB)\n",
    "            else:\n",
    "                colored_disp = None\n",
    "            \n",
    "            if 'noc_mask' not in data:\n",
    "                data['noc_mask'] = [None] * batch_size\n",
    "\n",
    "            show_figures(data['ref'][0], data['tgt'][0], colored_disp, data['noc_mask'][0], data['raw_ref'][0], data['raw_tgt'][0])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KITTI 2012 dataloader test\n",
    "from tqdm import tqdm\n",
    "\n",
    "splits = ['train', 'test',]\n",
    "batch_size = 1\n",
    "\n",
    "for split in splits:\n",
    "    for training in [True, False]:\n",
    "        dataset = KITTI2012_Dataset(split=split, training=training, requests=['ref','tgt','gt_disp','noc_mask','raw_ref','raw_tgt', 'ref_filename'])\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "        for i, data in (enumerate(dataloader)):\n",
    "            print('split: ', split, ' training: ', training, ' samples: ', dataset.__len__(), ' left shape: ', data['ref'].shape)\n",
    "\n",
    "            if 'gt_disp' in data:\n",
    "                colored_disp = colored_disparity_map_KITTI(data['gt_disp'][0])\n",
    "                colored_disp = cv2.cvtColor(colored_disp, cv2.COLOR_BGR2RGB)\n",
    "            else:\n",
    "                colored_disp = None\n",
    "            \n",
    "            if 'noc_mask' not in data:\n",
    "                data['noc_mask'] = [None] * batch_size\n",
    "\n",
    "            show_figures(data['ref'][0], data['tgt'][0], colored_disp, data['noc_mask'][0], data['raw_ref'][0], data['raw_tgt'][0])\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SceneFlow dataloader test\n",
    "from tqdm import tqdm\n",
    "\n",
    "splits = ['train', 'test',]\n",
    "batch_size = 1\n",
    "\n",
    "for split in splits:\n",
    "    for training in [True, False]:\n",
    "        dataset = SceneFlow_Dataset(split=split, training=training,requests=['ref','tgt','gt_disp','noc_mask','raw_ref','raw_tgt', 'ref_filename'])\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "        for i, data in (enumerate(dataloader)):\n",
    "            print('split: ', split, ' training: ', training, ' samples: ', dataset.__len__(), ' left shape: ', data['ref'].shape, ' left filename: ', data['ref_filename'])\n",
    "\n",
    "            if 'gt_disp' in data:\n",
    "                colored_disp = colored_disparity_map_Spectral_r(data['gt_disp'][0])\n",
    "                colored_disp = cv2.cvtColor(colored_disp, cv2.COLOR_BGR2RGB)\n",
    "            else:\n",
    "                colored_disp = None\n",
    "            \n",
    "            if 'noc_mask' not in data:\n",
    "                data['noc_mask'] = [None] * batch_size\n",
    "\n",
    "            show_figures(data['ref'][0], data['tgt'][0], colored_disp, data['noc_mask'][0], data['raw_ref'][0], data['raw_tgt'][0])\n",
    "            if i > 40:\n",
    "                assert 0\n",
    "            # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
