{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Better Summaries: Building Domain-Specific Clustering\n",
        "\n",
        "> **Series Overview**: This is the second notebook in our three-part series on systematically analyzing and improving RAG systems. In the first notebook, we discovered query patterns but found limitations with generic summaries. Now we'll fix that.\n",
        "\n",
        "> **Prerequisites**: Complete \"1. Cluster Conversations\" notebook first. You'll need the same dependencies and `OPENAI_API_KEY` from the previous notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/567-labs/kura/blob/main/docs/notebooks/how-to-look-at-data/02_summaries_task.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install kura in Google Colab\n",
        "!pip install kura\n",
        "\n",
        "\n",
        "# Make sure you've setup your `OPENAI_API_KEY``\n",
        "# os.environ['OPENAI_API_KEY'] = <your api key here> \n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "\n",
        "# Create data directory and download dataset\n",
        "DATA_DIRECTORY = './data'\n",
        "CHECKPOINT_DIRECTORY = './checkpoints_2'\n",
        "\n",
        "!mkdir -p {DATA_DIRECTORY}\n",
        "!curl -o {DATA_DIRECTORY}/conversations.json https://usekura.xyz/assets/conversations.json\n",
        "\n",
        "# Curl the Checkpoints\n",
        "CHECKPOINT_DIRECTORY = './checkpoints_2'\n",
        "os.makedirs(CHECKPOINT_DIRECTORY, exist_ok=True)\n",
        "\n",
        "!curl -o {CHECKPOINT_DIRECTORY}/clusters.jsonl https://usekura.xyz/assets/notebooks/checkpoints_2/clusters.jsonl\n",
        "!curl -o {CHECKPOINT_DIRECTORY}/conversations.jsonl https://usekura.xyz/assets/notebooks/checkpoints_2/conversations.jsonl  \n",
        "!curl -o {CHECKPOINT_DIRECTORY}/dimensionality.jsonl https://usekura.xyz/assets/notebooks/checkpoints_2/dimensionality.jsonl\n",
        "!curl -o {CHECKPOINT_DIRECTORY}/meta_clusters.jsonl https://usekura.xyz/assets/notebooks/checkpoints_2/meta_clusters.jsonl\n",
        "!curl -o {CHECKPOINT_DIRECTORY}/summaries.jsonl https://usekura.xyz/assets/notebooks/checkpoints_2/summaries.jsonl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Reproducing Results**: To reproduce the exact results from this notebook, the first cell downloads pre-computed checkpoints from our server. These checkpoints contain the intermediate results from each step of the clustering pipeline, allowing you to follow along without waiting for the computationally expensive embedding and clustering operations to complete.\n",
        "> \n",
        "> To download our precomputed checkpoints, make sure that you curl the `checkpoints_2` directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why This Matters\n",
        "\n",
        "**The generic summaries from our initial clustering missed crucial details that would enable effective query understanding.** When working with specialized domains like machine learning experiment tracking, generic descriptions like \"user seeks information about tracking\" fail to capture the specific W&B features, user goals, and pain points that matter for system improvement.\n",
        "\n",
        "**Custom summarization transforms vague descriptions into precise, actionable insights.** Instead of \"user requests assistance with tool integration,\" we can generate \"user is configuring W&B Artifacts for model versioning in PyTorch workflows.\" This precision is critical for building clusters that truly reflect how users interact with your platform.\n",
        "\n",
        "Domain-specific summaries enable us to:\n",
        "\n",
        "1. **Capture exact features** users are working with (Artifacts, Configs, Reports)\n",
        "2. **Identify specific goals** and pain points rather than generic categories  \n",
        "3. **Reveal usage patterns** that generic summaries obscure\n",
        "4. **Create foundations** for more targeted system improvements\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "In this notebook, you'll discover how to:\n",
        "\n",
        "1. **Extend Kura's summary functionality**\n",
        "   - Design specialized prompts that extract domain-specific information\n",
        "   - Evaluate new domain focused approaches vs generic ones\n",
        "   - Replace Kura's default summarization with your custom approach\n",
        "\n",
        "2. **Compare Summarization Approaches**\n",
        "   - Analyze the limitations of generic vs. domain-specific summaries\n",
        "   - See how improved summaries change clustering outcomes\n",
        "   - Understand the impact of summary quality on cluster interpretability\n",
        "\n",
        "3. **Generate Enhanced Clusters**\n",
        "   - Apply custom summaries to create more representative topic groups\n",
        "   - Configure clustering parameters for optimal domain-specific results\n",
        "   - Extract actionable insights about user behavior patterns\n",
        "\n",
        "## What You'll Discover\n",
        "\n",
        "**By the end of this notebook, you'll transform your seven generic clusters into three highly actionable categories**: Artifacts, Visualisations, and Integrations. This dramatic improvement in cluster quality—from vague topics to specific, actionable user needs—will provide the foundation for building production classifiers in the next notebook.\n",
        "\n",
        "## The Power of Domain-Specific Clustering\n",
        "\n",
        "**While generic clustering tells you \"what\" users are asking about, domain-specific clustering reveals \"why\" and \"how\" they're struggling.** This shift from surface-level topics to deep user intent understanding is what enables you to build targeted solutions rather than generic improvements.\n",
        "\n",
        "By the end of this series, you'll have a complete framework for turning raw user queries into systematic, data-driven RAG improvements that address real user needs rather than perceived ones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating Domain Specific Summaries\n",
        "\n",
        "To address the limitations that we identified in our default summaries, we'll now see how it easy it is to replace our generic summarisation approach with a domain-specific prompt which will allow us to generate summaries that allow us to precisely capture the tools, features and goals relevant to W&B users.\n",
        "\n",
        "With this new prompt, our goal is to\n",
        "\n",
        "1. Identify specific W&B features mentioned in the query (e.g., Artifacts, Configs, Reports)\n",
        "2. Clearly state the problem the user is trying to solve\n",
        "3. Format responses concisely (25 words or less) to ensure summaries remain focused\n",
        "\n",
        "This approach generates summaries that are not only more informative but also more consistent, making them ideal building blocks for meaningful clustering. Let's implement our custom model and see how it transforms our understanding of user query patterns.\n",
        "\n",
        "### Loading in Conversation\n",
        "\n",
        "Let's first start by loading in our conversations and parsing it into a list of `Conversation` objects that `Kura` can work with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from kura.types import Message, Conversation\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def process_query_obj(obj: dict):\n",
        "    return Conversation(\n",
        "        chat_id=obj[\"query_id\"],\n",
        "        created_at=datetime.now(),\n",
        "        messages=[\n",
        "            Message(\n",
        "                created_at=datetime.now(),\n",
        "                role=\"user\",\n",
        "                content=f\"\"\"\n",
        "User Query: {obj[\"query\"]}\n",
        "Retrieved Information : {obj[\"matching_document\"]}\n",
        "\"\"\",\n",
        "            )\n",
        "        ],\n",
        "        metadata={\"query_id\": obj[\"query_id\"]},\n",
        "    )\n",
        "\n",
        "\n",
        "with open(f\"{DATA_DIRECTORY}/conversations.json\") as f:\n",
        "    conversations_raw = json.load(f)\n",
        "\n",
        "conversations = [process_query_obj(obj) for obj in conversations_raw]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll then use the `JSONL` checkpoint manager to help store our conversations to our checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from kura.checkpoints import JSONLCheckpointManager\n",
        "\n",
        "\n",
        "checkpoint_manager = JSONLCheckpointManager(CHECKPOINT_DIRECTORY, enabled=True)\n",
        "checkpoint_manager.save_checkpoint(\"conversations\",conversations)\n",
        "conversations = checkpoint_manager.load_checkpoint(\"conversations\", Conversation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's now try to see how our default summaries look like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Summarising 2 conversations: 100%|██████████| 2/2 [00:02<00:00,  1.03s/it]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConversationSummary</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The user is seeking information on how to track machine learning experiments using a specific tool, </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">including code examples and steps involved.'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"The user's overall request for the assistant is to provide guidance on experiment tracking in machine </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">learning.\"</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">topic</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">languages</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'english'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'python'</span><span style=\"font-weight: bold\">]</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">task</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The task is to explain how to track machine learning experiments with code examples.'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">concerning_score</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">user_frustration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">assistant_errors</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">chat_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'5e878c76-25c1-4bad-8cae-6a40ca4c8138'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'conversation_turns'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'query_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'5e878c76-25c1-4bad-8cae-6a40ca4c8138'</span><span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">embedding</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mConversationSummary\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[33msummary\u001b[0m=\u001b[32m'The user is seeking information on how to track machine learning experiments using a specific tool, \u001b[0m\n",
              "\u001b[32mincluding code examples and steps involved.'\u001b[0m,\n",
              "    \u001b[33mrequest\u001b[0m=\u001b[32m\"The\u001b[0m\u001b[32m user's overall request for the assistant is to provide guidance on experiment tracking in machine \u001b[0m\n",
              "\u001b[32mlearning.\"\u001b[0m,\n",
              "    \u001b[33mtopic\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "    \u001b[33mlanguages\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'english'\u001b[0m, \u001b[32m'python'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "    \u001b[33mtask\u001b[0m=\u001b[32m'The task is to explain how to track machine learning experiments with code examples.'\u001b[0m,\n",
              "    \u001b[33mconcerning_score\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
              "    \u001b[33muser_frustration\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
              "    \u001b[33massistant_errors\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "    \u001b[33mchat_id\u001b[0m=\u001b[32m'5e878c76-25c1-4bad-8cae-6a40ca4c8138'\u001b[0m,\n",
              "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'conversation_turns'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'query_id'\u001b[0m: \u001b[32m'5e878c76-25c1-4bad-8cae-6a40ca4c8138'\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[33membedding\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConversationSummary</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Bayesian optimization is a hyperparameter tuning technique that uses a surrogate function for informed</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">search, contrasting with grid and random search methods.'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"The user's overall request for the assistant is to explain Bayesian optimization and its </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">implementation for hyperparameter tuning.\"</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">topic</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">languages</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'english'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'python'</span><span style=\"font-weight: bold\">]</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">task</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'The task is to provide information on Bayesian optimization and its application in hyperparameter </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">tuning.'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">concerning_score</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">user_frustration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">assistant_errors</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">chat_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'d7b77e8a-e86c-4953-bc9f-672618cdb751'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'conversation_turns'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'query_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'d7b77e8a-e86c-4953-bc9f-672618cdb751'</span><span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">embedding</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mConversationSummary\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[33msummary\u001b[0m=\u001b[32m'Bayesian optimization is a hyperparameter tuning technique that uses a surrogate function for informed\u001b[0m\n",
              "\u001b[32msearch, contrasting with grid and random search methods.'\u001b[0m,\n",
              "    \u001b[33mrequest\u001b[0m=\u001b[32m\"The\u001b[0m\u001b[32m user's overall request for the assistant is to explain Bayesian optimization and its \u001b[0m\n",
              "\u001b[32mimplementation for hyperparameter tuning.\"\u001b[0m,\n",
              "    \u001b[33mtopic\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "    \u001b[33mlanguages\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'english'\u001b[0m, \u001b[32m'python'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "    \u001b[33mtask\u001b[0m=\u001b[32m'The task is to provide information on Bayesian optimization and its application in hyperparameter \u001b[0m\n",
              "\u001b[32mtuning.'\u001b[0m,\n",
              "    \u001b[33mconcerning_score\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
              "    \u001b[33muser_frustration\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
              "    \u001b[33massistant_errors\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "    \u001b[33mchat_id\u001b[0m=\u001b[32m'd7b77e8a-e86c-4953-bc9f-672618cdb751'\u001b[0m,\n",
              "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'conversation_turns'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'query_id'\u001b[0m: \u001b[32m'd7b77e8a-e86c-4953-bc9f-672618cdb751'\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[33membedding\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from kura.summarisation import SummaryModel\n",
        "from rich import print as rprint\n",
        "\n",
        "summaries = await SummaryModel().summarise(conversations[:2])\n",
        "for summary in summaries:\n",
        "    rprint(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looking at these default summaries, we can identify several key limitations that prevent them from being truly useful for clustering W&B-specific queries:\n",
        "\n",
        "**Problems with Default Summaries**\n",
        "\n",
        "1. Lack of Specificity: The first summary refers to \"a specific tool\" rather than explicitly naming Weights & Biases, missing the opportunity to highlight the domain context.\n",
        "\n",
        "2. Missing Feature Details: Neither summary identifies which specific W&B features the users are interested in (experiment tracking, Bayesian optimization for hyperparameter tuning), which would be crucial for meaningful clustering.\n",
        "\n",
        "These generic summaries would lead to clusters based primarily on query structure (\"users asking for information\") rather than meaningful W&B feature categories or user goals. \n",
        "\n",
        "By defining our own summarisation model, we can address these limitations and cluster our user queries based off the specific problems and features they are trying to use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining Our New Summary Model\n",
        "\n",
        "**Notice how simple this is**: We just need to modify the prompt and pass it to Kura's existing `summarise_conversations` function. This approach makes the code easier to work with since we can configure the behavior through parameters rather than creating complex class hierarchies\n",
        "\n",
        "By customizing the prompt in the `summarise_conversations` function, our summaries become more precise and feature-focused. This allows us to better reflect how users interact with Weights and Biases and in turn translate to more representative clusters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from kura.summarisation import summarise_conversations\n",
        "\n",
        "WNB_SUMMARY_PROMPT = \"\"\"\n",
        "Analyze the user's query and the retrieved Weights and Biases documentation to provide a focused summary.\n",
        "\n",
        "In your response:\n",
        "\n",
        "1. Identify the specific W&B features being used, such as:\n",
        "   - Experiment tracking and logging\n",
        "   - Hyperparameter optimization\n",
        "   - Model registry and versioning\n",
        "   - Artifact management\n",
        "   - Reports and visualization\n",
        "   - Multi-GPU/distributed training\n",
        "\n",
        "2. Describe their concrete technical goal (e.g., \"setting up experiment tracking across multiple GPUs\" rather than just \"using experiment tracking\")\n",
        "\n",
        "Format your response in 20-25 words following:\n",
        "\n",
        "For clear technical goals:\n",
        "\"User needs help with [specific W&B feature] to [concrete technical goal], specifically [implementation detail/blocker].\"\n",
        "\n",
        "For general queries:\n",
        "\"User is asking about [W&B concept/feature] in the context of [relevant ML workflow/task].\"\n",
        "\n",
        "Reference the context below to identify the exact W&B functionality and technical requirements:\n",
        "<messages>\n",
        "{% for message in conversation.messages %}\n",
        "<message>{{message.role}}: {{message.content}}</message>\n",
        "{% endfor %}\n",
        "</messages>\n",
        "\n",
        "Focus on technical specifics rather than general descriptions.\n",
        "\n",
        "Also make sure to extract\n",
        "\n",
        "- **Languages**: What are the main languages of the conversation? Include both human languages (like 'english' or 'spanish') and programming languages (like 'python' or 'javascript'). Use lowercase full names.\n",
        "- **Concerning Score**: On a scale of 1 to 5, how concerning or potentially harmful is this conversation from a safety perspective?\n",
        "   - 1: Not concerning at all. Completely benign conversation.\n",
        "   - 2: Slightly concerning, but likely harmless.\n",
        "   - 3: Moderately concerning. May warrant a closer look.\n",
        "   - 4: Very concerning. Likely needs review.\n",
        "   - 5: Extremely concerning. Immediate review needed.\n",
        "\n",
        "- **User Frustration**: On a scale of 1 to 5, how frustrated is the user with the assistant?\n",
        "   - 1: Not frustrated at all. The user is happy with the assistant.\n",
        "   - 2: Slightly frustrated. The user is slightly annoyed with the assistant.\n",
        "   - 3: Moderately frustrated. The user is moderately annoyed with the assistant.\n",
        "   - 4: Very frustrated. The user is very annoyed with the assistant.\n",
        "   - 5: Extremely frustrated. The user is extremely annoyed with the assistant.\n",
        "\n",
        "- **Assistant Errors**: What errors did the assistant make?\n",
        "   Example:\n",
        "    - \"Responses were too long and verbose\"\n",
        "    - \"Misunderstood the user's intent or request\"\n",
        "    - \"Used wrong tool for the task\"\n",
        "    - \"Ignored user's stated preferences or constraints\"\n",
        "    - \"Provided outdated or incorrect information\"\n",
        "    - \"Failed to maintain conversation context\"\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now see the generated summaries below by passing in our new prompt into the summarise_conversations function. We'll be using the same conversations above which we generated summaries for."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Summarising 2 conversations: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConversationSummary</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"User needs help with experiment tracking to set up logging of hyperparameters and metrics during model</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">training, specifically using W&amp;B's logging functions.\"</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Analyze the user's query and the retrieved Weights and Biases documentation to provide a focused </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">summary.\"</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">topic</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'machine learning'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">languages</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'english'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'python'</span><span style=\"font-weight: bold\">]</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">task</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'summarize user query and documentation'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">concerning_score</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">user_frustration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">assistant_errors</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">chat_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'5e878c76-25c1-4bad-8cae-6a40ca4c8138'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'conversation_turns'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'query_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'5e878c76-25c1-4bad-8cae-6a40ca4c8138'</span><span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">embedding</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mConversationSummary\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[33msummary\u001b[0m=\u001b[32m\"User\u001b[0m\u001b[32m needs help with experiment tracking to set up logging of hyperparameters and metrics during model\u001b[0m\n",
              "\u001b[32mtraining, specifically using W&B's logging functions.\"\u001b[0m,\n",
              "    \u001b[33mrequest\u001b[0m=\u001b[32m\"Analyze\u001b[0m\u001b[32m the user's query and the retrieved Weights and Biases documentation to provide a focused \u001b[0m\n",
              "\u001b[32msummary.\"\u001b[0m,\n",
              "    \u001b[33mtopic\u001b[0m=\u001b[32m'machine learning'\u001b[0m,\n",
              "    \u001b[33mlanguages\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'english'\u001b[0m, \u001b[32m'python'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "    \u001b[33mtask\u001b[0m=\u001b[32m'summarize user query and documentation'\u001b[0m,\n",
              "    \u001b[33mconcerning_score\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
              "    \u001b[33muser_frustration\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
              "    \u001b[33massistant_errors\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "    \u001b[33mchat_id\u001b[0m=\u001b[32m'5e878c76-25c1-4bad-8cae-6a40ca4c8138'\u001b[0m,\n",
              "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'conversation_turns'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'query_id'\u001b[0m: \u001b[32m'5e878c76-25c1-4bad-8cae-6a40ca4c8138'\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[33membedding\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ConversationSummary</span><span style=\"font-weight: bold\">(</span>\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">summary</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'User needs help with hyperparameter optimization to implement Bayesian optimization using Weights and </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">Biases, specifically regarding the setup process and input requirements.'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">request</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Analyze the user's query and the retrieved Weights and Biases documentation to provide a focused </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">summary.\"</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">topic</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'machine learning'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">languages</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'english'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'python'</span><span style=\"font-weight: bold\">]</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">task</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'summarize user query and documentation'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">concerning_score</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">user_frustration</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">assistant_errors</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">chat_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'d7b77e8a-e86c-4953-bc9f-672618cdb751'</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'conversation_turns'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'query_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'d7b77e8a-e86c-4953-bc9f-672618cdb751'</span><span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"color: #808000; text-decoration-color: #808000\">embedding</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mConversationSummary\u001b[0m\u001b[1m(\u001b[0m\n",
              "    \u001b[33msummary\u001b[0m=\u001b[32m'User needs help with hyperparameter optimization to implement Bayesian optimization using Weights and \u001b[0m\n",
              "\u001b[32mBiases, specifically regarding the setup process and input requirements.'\u001b[0m,\n",
              "    \u001b[33mrequest\u001b[0m=\u001b[32m\"Analyze\u001b[0m\u001b[32m the user's query and the retrieved Weights and Biases documentation to provide a focused \u001b[0m\n",
              "\u001b[32msummary.\"\u001b[0m,\n",
              "    \u001b[33mtopic\u001b[0m=\u001b[32m'machine learning'\u001b[0m,\n",
              "    \u001b[33mlanguages\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'english'\u001b[0m, \u001b[32m'python'\u001b[0m\u001b[1m]\u001b[0m,\n",
              "    \u001b[33mtask\u001b[0m=\u001b[32m'summarize user query and documentation'\u001b[0m,\n",
              "    \u001b[33mconcerning_score\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
              "    \u001b[33muser_frustration\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
              "    \u001b[33massistant_errors\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "    \u001b[33mchat_id\u001b[0m=\u001b[32m'd7b77e8a-e86c-4953-bc9f-672618cdb751'\u001b[0m,\n",
              "    \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'conversation_turns'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'query_id'\u001b[0m: \u001b[32m'd7b77e8a-e86c-4953-bc9f-672618cdb751'\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[33membedding\u001b[0m=\u001b[3;35mNone\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from kura.summarisation import SummaryModel\n",
        "from rich import print as rprint\n",
        "\n",
        "summaries = await summarise_conversations(\n",
        "   conversations=conversations[:2],\n",
        "   prompt=WNB_SUMMARY_PROMPT,\n",
        "   model=SummaryModel()\n",
        ")\n",
        "\n",
        "for summary in summaries:\n",
        "    rprint(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "from kura import (\n",
        "    generate_base_clusters_from_conversation_summaries,\n",
        "    reduce_clusters_from_base_clusters,\n",
        "    reduce_dimensionality_from_clusters,\n",
        ")\n",
        "from kura.checkpoints import JSONLCheckpointManager\n",
        "from kura.cluster import ClusterDescriptionModel\n",
        "from kura.meta_cluster import MetaClusterModel\n",
        "from kura.dimensionality import HDBUMAP\n",
        "\n",
        "\n",
        "async def analyze_conversations(conversations, checkpoint_manager):\n",
        "    # Set up models\n",
        "    summary_model = SummaryModel()\n",
        "    cluster_model = ClusterDescriptionModel()\n",
        "    meta_cluster_model = MetaClusterModel(max_clusters=4)\n",
        "    dimensionality_model = HDBUMAP()\n",
        "\n",
        "    # Run pipeline steps\n",
        "    summaries = await summarise_conversations(\n",
        "        conversations, model=summary_model, checkpoint_manager=checkpoint_manager, prompt=WNB_SUMMARY_PROMPT\n",
        "    )\n",
        "\n",
        "    clusters = await generate_base_clusters_from_conversation_summaries(\n",
        "        summaries, model=cluster_model, checkpoint_manager=checkpoint_manager\n",
        "    )\n",
        "\n",
        "    reduced_clusters = await reduce_clusters_from_base_clusters(\n",
        "        clusters, model=meta_cluster_model, checkpoint_manager=checkpoint_manager\n",
        "    )\n",
        "\n",
        "    projected = await reduce_dimensionality_from_clusters(\n",
        "        reduced_clusters,\n",
        "        model=dimensionality_model,\n",
        "        checkpoint_manager=checkpoint_manager,\n",
        "    )\n",
        "\n",
        "    return projected\n",
        "\n",
        "\n",
        "checkpoint_manager = JSONLCheckpointManager(CHECKPOINT_DIRECTORY, enabled=True)\n",
        "checkpoint_manager.save_checkpoint(\"conversations\", conversations)\n",
        "clusters = await analyze_conversations(\n",
        "    conversations, checkpoint_manager=checkpoint_manager\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "from kura import (\n",
        "    generate_base_clusters_from_conversation_summaries,\n",
        "    reduce_clusters_from_base_clusters,\n",
        "    reduce_dimensionality_from_clusters,\n",
        "    CheckpointManager,\n",
        ")\n",
        "from kura.cluster import ClusterDescriptionModel\n",
        "from kura.meta_cluster import MetaClusterModel\n",
        "from kura.dimensionality import HDBUMAP\n",
        "\n",
        "\n",
        "async def analyze_conversations(conversations, checkpoint_manager):\n",
        "    # Set up models\n",
        "    summary_model = SummaryModel()\n",
        "    cluster_model = ClusterDescriptionModel()\n",
        "    meta_cluster_model = MetaClusterModel(max_clusters=4)\n",
        "    dimensionality_model = HDBUMAP()\n",
        "\n",
        "    # Run pipeline steps\n",
        "    summaries = await summarise_conversations(\n",
        "        conversations, model=summary_model, checkpoint_manager=checkpoint_manager, prompt=WNB_SUMMARY_PROMPT\n",
        "    )\n",
        "\n",
        "    clusters = await generate_base_clusters_from_conversation_summaries(\n",
        "        summaries, model=cluster_model, checkpoint_manager=checkpoint_manager\n",
        "    )\n",
        "\n",
        "    reduced_clusters = await reduce_clusters_from_base_clusters(\n",
        "        clusters, model=meta_cluster_model, checkpoint_manager=checkpoint_manager\n",
        "    )\n",
        "\n",
        "    projected = await reduce_dimensionality_from_clusters(\n",
        "        reduced_clusters,\n",
        "        model=dimensionality_model,\n",
        "        checkpoint_manager=checkpoint_manager,\n",
        "    )\n",
        "\n",
        "    return projected\n",
        "\n",
        "\n",
        "checkpoint_manager = CheckpointManager(f\"{CHECKPOINT_DIRECTORY}\", enabled=True)\n",
        "checkpoint_manager.save_checkpoint(\"conversations.jsonl\", conversations)\n",
        "clusters = await analyze_conversations(\n",
        "    conversations, checkpoint_manager=checkpoint_manager\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(3943254bfb5a471385aeadcc745e478b) Manage audio files and dataset versioning</span> : Users organized audio files for \n",
              "classification analysis and managed dataset versioning in W&amp;B. They focused on tasks such as loading metadata and \n",
              "updating datasets for effective machine learning workflows. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span>\n",
              "\n",
              "  • <span style=\"font-weight: bold\">Organize audio files for classification analysis</span> : The user prepared and structured audio data for \n",
              "classification tasks. This included tasks like loading, merging, and synchronizing metadata for effective analysis.\n",
              ": <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
              "    + <span style=\"font-weight: bold\">Prepare audio data for classification analysis</span> : The user processed and organized audio files for effective \n",
              "classification. This involved loading, merging DataFrames, and synchronizing metadata for analysis. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
              "\n",
              "\n",
              "  • <span style=\"font-weight: bold\">Assist with dataset versioning in W&amp;B</span> : Users sought help with managing dataset versioning and artifacts in \n",
              "W&amp;B. They focused on logging, tracking, and updating datasets for improved reproducibility in machine learning \n",
              "workflows. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span>\n",
              "    + <span style=\"font-weight: bold\">Help me manage dataset versioning in W&amp;B</span> : Users sought assistance with handling dataset versioning and \n",
              "artifacts in W&amp;B. They specifically focused on logging, tracking, and updating datasets for better reproducibility \n",
              "in their machine learning workflows. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span>\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "====\n",
              "\n",
              "\n",
              "<span style=\"font-weight: bold\">(92d75e32975c4651a2ab46ccb8a83fd9) Optimize machine learning experiments and resources</span> : Users explored methods to \n",
              "optimize and visualize machine learning experiments through Weights &amp; Biases. They focused on hyperparameter \n",
              "tuning, multi-GPU training, and maximizing the tool's utilization for improved performance and efficiency. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">449</span>\n",
              "\n",
              "  • <span style=\"font-weight: bold\">Optimize and visualize machine learning experiments with W&amp;B</span> : Users explored methods to log and visualize \n",
              "machine learning experiments using Weights &amp; Biases. They focused on customizing visualizations, handling data \n",
              "formats, and enhancing tracking for better analysis. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">195</span>\n",
              "    + <span style=\"font-weight: bold\">Explore data visualization with W&amp;B Tables</span> : Users investigated how to visualize diverse media types using \n",
              "wandb.Table. They aimed to manage and analyze different data formats effectively within the W&amp;B Tables interface. :\n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>\n",
              "    + <span style=\"font-weight: bold\">Help me log and visualize experiments in W&amp;B</span> : Users requested guidance on visualizing and logging various \n",
              "aspects of machine learning experiments using Weights &amp; Biases <span style=\"font-weight: bold\">(</span>W&amp;B<span style=\"font-weight: bold\">)</span>. They focused on customizing visualizations, \n",
              "tracking metrics, managing prompt configurations, and handling multi-class confusion matrices. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">71</span>\n",
              "    + <span style=\"font-weight: bold\">Enhance machine learning experiment tracking with W&amp;B</span> : Users optimized and troubleshot experiment tracking \n",
              "with Weights &amp; Biases, focusing on installation, configuration, and logging. They explored core features to improve\n",
              "ML workflows, ensuring better collaboration and data analysis. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">120</span>\n",
              "\n",
              "\n",
              "  • <span style=\"font-weight: bold\">Assist with hyperparameter optimization using Weights &amp; Biases</span> : Users requested help with optimizing \n",
              "hyperparameters through Weights &amp; Biases. They sought guidance on configuring sweeps, automating processes, and \n",
              "analyzing results for better performance. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span>\n",
              "    + <span style=\"font-weight: bold\">Help optimize hyperparameter sweeps using W&amp;B</span> : Users requested assistance in programmatically accessing and \n",
              "analyzing hyperparameter optimization results from W&amp;B sweeps. They sought guidance on optimizing configurations \n",
              "for efficient parallel training across multiple GPUs and CPUs. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>\n",
              "    + <span style=\"font-weight: bold\">Guide hyperparameter optimization using Weights &amp; Biases</span> : Users sought assistance with hyperparameter tuning\n",
              "using Weights &amp; Biases and related tools. They requested support for configuring sweeps, automating processes, and \n",
              "troubleshooting to enhance performance. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span>\n",
              "\n",
              "\n",
              "  • <span style=\"font-weight: bold\">Assist with multi-GPU training and optimization</span> : Users explored methods for effective multi-GPU distributed \n",
              "training using HuggingFace while seeking optimization of GPU resources during model training. They focused on job \n",
              "management, script arguments, and resource monitoring to enhance training efficiency. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>\n",
              "    + <span style=\"font-weight: bold\">Guide multi-GPU distributed training with HuggingFace</span> : Users requested help on setting up multi-GPU \n",
              "distributed training using HuggingFace Accelerate. They focused on launching jobs and managing script arguments \n",
              "across various hardware configurations. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
              "    + <span style=\"font-weight: bold\">Optimize GPU resources for model training</span> : Users sought assistance in optimizing GPU usage and memory during\n",
              "machine learning training. They emphasized the integration of W&amp;B for monitoring and enhancing the efficiency of \n",
              "training processes. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>\n",
              "\n",
              "\n",
              "  • <span style=\"font-weight: bold\">Assist in maximizing Weights &amp; Biases utilization</span> : Users sought guidance on using Weights &amp; Biases to manage \n",
              "experiments and data effectively. They aimed to optimize their machine learning workflows through understanding its\n",
              "features, configurations, and best practices. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">185</span>\n",
              "    + <span style=\"font-weight: bold\">Guide effective use of Weights &amp; Biases</span> : Users sought assistance in leveraging Weights &amp; Biases for managing\n",
              "experiments and data effectively. They aimed to enhance their machine learning workflows by understanding features,\n",
              "configurations, and best practices related to experiment tracking, data manipulation, and artifact management. : \n",
              "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">185</span>\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "====\n",
              "\n",
              "\n",
              "<span style=\"font-weight: bold\">(126ad2b1c8054e7b93d0dc652841623c) Enhance machine learning project collaboration with W&amp;B</span> : Users integrated \n",
              "Weights &amp; Biases into machine learning workflows while enhancing team collaboration features. They focused on \n",
              "optimizing tracking, management settings, and collaborative capabilities for effective project execution. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">74</span>\n",
              "\n",
              "  • <span style=\"font-weight: bold\">Integrate W&amp;B with machine learning frameworks</span> : Users received help integrating W&amp;B tracking into their \n",
              "machine learning workflows, specifically with PyTorch and TensorFlow. They also learned to manage W&amp;B settings and \n",
              "SageMaker configurations for secure deployments and effective tracking. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span>\n",
              "    + <span style=\"font-weight: bold\">Integrate W&amp;B tracking into ML workflows</span> : Users received assistance in integrating W&amp;B experiment tracking \n",
              "into their machine learning workflows using both PyTorch and TensorFlow. They learned to log metrics, \n",
              "hyperparameters, and artifacts effectively throughout the model training process. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19</span>\n",
              "    + <span style=\"font-weight: bold\">Assist with W&amp;B and SageMaker setup tasks</span> : Users needed help configuring sharing settings for W&amp;B reports \n",
              "and managing API keys. They also sought assistance in setting up secure IAM roles for SageMaker to ensure safe \n",
              "deployment and access management. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span>\n",
              "\n",
              "\n",
              "  • <span style=\"font-weight: bold\">Optimize team collaboration and management in W&amp;B</span> : Users explored ways to enhance collaboration and management\n",
              "features in Weights &amp; Biases. They focused on configuring roles, permissions, and various enterprise capabilities \n",
              "for improved project outcomes. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>\n",
              "    + <span style=\"font-weight: bold\">Enhance team collaboration in Weights &amp; Biases</span> : Users sought to optimize collaborative features in Weights &amp;\n",
              "Biases for better project management. They focused on configuring roles, permissions, and team settings to improve \n",
              "collaboration outcomes. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
              "    + <span style=\"font-weight: bold\">Help with team management and enterprise features</span> : Users sought assistance in managing team roles and \n",
              "permissions within W&amp;B, including inquiries about enterprise features specific to W&amp;B Server. They explored topics \n",
              "such as access control, secure storage, and distinctions in user management across membership tiers. : <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "====\n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m(\u001b[0m\u001b[1m3943254bfb5a471385aeadcc745e478b\u001b[0m\u001b[1m)\u001b[0m\u001b[1m Manage audio files and dataset versioning\u001b[0m : Users organized audio files for \n",
              "classification analysis and managed dataset versioning in W&B. They focused on tasks such as loading metadata and \n",
              "updating datasets for effective machine learning workflows. : \u001b[1;36m37\u001b[0m\n",
              "\n",
              "  • \u001b[1mOrganize audio files for classification analysis\u001b[0m : The user prepared and structured audio data for \n",
              "classification tasks. This included tasks like loading, merging, and synchronizing metadata for effective analysis.\n",
              ": \u001b[1;36m2\u001b[0m\n",
              "    + \u001b[1mPrepare audio data for classification analysis\u001b[0m : The user processed and organized audio files for effective \n",
              "classification. This involved loading, merging DataFrames, and synchronizing metadata for analysis. : \u001b[1;36m2\u001b[0m\n",
              "\n",
              "\n",
              "  • \u001b[1mAssist with dataset versioning in W&B\u001b[0m : Users sought help with managing dataset versioning and artifacts in \n",
              "W&B. They focused on logging, tracking, and updating datasets for improved reproducibility in machine learning \n",
              "workflows. : \u001b[1;36m35\u001b[0m\n",
              "    + \u001b[1mHelp me manage dataset versioning in W&B\u001b[0m : Users sought assistance with handling dataset versioning and \n",
              "artifacts in W&B. They specifically focused on logging, tracking, and updating datasets for better reproducibility \n",
              "in their machine learning workflows. : \u001b[1;36m35\u001b[0m\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "====\n",
              "\n",
              "\n",
              "\u001b[1m(\u001b[0m\u001b[1m92d75e32975c4651a2ab46ccb8a83fd9\u001b[0m\u001b[1m)\u001b[0m\u001b[1m Optimize machine learning experiments and resources\u001b[0m : Users explored methods to \n",
              "optimize and visualize machine learning experiments through Weights & Biases. They focused on hyperparameter \n",
              "tuning, multi-GPU training, and maximizing the tool's utilization for improved performance and efficiency. : \u001b[1;36m449\u001b[0m\n",
              "\n",
              "  • \u001b[1mOptimize and visualize machine learning experiments with W&B\u001b[0m : Users explored methods to log and visualize \n",
              "machine learning experiments using Weights & Biases. They focused on customizing visualizations, handling data \n",
              "formats, and enhancing tracking for better analysis. : \u001b[1;36m195\u001b[0m\n",
              "    + \u001b[1mExplore data visualization with W&B Tables\u001b[0m : Users investigated how to visualize diverse media types using \n",
              "wandb.Table. They aimed to manage and analyze different data formats effectively within the W&B Tables interface. :\n",
              "\u001b[1;36m4\u001b[0m\n",
              "    + \u001b[1mHelp me log and visualize experiments in W&B\u001b[0m : Users requested guidance on visualizing and logging various \n",
              "aspects of machine learning experiments using Weights & Biases \u001b[1m(\u001b[0mW&B\u001b[1m)\u001b[0m. They focused on customizing visualizations, \n",
              "tracking metrics, managing prompt configurations, and handling multi-class confusion matrices. : \u001b[1;36m71\u001b[0m\n",
              "    + \u001b[1mEnhance machine learning experiment tracking with W&B\u001b[0m : Users optimized and troubleshot experiment tracking \n",
              "with Weights & Biases, focusing on installation, configuration, and logging. They explored core features to improve\n",
              "ML workflows, ensuring better collaboration and data analysis. : \u001b[1;36m120\u001b[0m\n",
              "\n",
              "\n",
              "  • \u001b[1mAssist with hyperparameter optimization using Weights & Biases\u001b[0m : Users requested help with optimizing \n",
              "hyperparameters through Weights & Biases. They sought guidance on configuring sweeps, automating processes, and \n",
              "analyzing results for better performance. : \u001b[1;36m60\u001b[0m\n",
              "    + \u001b[1mHelp optimize hyperparameter sweeps using W&B\u001b[0m : Users requested assistance in programmatically accessing and \n",
              "analyzing hyperparameter optimization results from W&B sweeps. They sought guidance on optimizing configurations \n",
              "for efficient parallel training across multiple GPUs and CPUs. : \u001b[1;36m23\u001b[0m\n",
              "    + \u001b[1mGuide hyperparameter optimization using Weights & Biases\u001b[0m : Users sought assistance with hyperparameter tuning\n",
              "using Weights & Biases and related tools. They requested support for configuring sweeps, automating processes, and \n",
              "troubleshooting to enhance performance. : \u001b[1;36m37\u001b[0m\n",
              "\n",
              "\n",
              "  • \u001b[1mAssist with multi-GPU training and optimization\u001b[0m : Users explored methods for effective multi-GPU distributed \n",
              "training using HuggingFace while seeking optimization of GPU resources during model training. They focused on job \n",
              "management, script arguments, and resource monitoring to enhance training efficiency. : \u001b[1;36m9\u001b[0m\n",
              "    + \u001b[1mGuide multi-GPU distributed training with HuggingFace\u001b[0m : Users requested help on setting up multi-GPU \n",
              "distributed training using HuggingFace Accelerate. They focused on launching jobs and managing script arguments \n",
              "across various hardware configurations. : \u001b[1;36m3\u001b[0m\n",
              "    + \u001b[1mOptimize GPU resources for model training\u001b[0m : Users sought assistance in optimizing GPU usage and memory during\n",
              "machine learning training. They emphasized the integration of W&B for monitoring and enhancing the efficiency of \n",
              "training processes. : \u001b[1;36m6\u001b[0m\n",
              "\n",
              "\n",
              "  • \u001b[1mAssist in maximizing Weights & Biases utilization\u001b[0m : Users sought guidance on using Weights & Biases to manage \n",
              "experiments and data effectively. They aimed to optimize their machine learning workflows through understanding its\n",
              "features, configurations, and best practices. : \u001b[1;36m185\u001b[0m\n",
              "    + \u001b[1mGuide effective use of Weights & Biases\u001b[0m : Users sought assistance in leveraging Weights & Biases for managing\n",
              "experiments and data effectively. They aimed to enhance their machine learning workflows by understanding features,\n",
              "configurations, and best practices related to experiment tracking, data manipulation, and artifact management. : \n",
              "\u001b[1;36m185\u001b[0m\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "====\n",
              "\n",
              "\n",
              "\u001b[1m(\u001b[0m\u001b[1m126ad2b1c8054e7b93d0dc652841623c\u001b[0m\u001b[1m)\u001b[0m\u001b[1m Enhance machine learning project collaboration with W&B\u001b[0m : Users integrated \n",
              "Weights & Biases into machine learning workflows while enhancing team collaboration features. They focused on \n",
              "optimizing tracking, management settings, and collaborative capabilities for effective project execution. : \u001b[1;36m74\u001b[0m\n",
              "\n",
              "  • \u001b[1mIntegrate W&B with machine learning frameworks\u001b[0m : Users received help integrating W&B tracking into their \n",
              "machine learning workflows, specifically with PyTorch and TensorFlow. They also learned to manage W&B settings and \n",
              "SageMaker configurations for secure deployments and effective tracking. : \u001b[1;36m56\u001b[0m\n",
              "    + \u001b[1mIntegrate W&B tracking into ML workflows\u001b[0m : Users received assistance in integrating W&B experiment tracking \n",
              "into their machine learning workflows using both PyTorch and TensorFlow. They learned to log metrics, \n",
              "hyperparameters, and artifacts effectively throughout the model training process. : \u001b[1;36m19\u001b[0m\n",
              "    + \u001b[1mAssist with W&B and SageMaker setup tasks\u001b[0m : Users needed help configuring sharing settings for W&B reports \n",
              "and managing API keys. They also sought assistance in setting up secure IAM roles for SageMaker to ensure safe \n",
              "deployment and access management. : \u001b[1;36m37\u001b[0m\n",
              "\n",
              "\n",
              "  • \u001b[1mOptimize team collaboration and management in W&B\u001b[0m : Users explored ways to enhance collaboration and management\n",
              "features in Weights & Biases. They focused on configuring roles, permissions, and various enterprise capabilities \n",
              "for improved project outcomes. : \u001b[1;36m18\u001b[0m\n",
              "    + \u001b[1mEnhance team collaboration in Weights & Biases\u001b[0m : Users sought to optimize collaborative features in Weights &\n",
              "Biases for better project management. They focused on configuring roles, permissions, and team settings to improve \n",
              "collaboration outcomes. : \u001b[1;36m10\u001b[0m\n",
              "    + \u001b[1mHelp with team management and enterprise features\u001b[0m : Users sought assistance in managing team roles and \n",
              "permissions within W&B, including inquiries about enterprise features specific to W&B Server. They explored topics \n",
              "such as access control, secure storage, and distinctions in user management across membership tiers. : \u001b[1;36m8\u001b[0m\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "====\n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get top-level clusters (those without parents)\n",
        "parent_clusters = [cluster for cluster in clusters if cluster.parent_id is None]\n",
        "\n",
        "# Format each cluster's info with name, description and number of chats\n",
        "formatted_clusters = []\n",
        "for parent in parent_clusters:\n",
        "    # Add parent cluster info\n",
        "    cluster_info = f\"[bold]({parent.id}) {parent.name}[/bold] : {parent.description} : {len(parent.chat_ids)}\\n\"\n",
        "\n",
        "    # Get and format child clusters\n",
        "    child_clusters = [c for c in clusters if c.parent_id == parent.id]\n",
        "    for child in child_clusters:\n",
        "        cluster_info += f\"\\n  • [bold]{child.name}[/bold] : {child.description} : {len(child.chat_ids)}\"\n",
        "        child_child_clusters = [c for c in clusters if c.parent_id == child.id]\n",
        "        for child_child in child_child_clusters:\n",
        "            if child_child.parent_id == child.id:\n",
        "                cluster_info += f\"\\n    + [bold]{child_child.name}[/bold] : {child_child.description} : {len(child_child.chat_ids)}\"\n",
        "\n",
        "        cluster_info += \"\\n\\n\"\n",
        "\n",
        "    formatted_clusters.append(cluster_info)\n",
        "    formatted_clusters.append(\"\\n====\\n\")\n",
        "\n",
        "# Join with newlines and print\n",
        "rprint(\"\\n\\n\".join(formatted_clusters))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "### What You Learned\n",
        "\n",
        "In this notebook, you learned how to create domain-specific summarization models that dramatically improve clustering quality. You discovered how to:\n",
        "\n",
        "- **Create custom summary models** using specialized prompts tailored to your domain\n",
        "- **Replace generic descriptions** with precise, feature-specific summaries\n",
        "- **Configure clustering parameters** to achieve optimal grouping results\n",
        "- **Compare clustering outcomes** between default and custom approaches\n",
        "\n",
        "### What We Accomplished\n",
        "\n",
        "We were able to address the key limitation of our initial clustering using a new custom prompt that was domain specific, focusing on W&B features and user intentions. This allowed us to transform our clsutering results from generic topic groups into highly actionable categories.\n",
        "\n",
        "1. **Optimize machine learning experiments and resources** (449 conversations) - The largest cluster covering users exploring experiment tracking, hyperparameter optimization, multi-GPU training, and maximizing W&B utilization for improved ML performance\n",
        "2. **Enhance machine learning project collaboration with W&B** (74 conversations) - Users integrating W&B with PyTorch/TensorFlow workflows and optimizing team collaboration features including roles, permissions, and enterprise capabilities\n",
        "3. **Manage audio files and dataset versioning** (37 conversations) - Users organizing audio data for classification analysis and managing dataset versioning workflows in W&B\n",
        "\n",
        "This represents a significant upgrade from our previous clusters, providing much more specific and actionable information about user needs. The improved summaries eliminated the vagueness of descriptions like \"user seeks information about tracking\" and replaced them with precise insights about specific W&B workflows, optimization goals, and collaboration requirements.\n",
        "\n",
        "\n",
        "\n",
        "### Next: Building Production Classifiers\n",
        "\n",
        "While our improved clustering gives us deep insights into historical query patterns, we need a way to act on these insights in real-time production environments. In the next notebook, \"Classifiers\", we'll bridge the gap between discovery and action by:\n",
        "\n",
        "- **Building production-ready classifiers** using the `instructor` library to achieve ~90% accuracy through systematic prompt engineering\n",
        "- **Creating automated labeling workflows** with weak supervision to efficiently generate labeled datasets for training\n",
        "- **Focusing on three high-impact categories** - artifacts (20% of queries), integrations (15%), and visualizations (14%) - that account for almost 50% of all user conversations\n",
        "- **Applying classifiers at scale** to understand true query distributions and identify exactly where to focus improvement efforts\n",
        "\n",
        "This classifier will enable you to automatically categorize incoming queries in real-time, detect production drift when certain query types surge, and intelligently route questions to specialized retrieval systems. More importantly, you'll move from \"we think users struggle with X\" to \"we know 20% of users need help with artifacts, 15% with integrations, and 14% with visualizations—and we can automatically detect and route these queries for specialized handling.\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
