Metadata-Version: 2.4
Name: pyTorchAutoForge
Version: 0.2.1
Summary: PyTorchAutoForge library is based on raw PyTorch and designed to automate DNN development, model tracking and deployment, tightly integrated with MLflow and Optuna. It supports Spiking networks libraries (WIP). Deployment can be performed using ONNx, pyTorch facilities or TensorRT (WIP). The library is designed to be compatible with Jetson Orin Nano Jetpack rev6.1, with bash script to automatically configure virtualenv.
Author-email: "Pietro Califano (PC)" <petercalifano.gs@gmail.com>
License: MIT
License-File: LICENSE
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: POSIX :: Linux
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.10
Requires-Dist: albumentations
Requires-Dist: captum
Requires-Dist: colorama
Requires-Dist: dacite
Requires-Dist: expelliarmus; platform_machine == 'x86_64'
Requires-Dist: inputimeout
Requires-Dist: kornia
Requires-Dist: lietorch; platform_machine == 'x86_64'
Requires-Dist: matplotlib<=3.10.0
Requires-Dist: mlflow<=3.2
Requires-Dist: msgpack
Requires-Dist: mypy
Requires-Dist: norse; platform_machine == 'x86_64'
Requires-Dist: numpy
Requires-Dist: onnx<=1.18.0
Requires-Dist: onnxruntime
Requires-Dist: onnxscript
Requires-Dist: optuna
Requires-Dist: pytest<=8.3.5
Requires-Dist: scikit-learn<=1.6.1
Requires-Dist: scipy
Requires-Dist: seaborn
Requires-Dist: statsmodels
Requires-Dist: tonic; platform_machine == 'x86_64'
Requires-Dist: torch-tb-profiler
Requires-Dist: torch<=2.8.0; platform_machine == 'x86_64'
Requires-Dist: torchinfo
Requires-Dist: torchvision; platform_machine == 'x86_64'
Provides-Extra: cuda-all
Requires-Dist: pycuda; (platform_machine == 'x86_64') and extra == 'cuda-all'
Requires-Dist: pynvml; (platform_machine == 'x86_64') and extra == 'cuda-all'
Description-Content-Type: text/markdown

# pyTorchAutoForge
_Warning: Work in progress :)_

A library based on PyTorch (<https://pytorch.org/>) and designed to automate ML models development, tracking and deployment, integrated with MLflow and Optuna (<https://mlflow.org/>, <https://optuna.org/>). It also supports spiking networks libraries (WIP). Model optimization and deployment can be performed using ONNx, pyTorch facilities or TensorRT (WIP). The library aims to be compatible with Jetson Orin Nano Jetpack rev6.1. Several other functionalities and utilities for sklearn and pySR (<https://github.com/MilesCranmer/PySR>) are included (see README and documentation).

## Installation using pip

This is the suggested installation method, the others are mostly intended for development and may not be completely up-to-date with the newest release versions. 
Run in a conda or virtual environment:

```bash
pip install pyTorchAutoForge
```

Dependencies for the core modules should be installed automatically using pip.

## Manual installation (venv)

1) Clone the repository
2) Create a virtual environment using python >= 3.10 (tested with 3.11), using `python -m venv <your_venv_name>`
3) Activate the virtual environment using `source <your_venv_name>/bin/activate`
4) Install the requirements using `pip install -r requirements.txt`
5) Install the package using `pip install .` in the root folder of the repository

## Manual installation (conda)

### Option A:
  1) Clone the repository
  2) Create a new conda environment (python >=3.10) using the provided `enrivonment.yml` file

### Option B;
  1) Clone the repository
  2) Use the automatic installation script `conda_install.sh`. There are several options, use those you need. It will automatically create a new environment named **autoforge**.
