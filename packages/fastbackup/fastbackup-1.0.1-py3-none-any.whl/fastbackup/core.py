#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FastBackup - ä¸€è¡Œå¯¼å…¥å¼å®éªŒå¤‡ä»½å·¥å…·
åªéœ€è¦åœ¨mainå‡½æ•°å¼€å¤´ import fastbackup å³å¯è‡ªåŠ¨å¤‡ä»½
"""

import os
import sys
import shutil
import datetime
import json
import hashlib
import inspect
from pathlib import Path
import atexit


class FastBackup:
    def __init__(self):
        # è‡ªåŠ¨æ£€æµ‹è°ƒç”¨è„šæœ¬çš„ç›®å½•ä½œä¸ºé¡¹ç›®æ ¹ç›®å½•
        caller_frame = inspect.currentframe().f_back
        caller_file = caller_frame.f_globals['__file__']
        self.project_path = Path(caller_file).parent.resolve()

        # å¤‡ä»½ç›®å½•è®¾ç½®ä¸ºé¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ .fastbackup
        self.backup_root = self.project_path / '.fastbackup'
        self.backup_root.mkdir(exist_ok=True)

        # åˆ›å»º .gitignore æ–‡ä»¶å¿½ç•¥å¤‡ä»½ç›®å½•
        gitignore_path = self.project_path / '.gitignore'
        self._update_gitignore(gitignore_path)

        # æ‰§è¡Œå¤‡ä»½
        self.backup_dir = self._auto_backup()

        # æ³¨å†Œé€€å‡ºæ—¶çš„æ¸…ç†å‡½æ•°
        atexit.register(self._on_exit)

    def _update_gitignore(self, gitignore_path):
        """æ›´æ–°.gitignoreæ–‡ä»¶ï¼Œå¿½ç•¥å¤‡ä»½ç›®å½•"""
        gitignore_entry = ".fastbackup/"

        if gitignore_path.exists():
            with open(gitignore_path, 'r', encoding='utf-8') as f:
                content = f.read()

            if gitignore_entry not in content:
                with open(gitignore_path, 'a', encoding='utf-8') as f:
                    if not content.endswith('\n'):
                        f.write('\n')
                    f.write(f"{gitignore_entry}\n")
        else:
            with open(gitignore_path, 'w', encoding='utf-8') as f:
                f.write(f"{gitignore_entry}\n")

    def _get_python_files(self):
        """è·å–é¡¹ç›®ä¸­æ‰€æœ‰Pythonæ–‡ä»¶"""
        python_files = []
        exclude_dirs = {'.git', '__pycache__', '.pytest_cache', 'venv', 'env',
                        '.venv', 'node_modules', '.fastbackup', '.idea', '.vscode'}

        for root, dirs, files in os.walk(self.project_path):
            # è¿‡æ»¤æ‰ä¸éœ€è¦çš„ç›®å½•
            dirs[:] = [d for d in dirs if d not in exclude_dirs and not d.startswith('.')]

            for file in files:
                if file.endswith('.py'):
                    file_path = Path(root) / file
                    python_files.append(file_path)

        return python_files

    def _calculate_file_hash(self, file_path):
        """è®¡ç®—æ–‡ä»¶çš„MD5å“ˆå¸Œå€¼"""
        hash_md5 = hashlib.md5()
        try:
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except:
            return None

    def _has_changes(self):
        """æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶å˜åŒ–"""
        latest_backup = self._get_latest_backup()
        if not latest_backup:
            return True

        info_file = latest_backup / "backup_info.json"
        if not info_file.exists():
            return True

        try:
            with open(info_file, 'r', encoding='utf-8') as f:
                last_info = json.load(f)
        except:
            return True

        # æ£€æŸ¥å½“å‰æ–‡ä»¶å“ˆå¸Œ
        current_files = self._get_python_files()
        current_hashes = {}

        for file_path in current_files:
            rel_path = str(file_path.relative_to(self.project_path))
            file_hash = self._calculate_file_hash(file_path)
            if file_hash:
                current_hashes[rel_path] = file_hash

        last_hashes = last_info.get('file_hashes', {})
        return current_hashes != last_hashes

    def _get_latest_backup(self):
        """è·å–æœ€æ–°çš„å¤‡ä»½ç›®å½•"""
        backup_dirs = [d for d in self.backup_root.iterdir() if d.is_dir()]
        if not backup_dirs:
            return None
        return max(backup_dirs, key=lambda x: x.name)

    def _auto_backup(self):
        """è‡ªåŠ¨æ‰§è¡Œå¤‡ä»½"""
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤‡ä»½
        if not self._has_changes():
            latest_backup = self._get_latest_backup()
            if latest_backup:
                print(f"ğŸ”„ FastBackup: ä½¿ç”¨ç°æœ‰å¤‡ä»½ {latest_backup.name}")
            return latest_backup

        # åˆ›å»ºæ–°å¤‡ä»½
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"backup_{timestamp}"
        backup_dir = self.backup_root / backup_name
        backup_dir.mkdir(exist_ok=True)

        python_files = self._get_python_files()

        if not python_files:
            print("âš ï¸  FastBackup: æ²¡æœ‰æ‰¾åˆ°Pythonæ–‡ä»¶")
            return None

        print(f"ğŸ’¾ FastBackup: åˆ›å»ºå¤‡ä»½ {backup_name} ({len(python_files)} ä¸ªæ–‡ä»¶)")

        # å¤‡ä»½ä¿¡æ¯
        backup_info = {
            "timestamp": timestamp,
            "project_path": str(self.project_path),
            "file_count": len(python_files),
            "file_hashes": {},
            "files": []
        }

        # å¤åˆ¶æ–‡ä»¶
        for file_path in python_files:
            try:
                rel_path = file_path.relative_to(self.project_path)
                target_path = backup_dir / rel_path
                target_path.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(file_path, target_path)

                file_hash = self._calculate_file_hash(file_path)
                file_info = {
                    "path": str(rel_path),
                    "size": file_path.stat().st_size,
                    "modified": datetime.datetime.fromtimestamp(file_path.stat().st_mtime).isoformat(),
                    "hash": file_hash
                }

                backup_info["files"].append(file_info)
                if file_hash:
                    backup_info["file_hashes"][str(rel_path)] = file_hash

            except Exception as e:
                print(f"âš ï¸  FastBackup: å¤‡ä»½å¤±è´¥ {file_path}: {e}")

        # ä¿å­˜å¤‡ä»½ä¿¡æ¯
        with open(backup_dir / "backup_info.json", 'w', encoding='utf-8') as f:
            json.dump(backup_info, f, indent=2, ensure_ascii=False)

        return backup_dir

    def _on_exit(self):
        """ç¨‹åºé€€å‡ºæ—¶çš„å¤„ç†"""
        if hasattr(self, 'backup_dir') and self.backup_dir:
            # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ ä¸€äº›é€€å‡ºæ—¶çš„å¤„ç†é€»è¾‘
            pass

    @classmethod
    def list_backups(cls, project_path=None):
        """åˆ—å‡ºæ‰€æœ‰å¤‡ä»½ï¼ˆç±»æ–¹æ³•ï¼Œå¯ä»¥ç‹¬ç«‹è°ƒç”¨ï¼‰"""
        if project_path is None:
            # è‡ªåŠ¨æ£€æµ‹å½“å‰é¡¹ç›®è·¯å¾„
            caller_frame = inspect.currentframe().f_back
            caller_file = caller_frame.f_globals['__file__']
            project_path = Path(caller_file).parent.resolve()
        else:
            project_path = Path(project_path).resolve()

        backup_root = project_path / '.fastbackup'

        if not backup_root.exists():
            print("ğŸ“ æ²¡æœ‰æ‰¾åˆ°å¤‡ä»½ç›®å½•")
            return

        backup_dirs = sorted([d for d in backup_root.iterdir() if d.is_dir()],
                             key=lambda x: x.name, reverse=True)

        if not backup_dirs:
            print("ğŸ“ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¤‡ä»½")
            return

        print(f"ğŸ“‹ FastBackup å†å²è®°å½• ({len(backup_dirs)} ä¸ªå¤‡ä»½):")
        print("-" * 60)

        for i, backup_dir in enumerate(backup_dirs[:10]):  # åªæ˜¾ç¤ºæœ€è¿‘10ä¸ª
            info_file = backup_dir / "backup_info.json"

            if info_file.exists():
                try:
                    with open(info_file, 'r', encoding='utf-8') as f:
                        info = json.load(f)

                    timestamp = info.get('timestamp', '')
                    file_count = info.get('file_count', 0)

                    # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
                    try:
                        dt = datetime.datetime.strptime(timestamp, "%Y%m%d_%H%M%S")
                        time_str = dt.strftime("%Y-%m-%d %H:%M:%S")
                    except:
                        time_str = timestamp

                    print(f"{i + 1:2d}. {time_str} | {file_count} æ–‡ä»¶ | {backup_dir.name}")

                except Exception:
                    print(f"{i + 1:2d}. {backup_dir.name} (ä¿¡æ¯è¯»å–å¤±è´¥)")
            else:
                print(f"{i + 1:2d}. {backup_dir.name} (æ— ä¿¡æ¯æ–‡ä»¶)")

        if len(backup_dirs) > 10:
            print(f"... è¿˜æœ‰ {len(backup_dirs) - 10} ä¸ªæ›´æ—©çš„å¤‡ä»½")

    @classmethod
    def restore_backup(cls, backup_name, project_path=None):
        """æ¢å¤æŒ‡å®šçš„å¤‡ä»½"""
        if project_path is None:
            caller_frame = inspect.currentframe().f_back
            caller_file = caller_frame.f_globals['__file__']
            project_path = Path(caller_file).parent.resolve()
        else:
            project_path = Path(project_path).resolve()

        backup_root = project_path / '.fastbackup'
        backup_dir = backup_root / backup_name

        if not backup_dir.exists():
            print(f"âŒ å¤‡ä»½ä¸å­˜åœ¨: {backup_name}")
            return False

        print(f"ğŸ”„ æ¢å¤å¤‡ä»½: {backup_name}")

        # è¯»å–å¤‡ä»½ä¿¡æ¯
        info_file = backup_dir / "backup_info.json"
        if info_file.exists():
            with open(info_file, 'r', encoding='utf-8') as f:
                backup_info = json.load(f)

            restored_count = 0
            for file_info in backup_info.get('files', []):
                src_path = backup_dir / file_info['path']
                dst_path = project_path / file_info['path']

                if src_path.exists():
                    try:
                        dst_path.parent.mkdir(parents=True, exist_ok=True)
                        shutil.copy2(src_path, dst_path)
                        restored_count += 1
                        print(f"  âœ… {file_info['path']}")
                    except Exception as e:
                        print(f"  âŒ {file_info['path']}: {e}")

            print(f"âœ¨ æ¢å¤å®Œæˆ! å…±æ¢å¤ {restored_count} ä¸ªæ–‡ä»¶")
            return True
        else:
            print("âŒ æ‰¾ä¸åˆ°å¤‡ä»½ä¿¡æ¯æ–‡ä»¶")
            return False


# å…¨å±€å˜é‡ï¼Œé¿å…é‡å¤åˆå§‹åŒ–
_backup_instance = None


def _ensure_backup():
    """ç¡®ä¿å¤‡ä»½å®ä¾‹å·²åˆ›å»ºï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
    global _backup_instance
    if _backup_instance is None:
        _backup_instance = FastBackup()
    return _backup_instance


# å¯¼å‡ºçš„ä¾¿æ·å‡½æ•°
def backup():
    """æ‰‹åŠ¨è§¦å‘å¤‡ä»½"""
    return _ensure_backup()


def list_backups():
    """åˆ—å‡ºæ‰€æœ‰å¤‡ä»½"""
    FastBackup.list_backups()


def restore(backup_name):
    """æ¢å¤æŒ‡å®šå¤‡ä»½"""
    return FastBackup.restore_backup(backup_name)


# å½“æ¨¡å—è¢«å¯¼å…¥æ—¶è‡ªåŠ¨æ‰§è¡Œå¤‡ä»½
_ensure_backup()

# å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œæä¾›å‘½ä»¤è¡ŒåŠŸèƒ½
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='FastBackup - å¿«é€Ÿå®éªŒå¤‡ä»½å·¥å…·')
    parser.add_argument('--list', '-l', action='store_true', help='åˆ—å‡ºæ‰€æœ‰å¤‡ä»½')
    parser.add_argument('--restore', '-r', help='æ¢å¤æŒ‡å®šå¤‡ä»½')
    parser.add_argument('--project', '-p', help='é¡¹ç›®è·¯å¾„ï¼ˆé»˜è®¤å½“å‰ç›®å½•ï¼‰')

    args = parser.parse_args()

    if args.list:
        FastBackup.list_backups(args.project or os.getcwd())
    elif args.restore:
        FastBackup.restore_backup(args.restore, args.project or os.getcwd())
    else:
        print("FastBackup - ä¸€è¡Œå¯¼å…¥å¼å®éªŒå¤‡ä»½å·¥å…·")
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  åœ¨ä½ çš„Pythonè„šæœ¬å¼€å¤´æ·»åŠ : import fastbackup")
        print("  å‘½ä»¤è¡ŒæŸ¥çœ‹å¤‡ä»½: python fastbackup.py --list")
        print("  æ¢å¤å¤‡ä»½: python fastbackup.py --restore backup_20240101_120000")