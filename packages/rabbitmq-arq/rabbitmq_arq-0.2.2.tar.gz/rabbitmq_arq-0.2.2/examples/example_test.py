# -*- coding: utf-8 -*-
# @version        : 1.0
# @Create Time    : 2025/5/9 21:00
# @File           : test_example
# @IDE            : PyCharm
# @desc           : æµ‹è¯• RabbitMQ-ARQ ä¿®å¤æ•ˆæœ

import asyncio
import logging
import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ï¼ˆç”¨äºå¼€å‘ç¯å¢ƒï¼‰
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from rabbitmq_arq import (
    Worker,
    WorkerSettings,
    RabbitMQClient,
    RabbitMQSettings,
    JobContext,
    Retry
)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger('test_example')

# RabbitMQ è¿æ¥é…ç½®
rabbitmq_settings = RabbitMQSettings(
    rabbitmq_url="amqp://guest:guest@localhost:5672/",
    prefetch_count=10,
    connection_timeout=30,
)


# === æµ‹è¯•ä»»åŠ¡å‡½æ•° ===

async def basic_task_test(ctx: JobContext, task_name: str, data: dict):
    """åŸºç¡€ä»»åŠ¡æµ‹è¯•"""
    logger.info(f"ğŸ”¬ æ‰§è¡ŒåŸºç¡€ä»»åŠ¡: {task_name}")
    logger.info(f"   ä»»åŠ¡ID: {ctx.job_id}")
    logger.info(f"   æ•°æ®: {data}")

    await asyncio.sleep(30)

    logger.info(f"âœ… åŸºç¡€ä»»åŠ¡ {task_name} å»¶è¿Ÿ30ç§’ å®Œæˆ")
    return {"task_name": task_name, "status": "completed", "data": data}


async def retry_task_test(ctx: JobContext, retry_count: int = 2):
    """é‡è¯•ä»»åŠ¡æµ‹è¯• - ARQ é£æ ¼"""
    logger.info(f"ğŸ”„ æ‰§è¡Œé‡è¯•ä»»åŠ¡æµ‹è¯•")
    logger.info(f"   ä»»åŠ¡ID: {ctx.job_id}")
    logger.info(f"   å½“å‰å°è¯•: {ctx.job_try}")
    logger.info(f"   é¢„æœŸé‡è¯•: {retry_count} æ¬¡")

    if ctx.job_try <= retry_count:
        logger.warning(f"ğŸ’¥ ä»»åŠ¡éœ€è¦é‡è¯• ({ctx.job_try}/{retry_count})")
        # ARQ é£æ ¼ï¼šæ˜¾å¼æŠ›å‡º Retry å¼‚å¸¸
        raise Retry(defer=1)  # 1ç§’åé‡è¯•

    logger.info(f"âœ… é‡è¯•ä»»åŠ¡æœ€ç»ˆæˆåŠŸ")
    return {"retry_count": ctx.job_try - 1, "status": "completed"}


async def delayed_task_test(ctx: JobContext, message: str):
    """å»¶è¿Ÿä»»åŠ¡æµ‹è¯•"""
    logger.info(f"â° æ‰§è¡Œå»¶è¿Ÿä»»åŠ¡: {message}")
    logger.info(f"   ä»»åŠ¡ID: {ctx.job_id}")

    await asyncio.sleep(0.2)

    logger.info(f"âœ… å»¶è¿Ÿä»»åŠ¡å®Œæˆ: {message}")
    return {"message": message, "status": "completed"}


async def error_task_test(ctx: JobContext, error_message: str = "æµ‹è¯•é”™è¯¯"):
    """é”™è¯¯ä»»åŠ¡æµ‹è¯• - ARQ é£æ ¼ï¼ŒæŠ›å‡ºä¸å¯é‡è¯•çš„å¼‚å¸¸"""
    logger.info(f"ğŸ’¥ æ‰§è¡Œé”™è¯¯ä»»åŠ¡æµ‹è¯•")
    logger.info(f"   ä»»åŠ¡ID: {ctx.job_id}")
    logger.info(f"   é”™è¯¯ä¿¡æ¯: {error_message}")
    
    # æ¨¡æ‹Ÿä¸€äº›å¤„ç†æ—¶é—´
    await asyncio.sleep(0.1)
    
    # ARQ é£æ ¼ï¼šæŠ›å‡ºæ˜ç¡®çš„ä¸å¯é‡è¯•å¼‚å¸¸
    logger.warning(f"âŒ ä»»åŠ¡å³å°†æŠ›å‡º ValueError: {error_message}")
    raise ValueError(error_message)  # ValueError æ˜¯ä¸å¯é‡è¯•çš„å¼‚å¸¸


async def network_retry_task_test(ctx: JobContext, should_succeed_on_try: int = 3):
    """ç½‘ç»œé‡è¯•ä»»åŠ¡æµ‹è¯• - æ¨¡æ‹Ÿç½‘ç»œé”™è¯¯çš„é‡è¯•"""
    logger.info(f"ğŸŒ æ‰§è¡Œç½‘ç»œé‡è¯•ä»»åŠ¡æµ‹è¯•")
    logger.info(f"   ä»»åŠ¡ID: {ctx.job_id}")
    logger.info(f"   å½“å‰å°è¯•: {ctx.job_try}")
    logger.info(f"   é¢„æœŸåœ¨ç¬¬ {should_succeed_on_try} æ¬¡å°è¯•æˆåŠŸ")
    
    # æ¨¡æ‹Ÿç½‘ç»œè¯·æ±‚
    await asyncio.sleep(0.1)
    
    if ctx.job_try < should_succeed_on_try:
        logger.warning(f"ğŸŒ æ¨¡æ‹Ÿç½‘ç»œè¿æ¥é”™è¯¯ (å°è¯• {ctx.job_try}/{should_succeed_on_try})")
        # æŠ›å‡ºç³»ç»Ÿçº§é”™è¯¯ï¼Œè¿™äº›é”™è¯¯ä¼šè‡ªåŠ¨é‡è¯•
        raise OSError(f"ç½‘ç»œè¿æ¥å¤±è´¥ (å°è¯• {ctx.job_try})")
    
    logger.info(f"âœ… ç½‘ç»œä»»åŠ¡åœ¨ç¬¬ {ctx.job_try} æ¬¡å°è¯•æˆåŠŸ")
    return {"success_on_try": ctx.job_try, "status": "completed"}


# === ç”Ÿå‘½å‘¨æœŸé’©å­ ===

async def startup_test(ctx: dict):
    """æµ‹è¯•å¯åŠ¨é’©å­"""
    logger.info("ğŸš€ æµ‹è¯• Worker å¯åŠ¨ä¸­...")
    ctx['test_stats'] = {
        'start_time': asyncio.get_event_loop().time(),
        'jobs_processed': 0,
        'jobs_completed': 0,
        'jobs_failed': 0,
        'jobs_retried': 0
    }
    logger.info("âœ… æµ‹è¯• Worker å‡†å¤‡å°±ç»ª")


async def shutdown_test(ctx: dict):
    """æµ‹è¯•å…³é—­é’©å­"""
    logger.info("ğŸ›‘ æµ‹è¯• Worker æ­£åœ¨å…³é—­...")

    stats = ctx.get('test_stats', {})
    start_time = stats.get('start_time', 0)
    current_time = asyncio.get_event_loop().time()
    runtime = current_time - start_time if start_time else 0

    logger.info("ğŸ“Š æµ‹è¯•è¿è¡Œç»Ÿè®¡:")
    logger.info(f"   è¿è¡Œæ—¶é—´: {runtime:.2f} ç§’")
    logger.info(f"   å¤„ç†ä»»åŠ¡: {stats.get('jobs_processed', 0)} ä¸ª")
    logger.info(f"   æˆåŠŸä»»åŠ¡: {stats.get('jobs_completed', 0)} ä¸ª")
    logger.info(f"   å¤±è´¥ä»»åŠ¡: {stats.get('jobs_failed', 0)} ä¸ª")
    logger.info(f"   é‡è¯•ä»»åŠ¡: {stats.get('jobs_retried', 0)} ä¸ª")

    logger.info("âœ… æµ‹è¯• Worker å·²å…³é—­")


async def job_start_hook(ctx: dict):
    """ä»»åŠ¡å¼€å§‹é’©å­"""
    stats = ctx.get('test_stats', {})
    stats['jobs_processed'] = stats.get('jobs_processed', 0) + 1


async def job_end_hook(ctx: dict):
    """ä»»åŠ¡ç»“æŸé’©å­"""
    stats = ctx.get('test_stats', {})
    job_status = ctx.get('job_status')

    if job_status == 'completed':
        stats['jobs_completed'] = stats.get('jobs_completed', 0) + 1
    elif job_status == 'failed':
        stats['jobs_failed'] = stats.get('jobs_failed', 0) + 1
    elif job_status == 'retried':
        stats['jobs_retried'] = stats.get('jobs_retried', 0) + 1


# === Worker é…ç½® ===

# æµ‹è¯• Worker é…ç½®
test_worker_settings = WorkerSettings(
    rabbitmq_settings=rabbitmq_settings,
    functions=[basic_task_test, retry_task_test, delayed_task_test, error_task_test, network_retry_task_test],
    worker_name="test_worker",

    # é˜Ÿåˆ—é…ç½®
    queue_name="test_queue",
    dlq_name="test_queue_dlq",

    # ä»»åŠ¡å¤„ç†é…ç½®
    max_retries=3,
    retry_backoff=1.0,
    # job_timeout=30,
    max_concurrent_jobs=3,

    # Burst æ¨¡å¼é…ç½®ï¼ˆç”¨äºæµ‹è¯•ï¼‰
    burst_mode=False,
    burst_timeout=60,
    burst_check_interval=1.0,
    burst_wait_for_tasks=True,

    # ç”Ÿå‘½å‘¨æœŸé’©å­
    on_startup=startup_test,
    on_shutdown=shutdown_test,
    on_job_start=job_start_hook,
    on_job_end=job_end_hook,

    # æ—¥å¿—é…ç½®
    log_level="INFO",

    job_result_store_url="redis://:Admin123@127.0.0.1:46379/0",
)


# === æµ‹è¯•å‡½æ•° ===

async def basic_functionality_test():
    """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
    logger.info("ğŸ§ª å¼€å§‹åŸºæœ¬åŠŸèƒ½æµ‹è¯•")

    client = RabbitMQClient(
        rabbitmq_settings,
        result_store_url="redis://:Admin123@127.0.0.1:46379/0"
    )

    try:
        await client.connect()
        logger.info("âœ… å®¢æˆ·ç«¯è¿æ¥æˆåŠŸ")

        # æµ‹è¯•åŸºç¡€ä»»åŠ¡æäº¤
        job1 = await client.enqueue_job(
            "basic_task_test",
            task_name="åŸºç¡€æµ‹è¯•",
            data={"test": True, "number": 123},
            queue_name="test_queue"
        )
        logger.info(f"âœ… åŸºç¡€ä»»åŠ¡å·²æäº¤: {job1.job_id}")
        logger.info(f"âœ… åŸºç¡€ä»»åŠ¡ç»“æœ: {await job1.result()}")

        # æµ‹è¯•é‡è¯•ä»»åŠ¡
        job2 = await client.enqueue_job(
            "retry_task_test",
            retry_count=2,
            queue_name="test_queue"
        )
        logger.info(f"âœ… é‡è¯•ä»»åŠ¡å·²æäº¤: {job2.job_id}")

        # æµ‹è¯•å»¶è¿Ÿä»»åŠ¡
        job3 = await client.enqueue_job(
            "delayed_task_test",
            message="è¿™æ˜¯ä¸€ä¸ªå»¶è¿Ÿ3ç§’çš„ä»»åŠ¡",
            queue_name="test_queue",
            _defer_by=3
        )
        logger.info(f"âœ… å»¶è¿Ÿä»»åŠ¡å·²æäº¤: {job3.job_id}")

        # æµ‹è¯•é”™è¯¯ä»»åŠ¡
        job4 = await client.enqueue_job(
            "error_task_test",
            error_message="è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•é”™è¯¯",
            queue_name="test_queue"
        )
        logger.info(f"âœ… é”™è¯¯ä»»åŠ¡å·²æäº¤: {job4.job_id}")

        # æµ‹è¯•ç½‘ç»œé‡è¯•ä»»åŠ¡
        job5 = await client.enqueue_job(
            "network_retry_task_test",
            should_succeed_on_try=3,
            queue_name="test_queue"
        )
        logger.info(f"âœ… ç½‘ç»œé‡è¯•ä»»åŠ¡å·²æäº¤: {job5.job_id}")

        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•ä»»åŠ¡å·²æäº¤")

        # æµ‹è¯• ARQ é£æ ¼çš„ä»»åŠ¡çŠ¶æ€å’Œç»“æœ API
        logger.info("ğŸ“‹ å¼€å§‹æµ‹è¯• ARQ é£æ ¼ä»»åŠ¡æ“ä½œ...")

        # æ¼”ç¤ºä»»åŠ¡çŠ¶æ€æŸ¥è¯¢
        jobs = [job1, job2, job3, job4, job5]
        job_names = ["åŸºç¡€ä»»åŠ¡", "é‡è¯•ä»»åŠ¡", "å»¶è¿Ÿä»»åŠ¡", "é”™è¯¯ä»»åŠ¡", "ç½‘ç»œé‡è¯•ä»»åŠ¡"]

        for job, name in zip(jobs, job_names):
            try:
                # è·å–ä»»åŠ¡çŠ¶æ€
                status = await job.status()
                logger.info(f"ğŸ“Š {name} çŠ¶æ€: {status}")

                # è·å–ä»»åŠ¡ä¿¡æ¯
                info = await job.info()
                logger.info(f"â„¹ï¸  {name} ä¿¡æ¯: {info}")
            except Exception as e:
                logger.warning(f"âš ï¸ è·å– {name} çŠ¶æ€å¤±è´¥: {e}")

        # ç­‰å¾…å¹¶è·å–ä»»åŠ¡ç»“æœ
        logger.info("â³ å¼€å§‹ç­‰å¾…ä»»åŠ¡ç»“æœ...")

        # åŸºç¡€ä»»åŠ¡ç»“æœ
        try:
            logger.info(f"ğŸ”„ ç­‰å¾…åŸºç¡€ä»»åŠ¡å®Œæˆ: {job1.job_id}")
            result1 = await job1.result(timeout=10)
            logger.info(f"âœ… åŸºç¡€ä»»åŠ¡ç»“æœ: {result1}")
        except Exception as e:
            logger.error(f"âŒ è·å–åŸºç¡€ä»»åŠ¡ç»“æœå¤±è´¥: {e}")

        # é‡è¯•ä»»åŠ¡ç»“æœ  
        try:
            logger.info(f"ğŸ”„ ç­‰å¾…é‡è¯•ä»»åŠ¡å®Œæˆ: {job2.job_id}")
            result2 = await job2.result(timeout=15)  # é‡è¯•ä»»åŠ¡éœ€è¦æ›´é•¿æ—¶é—´
            logger.info(f"âœ… é‡è¯•ä»»åŠ¡ç»“æœ: {result2}")
        except Exception as e:
            logger.error(f"âŒ è·å–é‡è¯•ä»»åŠ¡ç»“æœå¤±è´¥: {e}")

        # å»¶è¿Ÿä»»åŠ¡ç»“æœ
        try:
            logger.info(f"ğŸ”„ ç­‰å¾…å»¶è¿Ÿä»»åŠ¡å®Œæˆ: {job3.job_id}")
            result3 = await job3.result(timeout=10)  # å»¶è¿Ÿ3ç§’ + æ‰§è¡Œæ—¶é—´
            logger.info(f"âœ… å»¶è¿Ÿä»»åŠ¡ç»“æœ: {result3}")
        except Exception as e:
            logger.error(f"âŒ è·å–å»¶è¿Ÿä»»åŠ¡ç»“æœå¤±è´¥: {e}")

        # é”™è¯¯ä»»åŠ¡ç»“æœï¼ˆé¢„æœŸå¤±è´¥ï¼‰
        try:
            logger.info(f"ğŸ”„ ç­‰å¾…é”™è¯¯ä»»åŠ¡å®Œæˆ: {job4.job_id}")
            result4 = await job4.result(timeout=10)
            logger.warning(f"âš ï¸ é”™è¯¯ä»»åŠ¡æ„å¤–æˆåŠŸ: {result4}")
        except Exception as e:
            logger.info(f"âœ… é”™è¯¯ä»»åŠ¡æŒ‰é¢„æœŸå¤±è´¥: {e}")

        # ç½‘ç»œé‡è¯•ä»»åŠ¡ç»“æœ
        try:
            logger.info(f"ğŸ”„ ç­‰å¾…ç½‘ç»œé‡è¯•ä»»åŠ¡å®Œæˆ: {job5.job_id}")
            result5 = await job5.result(timeout=15)  # ç½‘ç»œé‡è¯•éœ€è¦æ›´é•¿æ—¶é—´
            logger.info(f"âœ… ç½‘ç»œé‡è¯•ä»»åŠ¡ç»“æœ: {result5}")
        except Exception as e:
            logger.error(f"âŒ è·å–ç½‘ç»œé‡è¯•ä»»åŠ¡ç»“æœå¤±è´¥: {e}")

        # æœ€åå†æ¬¡æ£€æŸ¥æ‰€æœ‰ä»»åŠ¡çš„æœ€ç»ˆçŠ¶æ€
        logger.info("ğŸ æ£€æŸ¥æœ€ç»ˆä»»åŠ¡çŠ¶æ€...")
        for job, name in zip(jobs, job_names):
            try:
                final_status = await job.status()
                logger.info(f"ğŸ“ˆ {name} æœ€ç»ˆçŠ¶æ€: {final_status}")
            except Exception as e:
                logger.warning(f"âš ï¸ è·å– {name} æœ€ç»ˆçŠ¶æ€å¤±è´¥: {e}")

        logger.info("ğŸŠ ARQ é£æ ¼ä»»åŠ¡æ“ä½œæµ‹è¯•å®Œæˆ")

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        raise
    finally:
        await client.close()
        logger.info("å®¢æˆ·ç«¯è¿æ¥å·²å…³é—­")


async def run_test_worker():
    """è¿è¡Œæµ‹è¯• Worker"""
    logger.info("ğŸš€ å¯åŠ¨æµ‹è¯• Worker")
    worker = Worker(test_worker_settings)
    await worker.main()


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1:
        command = sys.argv[1]

        if command == "worker":
            # è¿è¡Œæµ‹è¯• Worker
            asyncio.run(run_test_worker())
        else:
            logger.error(f"âŒ æœªçŸ¥å‘½ä»¤: {command}")
            logger.info("ğŸ’¡ å¯ç”¨å‘½ä»¤:")
            logger.info("  python test_example.py        # æäº¤æµ‹è¯•ä»»åŠ¡")
            logger.info("  python test_example.py worker # å¯åŠ¨æµ‹è¯• Worker")
    else:
        # æäº¤æµ‹è¯•ä»»åŠ¡
        logger.info("å¯åŠ¨æµ‹è¯•æ¨¡å¼...")
        asyncio.run(basic_functionality_test())
