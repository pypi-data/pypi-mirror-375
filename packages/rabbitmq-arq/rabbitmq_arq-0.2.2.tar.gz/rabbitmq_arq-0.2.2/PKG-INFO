Metadata-Version: 2.4
Name: rabbitmq_arq
Version: 0.2.2
Summary: ä¸€ä¸ªåŸºäºRabbitMQçš„ä»»åŠ¡é˜Ÿåˆ—åº“ï¼Œæä¾›ç±»ä¼¼arqçš„ç®€æ´API
Author-email: RabbitMQ-ARQ Team <robin528919@gmail.com>
License-Expression: MIT
Project-URL: Homepage, https://github.com/Robin528919/rabbitmq-mq
Project-URL: Repository, https://github.com/Robin528919/rabbitmq-mq
Project-URL: Documentation, https://github.com/Robin528919/rabbitmq-mq#readme
Project-URL: Bug Tracker, https://github.com/Robin528919/rabbitmq-mq/issues
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: System :: Distributed Computing
Classifier: Framework :: AsyncIO
Classifier: Operating System :: OS Independent
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: aio-pika>=9.0.0
Requires-Dist: pydantic>=2.0.0
Requires-Dist: click>=8.0.0
Requires-Dist: redis>=4.5.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: isort>=5.12.0; extra == "dev"
Requires-Dist: flake8>=6.0.0; extra == "dev"
Requires-Dist: mypy>=1.5.0; extra == "dev"
Requires-Dist: pre-commit>=3.0.0; extra == "dev"
Provides-Extra: mongodb
Requires-Dist: pymongo>=4.3.0; extra == "mongodb"
Requires-Dist: motor>=3.2.0; extra == "mongodb"
Provides-Extra: database
Requires-Dist: asyncpg>=0.28.0; extra == "database"
Requires-Dist: aiomysql>=0.2.0; extra == "database"
Requires-Dist: aiosqlite>=0.19.0; extra == "database"
Provides-Extra: s3
Requires-Dist: aioboto3>=11.0.0; extra == "s3"
Provides-Extra: all
Requires-Dist: pymongo>=4.3.0; extra == "all"
Requires-Dist: motor>=3.2.0; extra == "all"
Requires-Dist: asyncpg>=0.28.0; extra == "all"
Requires-Dist: aiomysql>=0.2.0; extra == "all"
Requires-Dist: aiosqlite>=0.19.0; extra == "all"
Requires-Dist: aioboto3>=11.0.0; extra == "all"
Dynamic: license-file

# RabbitMQ ARQ

ä¸€ä¸ªåŸºäº RabbitMQ çš„å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—åº“ï¼Œæä¾›ç±»ä¼¼ [arq](https://github.com/samuelcolvin/arq) çš„ç®€æ´ APIã€‚

## ç‰¹æ€§

- ğŸš€ **é«˜æ€§èƒ½**: æ”¯æŒ â‰¥5000 æ¶ˆæ¯/ç§’çš„å¤„ç†èƒ½åŠ›
- ğŸ¯ **ç®€æ´ API**: ç±»ä¼¼ arq çš„è£…é¥°å™¨é£æ ¼ï¼Œæ˜“äºä½¿ç”¨
- ğŸ’¾ **ç»“æœå­˜å‚¨**: Rediså­˜å‚¨åç«¯ï¼ŒURLè‡ªåŠ¨è¯†åˆ«é…ç½®
- ğŸ”§ **æ˜“äºè¿ç§»**: æä¾›ä»ç°æœ‰ Consumer è¿ç§»çš„å·¥å…·
- ğŸŒ **ä¸­æ–‡å‹å¥½**: æ”¯æŒä¸­æ–‡æ—¥å¿—è¾“å‡º
- ğŸ”„ **é«˜å¯ç”¨**: å†…ç½®é‡è¯•æœºåˆ¶å’Œé”™è¯¯å¤„ç†
- ğŸ“Š **ç›‘æ§æ”¯æŒ**: é›†æˆç›‘æ§æŒ‡æ ‡æ”¶é›†

## å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
# åŸºç¡€å®‰è£…ï¼ˆåŒ…å«Redisæ”¯æŒï¼‰
pip install rabbitmq-arq

# å®‰è£…æ‰€æœ‰å­˜å‚¨åç«¯ä¾èµ–ï¼ˆä¸ºæœªæ¥ç‰ˆæœ¬åšå‡†å¤‡ï¼‰
pip install "rabbitmq-arq[all]"

# å®‰è£…ç‰¹å®šå­˜å‚¨åç«¯ä¾èµ–
pip install "rabbitmq-arq[mongodb]"    # MongoDBï¼ˆè®¡åˆ’æ”¯æŒï¼‰
pip install "rabbitmq-arq[database]"   # æ•°æ®åº“æ”¯æŒï¼ˆè®¡åˆ’æ”¯æŒï¼‰
pip install "rabbitmq-arq[s3]"         # S3æ”¯æŒï¼ˆè®¡åˆ’æ”¯æŒï¼‰
```

> **æ³¨æ„**ï¼šå½“å‰ç‰ˆæœ¬åªæœ‰Rediså­˜å‚¨åç«¯å¯ç”¨ã€‚å…¶ä»–å­˜å‚¨åç«¯çš„ä¾èµ–åŒ…å·²é¢„å…ˆé…ç½®ï¼Œä½†åŠŸèƒ½å°†åœ¨æœªæ¥ç‰ˆæœ¬ä¸­å®ç°ã€‚

### åŸºæœ¬ä½¿ç”¨

#### å®šä¹‰ä»»åŠ¡

```python
import asyncio
from rabbitmq_arq import JobContext, Retry

# å®šä¹‰ä»»åŠ¡ï¼ˆå¸¦ä¸Šä¸‹æ–‡çš„å¼‚æ­¥å‡½æ•°ï¼‰
async def send_email(ctx: JobContext, to: str, subject: str, body: str) -> dict:
    """å‘é€é‚®ä»¶ä»»åŠ¡"""
    print(f"å‘é€é‚®ä»¶åˆ° {to}: {subject}")
    print(f"ä»»åŠ¡ID: {ctx.job_id}, å°è¯•æ¬¡æ•°: {ctx.job_try}")
    
    # æ¨¡æ‹Ÿé‚®ä»¶å‘é€é€»è¾‘
    await asyncio.sleep(1)
    
    # æ¨¡æ‹Ÿå¯èƒ½çš„å¤±è´¥å’Œé‡è¯•
    if "fail" in to and ctx.job_try <= 2:
        raise Retry(defer=5)  # 5ç§’åé‡è¯•
    
    return {"to": to, "subject": subject, "sent_at": asyncio.get_event_loop().time()}

async def process_data(ctx: JobContext, data: dict) -> dict:
    """æ•°æ®å¤„ç†ä»»åŠ¡"""
    print(f"å¤„ç†æ•°æ®: {data}")
    print(f"ä»»åŠ¡ID: {ctx.job_id}")
    
    # æ•°æ®å¤„ç†é€»è¾‘
    await asyncio.sleep(0.5)
    result = {"processed": True, "count": len(data), "processed_at": asyncio.get_event_loop().time()}
    return result
```

#### å‘é€ä»»åŠ¡

```python
import asyncio
from rabbitmq_arq import RabbitMQClient
from rabbitmq_arq.connections import RabbitMQSettings
from datetime import datetime, timedelta

async def main():
    # åˆ›å»ºå®¢æˆ·ç«¯
    settings = RabbitMQSettings(rabbitmq_url="amqp://localhost:5672")
    client = RabbitMQClient(settings)
    
    # è¿æ¥å¹¶å‘é€ä»»åŠ¡
    await client.connect()
    
    # æäº¤å³æ—¶ä»»åŠ¡
    job = await client.enqueue_job(
        "send_email",  # ä»»åŠ¡åç§°
        to="user@example.com",
        subject="æ¬¢è¿ä½¿ç”¨ RabbitMQ ARQ",
        body="è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•é‚®ä»¶",
        queue_name="default"  # æŒ‡å®šé˜Ÿåˆ—
    )
    print(f"å³æ—¶ä»»åŠ¡å·²æäº¤: {job.job_id}")
    
    # æäº¤å»¶è¿Ÿä»»åŠ¡ï¼ˆå»¶è¿Ÿ10ç§’ï¼‰
    delayed_job = await client.enqueue_job(
        "process_data",
        data={"key": "value", "count": 100},
        queue_name="default",
        _defer_by=10  # å»¶è¿Ÿ10ç§’æ‰§è¡Œ
    )
    print(f"å»¶è¿Ÿä»»åŠ¡å·²æäº¤: {delayed_job.job_id}")
    
    # æäº¤å®šæ—¶ä»»åŠ¡ï¼ˆæŒ‡å®šæ—¶é—´æ‰§è¡Œï¼‰
    scheduled_job = await client.enqueue_job(
        "send_email",
        to="scheduled@example.com",
        subject="å®šæ—¶é‚®ä»¶",
        body="è¿™æ˜¯ä¸€ä¸ªå®šæ—¶é‚®ä»¶",
        queue_name="default",
        defer_until=datetime.now() + timedelta(hours=1)  # 1å°æ—¶åæ‰§è¡Œ
    )
    print(f"å®šæ—¶ä»»åŠ¡å·²æäº¤: {scheduled_job.job_id}")
    
    await client.close()

if __name__ == "__main__":
    asyncio.run(main())
```

#### å¯åŠ¨å·¥ä½œå™¨

```python
import asyncio
from rabbitmq_arq import Worker, WorkerSettings
from rabbitmq_arq.connections import RabbitMQSettings

# ç”Ÿå‘½å‘¨æœŸé’©å­å‡½æ•°
async def startup_hook(ctx: dict):
    """Worker å¯åŠ¨æ—¶æ‰§è¡Œ"""
    print("ğŸš€ Worker å¯åŠ¨ä¸­...")
    # åˆå§‹åŒ–èµ„æºï¼Œå¦‚æ•°æ®åº“è¿æ¥ç­‰
    ctx['start_time'] = asyncio.get_event_loop().time()

async def shutdown_hook(ctx: dict):
    """Worker å…³é—­æ—¶æ‰§è¡Œ"""
    print("ğŸ›‘ Worker å…³é—­ä¸­...")
    # æ¸…ç†èµ„æº
    start_time = ctx.get('start_time', 0)
    runtime = asyncio.get_event_loop().time() - start_time
    print(f"è¿è¡Œæ—¶é—´: {runtime:.1f}ç§’")

async def main():
    # é…ç½®è®¾ç½®
    rabbitmq_settings = RabbitMQSettings(
        rabbitmq_url="amqp://localhost:5672",
        prefetch_count=100,  # æ¶ˆæ¯é¢„å–æ•°é‡
        connection_timeout=30
    )
    
    worker_settings = WorkerSettings(
        rabbitmq_settings=rabbitmq_settings,
        functions=[send_email, process_data],  # ä»»åŠ¡å‡½æ•°åˆ—è¡¨
        worker_name="demo_worker",
        
        # é˜Ÿåˆ—é…ç½®
        queue_name="default",
        dlq_name="default_dlq",  # æ­»ä¿¡é˜Ÿåˆ—
        
        # ä»»åŠ¡å¤„ç†é…ç½®
        max_retries=3,
        retry_backoff=5.0,
        job_timeout=300,
        max_concurrent_jobs=10,
        
        # ç”Ÿå‘½å‘¨æœŸé’©å­
        on_startup=startup_hook,
        on_shutdown=shutdown_hook,
        
        # æ—¥å¿—é…ç½®
        log_level="INFO"
    )
    
    # åˆ›å»ºå¹¶å¯åŠ¨å·¥ä½œå™¨
    worker = Worker(worker_settings)
    await worker.main()

if __name__ == "__main__":
    asyncio.run(main())
```

### å‘½ä»¤è¡Œå·¥å…·

```bash
# å¯åŠ¨å¸¸è§„æ¨¡å¼ Worker
rabbitmq-arq worker -m myapp.workers:worker_settings

# å¯åŠ¨ Burst æ¨¡å¼ Workerï¼ˆå¤„ç†å®Œé˜Ÿåˆ—åè‡ªåŠ¨é€€å‡ºï¼‰
rabbitmq-arq worker -m myapp.workers:worker_settings --burst

# è‡ªå®šä¹‰é…ç½®å¯åŠ¨ Worker
rabbitmq-arq worker -m myapp.workers:worker_settings \
    --rabbitmq-url amqp://user:pass@localhost:5672/ \
    --queue my_queue \
    --max-concurrent-jobs 20 \
    --burst-timeout 600

# æŸ¥çœ‹é˜Ÿåˆ—ä¿¡æ¯
rabbitmq-arq queue-info --queue default

# æ¸…ç©ºé˜Ÿåˆ—
rabbitmq-arq purge-queue --queue default

# éªŒè¯ Worker é…ç½®
rabbitmq-arq validate-config -m myapp.workers:worker_settings
```

## é«˜çº§ç‰¹æ€§

### ä»»åŠ¡ç»“æœå­˜å‚¨

RabbitMQ-ARQ æ”¯æŒå°†ä»»åŠ¡ç»“æœæŒä¹…åŒ–å­˜å‚¨åˆ°Redisï¼Œä¾¿äºåç»­æŸ¥è¯¢å’Œç›‘æ§ã€‚é€šè¿‡ URL è‡ªåŠ¨è¯†åˆ«Redisé…ç½®ï¼š

#### é…ç½®å­˜å‚¨åç«¯

```python
from rabbitmq_arq import Worker, WorkerSettings, create_client
from rabbitmq_arq.connections import RabbitMQSettings

# Redis å­˜å‚¨é…ç½®ï¼ˆæ¨èï¼‰
rabbitmq_settings = RabbitMQSettings(rabbitmq_url="amqp://localhost:5672")

worker_settings = WorkerSettings(
    rabbitmq_settings=rabbitmq_settings,
    functions=[your_tasks],
    worker_name="result_storage_worker",
    queue_name="default",
    
    # ä»»åŠ¡ç»“æœå­˜å‚¨é…ç½®
    enable_job_result_storage=True,
    job_result_store_url="redis://localhost:6379/0",  # è‡ªåŠ¨è¯†åˆ«ä¸º Redis
    job_result_ttl=86400,  # ç»“æœä¿å­˜24å°æ—¶
)

# å®¢æˆ·ç«¯é…ç½®ï¼ˆç”¨äºæŸ¥è¯¢ç»“æœï¼‰
client = await create_client(
    rabbitmq_settings=rabbitmq_settings,
    result_store_url="redis://localhost:6379/0"  # ä¸ Worker ä½¿ç”¨ç›¸åŒçš„å­˜å‚¨
)
```

#### æ”¯æŒçš„å­˜å‚¨åç«¯

**å½“å‰æ”¯æŒï¼ˆv0.2.0ï¼‰**ï¼š
```python
# Redisï¼ˆæ¨èï¼Œç”Ÿäº§å°±ç»ªï¼‰
"redis://localhost:6379/0"
"rediss://user:pass@localhost:6380/1"  # Redis SSL
```

**è®¡åˆ’æ”¯æŒï¼ˆæœªæ¥ç‰ˆæœ¬ï¼‰**ï¼š
```python
# å…³ç³»å‹æ•°æ®åº“ï¼ˆè®¡åˆ’ä¸­ï¼‰
"postgresql://user:pass@localhost:5432/dbname"
"postgres://user:pass@localhost:5432/dbname"
"mysql://user:pass@localhost:3306/dbname"
"sqlite:///path/to/database.db"

# NoSQL æ•°æ®åº“ï¼ˆè®¡åˆ’ä¸­ï¼‰
"mongodb://localhost:27017/dbname"

# äº‘å­˜å‚¨ï¼ˆè®¡åˆ’ä¸­ï¼‰
"s3://bucket-name/prefix"  # Amazon S3
```

> **æ³¨æ„**ï¼šå½“å‰ç‰ˆæœ¬ï¼ˆv0.2.0ï¼‰åªå®ç°äº†Rediså­˜å‚¨åç«¯ã€‚å…¶ä»–å­˜å‚¨åç«¯å°†åœ¨åç»­ç‰ˆæœ¬ä¸­é€æ­¥æ·»åŠ ã€‚å¦‚æœæ‚¨éœ€è¦å…¶ä»–å­˜å‚¨åç«¯æ”¯æŒï¼Œè¯·åœ¨ [GitHub Issues](https://github.com/Robin528919/rabbitmq-mq/issues) ä¸­æå‡ºéœ€æ±‚ã€‚

#### æŸ¥è¯¢ä»»åŠ¡ç»“æœ

```python
import asyncio
from rabbitmq_arq import create_client, JobContext
from rabbitmq_arq.connections import RabbitMQSettings

# ç¤ºä¾‹ä»»åŠ¡å‡½æ•°
async def data_processing_task(ctx: JobContext, data: dict) -> dict:
    """æ•°æ®å¤„ç†ä»»åŠ¡ï¼Œè¿”å›å¤„ç†ç»“æœ"""
    await asyncio.sleep(1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
    return {
        "processed": True,
        "input_count": len(data),
        "result": f"processed_{data['id']}",
        "timestamp": asyncio.get_event_loop().time()
    }

async def main():
    # åˆ›å»ºå®¢æˆ·ç«¯
    settings = RabbitMQSettings(rabbitmq_url="amqp://localhost:5672")
    client = await create_client(
        rabbitmq_settings=settings,
        result_store_url="redis://localhost:6379/0"
    )
    
    try:
        # æäº¤ä»»åŠ¡
        job = await client.enqueue_job(
            "data_processing_task",
            data={"id": "test_001", "value": "sample_data"},
            queue_name="default"
        )
        print(f"ä»»åŠ¡å·²æäº¤: {job.job_id}")
        
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        await asyncio.sleep(5)
        
        # æŸ¥è¯¢ä»»åŠ¡ç»“æœ
        result = await client.get_job_result(job.job_id)
        if result:
            print(f"ä»»åŠ¡çŠ¶æ€: {result.status}")
            print(f"ä»»åŠ¡ç»“æœ: {result.result}")
            print(f"æ‰§è¡Œæ—¶é•¿: {result.duration}ç§’")
            print(f"æ‰§è¡Œè€…: {result.worker_id}")
        else:
            print("ä»»åŠ¡ç»“æœæœªæ‰¾åˆ°")
        
        # æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€ï¼ˆæ›´è½»é‡ï¼‰
        status = await client.get_job_status(job.job_id)
        print(f"å½“å‰çŠ¶æ€: {status}")
        
        # æ‰¹é‡æŸ¥è¯¢ç»“æœ
        batch_results = await client.get_job_results([job.job_id, "another_job_id"])
        print(f"æ‰¹é‡æŸ¥è¯¢ç»“æœ: {len(batch_results)} ä¸ªç»“æœ")
        
        # è·å–å­˜å‚¨ç»Ÿè®¡
        stats = await client.get_storage_stats()
        print(f"å­˜å‚¨ç»Ÿè®¡: {stats}")
        
        # åˆ é™¤ä»»åŠ¡ç»“æœ
        deleted = await client.delete_job_result(job.job_id)
        print(f"ç»“æœåˆ é™¤æˆåŠŸ: {deleted}")
        
    finally:
        await client.close()

if __name__ == "__main__":
    asyncio.run(main())
```

#### ç»“æœå­˜å‚¨é…ç½®é€‰é¡¹

```python
worker_settings = WorkerSettings(
    # ... å…¶ä»–é…ç½® ...
    
    # ç»“æœå­˜å‚¨é…ç½®
    enable_job_result_storage=True,  # æ˜¯å¦å¯ç”¨ç»“æœå­˜å‚¨
    job_result_store_url="redis://localhost:6379/0",  # å­˜å‚¨URL
    job_result_ttl=86400,  # ç»“æœè¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤24å°æ—¶
)
```

#### å­˜å‚¨çš„æ•°æ®ç»“æ„

ä»»åŠ¡ç»“æœåŒ…å«ä»¥ä¸‹ä¿¡æ¯ï¼š

```python
{
    "job_id": "abc123...",           # ä»»åŠ¡ID
    "status": "completed",           # ä»»åŠ¡çŠ¶æ€
    "result": {...},                 # ä»»åŠ¡è¿”å›ç»“æœ
    "error": null,                   # é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå¤±è´¥ï¼‰
    "start_time": "2025-01-15T10:30:00Z",  # å¼€å§‹æ—¶é—´
    "end_time": "2025-01-15T10:30:05Z",    # ç»“æŸæ—¶é—´
    "duration": 5.2,                 # æ‰§è¡Œæ—¶é•¿ï¼ˆç§’ï¼‰
    "worker_id": "worker_001",       # æ‰§è¡Œçš„Worker ID
    "queue_name": "default",         # é˜Ÿåˆ—åç§°
    "retry_count": 0,                # é‡è¯•æ¬¡æ•°
    "function_name": "my_task",      # å‡½æ•°åç§°
    "args": [1, 2, 3],              # å‡½æ•°å‚æ•°
    "kwargs": {"key": "value"},      # å‡½æ•°å…³é”®å­—å‚æ•°
    "created_at": "2025-01-15T10:30:00Z",  # åˆ›å»ºæ—¶é—´
    "expires_at": "2025-01-16T10:30:00Z"   # è¿‡æœŸæ—¶é—´
}
```

#### æœ€ä½³å®è·µ

1. **Rediså­˜å‚¨é…ç½®**ï¼š
   - å¼€å‘ç¯å¢ƒï¼šä½¿ç”¨æœ¬åœ°Rediså®ä¾‹ `redis://localhost:6379/0`
   - ç”Ÿäº§ç¯å¢ƒï¼šä½¿ç”¨Redisé›†ç¾¤æˆ–å“¨å…µæ¨¡å¼ `redis://user:pass@redis-cluster:6379/0`
   - å®‰å…¨è¿æ¥ï¼šä½¿ç”¨SSLåŠ å¯† `rediss://user:pass@redis.example.com:6380/0`

2. **è®¾ç½®åˆç†çš„TTL**ï¼š
   ```python
   # çŸ­æœŸä»»åŠ¡ï¼ˆ1å°æ—¶ï¼‰
   job_result_ttl=3600
   
   # ä¸­æœŸä»»åŠ¡ï¼ˆ1å¤©ï¼‰
   job_result_ttl=86400
   
   # é•¿æœŸä»»åŠ¡ï¼ˆ1å‘¨ï¼‰
   job_result_ttl=604800
   ```

3. **ç›‘æ§å­˜å‚¨ä½¿ç”¨**ï¼š
   ```python
   stats = await client.get_storage_stats()
   print(f"å­˜å‚¨ç±»å‹: {stats['store_type']}")
   print(f"æ€»å­˜å‚¨é‡: {stats['total_stored']}")
   print(f"æˆåŠŸç‡: {stats['success_rate']:.2%}")
   ```

### é”™è¯¯å¤„ç†å’Œé‡è¯•

RabbitMQ-ARQ å…·æœ‰æ™ºèƒ½é”™è¯¯åˆ†ç±»å’Œè‡ªåŠ¨é‡è¯•æœºåˆ¶ï¼š

```python
import random
from rabbitmq_arq import JobContext, Retry
from rabbitmq_arq.exceptions import MaxRetriesExceeded

async def reliable_task(ctx: JobContext, data: str) -> str:
    """å…·æœ‰é‡è¯•æœºåˆ¶çš„å¯é ä»»åŠ¡"""
    print(f"ä»»åŠ¡æ‰§è¡Œï¼Œå°è¯•æ¬¡æ•°: {ctx.job_try}")
    
    # æ¨¡æ‹Ÿå¯èƒ½å¤±è´¥çš„æ“ä½œ
    if random.random() < 0.3 and ctx.job_try <= 2:
        # æŠ›å‡º Retry å¼‚å¸¸è¿›è¡Œé‡è¯•
        raise Retry(defer=5)  # 5ç§’åé‡è¯•
    
    if ctx.job_try > 3:
        # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
        raise MaxRetriesExceeded(f"ä»»åŠ¡å¤±è´¥è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°: {ctx.job_try}")
    
    return f"å¤„ç†å®Œæˆ: {data}ï¼Œå°è¯•æ¬¡æ•°: {ctx.job_try}"

# Worker çš„æ™ºèƒ½é”™è¯¯åˆ†ç±»ï¼š
# âœ… è‡ªåŠ¨é‡è¯•çš„é”™è¯¯ï¼š
#   - ç½‘ç»œè¿æ¥é”™è¯¯ï¼ˆConnectionErrorï¼‰
#   - è¶…æ—¶é”™è¯¯ï¼ˆTimeoutErrorï¼‰
#   - ä¸´æ—¶æœåŠ¡ä¸å¯ç”¨
#   - æ˜¾å¼çš„ Retry å¼‚å¸¸
#
# âŒ ä¸é‡è¯•çš„é”™è¯¯ï¼š
#   - ä»£ç è¯­æ³•é”™è¯¯ï¼ˆSyntaxErrorï¼‰
#   - ç±»å‹é”™è¯¯ï¼ˆTypeErrorï¼‰
#   - å‚æ•°é”™è¯¯ï¼ˆValueErrorï¼‰
#   - æƒé™é”™è¯¯ï¼ˆPermissionErrorï¼‰
```

### å»¶è¿Ÿä»»åŠ¡å’Œå®šæ—¶ä»»åŠ¡

```python
import asyncio
from datetime import datetime, timedelta
from rabbitmq_arq import RabbitMQClient, JobContext
from rabbitmq_arq.connections import RabbitMQSettings

# å»¶è¿Ÿä»»åŠ¡å‡½æ•°
async def delayed_notification(ctx: JobContext, user_id: int, message: str):
    """å»¶è¿Ÿé€šçŸ¥ä»»åŠ¡"""
    print(f"å‘é€å»¶è¿Ÿé€šçŸ¥ç»™ç”¨æˆ· {user_id}: {message}")
    print(f"ä»»åŠ¡ID: {ctx.job_id}ï¼Œè®¡åˆ’æ‰§è¡Œæ—¶é—´å·²åˆ°")
    return {"user_id": user_id, "message": message, "sent_at": datetime.now()}

async def main():
    settings = RabbitMQSettings(rabbitmq_url="amqp://localhost:5672")
    client = RabbitMQClient(settings)
    await client.connect()
    
    # æ–¹å¼1: å»¶è¿Ÿæ‰§è¡Œï¼ˆä½¿ç”¨ _defer_by å‚æ•°ï¼Œå•ä½ï¼šç§’ï¼‰
    job1 = await client.enqueue_job(
        "delayed_notification",
        user_id=123,
        message="è¿™æ˜¯ä¸€ä¸ªå»¶è¿Ÿ30ç§’çš„é€šçŸ¥",
        queue_name="default",
        _defer_by=30  # 30ç§’åæ‰§è¡Œ
    )
    print(f"å»¶è¿Ÿä»»åŠ¡å·²æäº¤: {job1.job_id}")
    
    # æ–¹å¼2: å®šæ—¶æ‰§è¡Œï¼ˆä½¿ç”¨ defer_until å‚æ•°ï¼‰
    scheduled_time = datetime.now() + timedelta(hours=2)
    job2 = await client.enqueue_job(
        "delayed_notification",
        user_id=456,
        message="è¿™æ˜¯ä¸€ä¸ªå®šæ—¶é€šçŸ¥",
        queue_name="default",
        defer_until=scheduled_time  # æŒ‡å®šæ—¶é—´æ‰§è¡Œ
    )
    print(f"å®šæ—¶ä»»åŠ¡å·²æäº¤: {job2.job_id}ï¼Œå°†åœ¨ {scheduled_time} æ‰§è¡Œ")
    
    # æ–¹å¼3: å›ºå®šæ—¶é—´æ‰§è¡Œ
    fixed_time = datetime(2025, 12, 31, 23, 59, 0)
    job3 = await client.enqueue_job(
        "delayed_notification",
        user_id=789,
        message="æ–°å¹´ç¥ç¦",
        queue_name="default",
        defer_until=fixed_time
    )
    print(f"æ–°å¹´ä»»åŠ¡å·²æäº¤: {job3.job_id}")
    
    await client.close()

if __name__ == "__main__":
    asyncio.run(main())
```

## æ€§èƒ½ä¼˜åŒ–

### é«˜å¹¶å‘é…ç½®

```python
from rabbitmq_arq import Worker, WorkerSettings
from rabbitmq_arq.connections import RabbitMQSettings

# é«˜æ€§èƒ½ RabbitMQ è¿æ¥é…ç½®
rabbitmq_settings = RabbitMQSettings(
    rabbitmq_url="amqp://localhost:5672",
    prefetch_count=5000,     # é«˜é¢„å–æ•°é‡ï¼Œæå‡ååé‡
    connection_timeout=30,   # è¿æ¥è¶…æ—¶æ—¶é—´
)

# é«˜æ€§èƒ½ Worker é…ç½®
worker_settings = WorkerSettings(
    rabbitmq_settings=rabbitmq_settings,
    functions=[your_task_functions],
    worker_name="high_performance_worker",
    
    # é˜Ÿåˆ—é…ç½®
    queue_name="high_performance",
    dlq_name="high_performance_dlq",
    
    # é«˜å¹¶å‘ä»»åŠ¡å¤„ç†é…ç½®
    max_concurrent_jobs=50,   # å¢åŠ å¹¶å‘ä»»åŠ¡æ•°
    job_timeout=600,         # ä»»åŠ¡è¶…æ—¶æ—¶é—´
    max_retries=3,
    retry_backoff=2.0,
    
    # Burst æ¨¡å¼é…ç½®ï¼ˆå¯é€‰ï¼‰
    burst_mode=False,        # æŒç»­è¿è¡Œæ¨¡å¼
    burst_check_interval=0.5, # å¿«é€Ÿé˜Ÿåˆ—æ£€æŸ¥
    
    # ç›‘æ§é…ç½®
    health_check_interval=30, # å¥åº·æ£€æŸ¥é—´éš”
    
    # æ—¥å¿—é…ç½®
    log_level="INFO"
)

worker = Worker(worker_settings)
```

### æ‰¹é‡ä»»åŠ¡æäº¤

```python
import asyncio
from rabbitmq_arq import RabbitMQClient, JobContext
from rabbitmq_arq.connections import RabbitMQSettings

# æ‰¹é‡å¤„ç†ä»»åŠ¡å‡½æ•°
async def batch_process_item(ctx: JobContext, item_id: int, data: str):
    """æ‰¹é‡å¤„ç†å•ä¸ªé¡¹ç›®"""
    print(f"å¤„ç†é¡¹ç›® {item_id}: {data}")
    await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
    return {"item_id": item_id, "processed": True, "result": f"processed_{data}"}

async def batch_submit_example():
    """æ‰¹é‡æäº¤ä»»åŠ¡ç¤ºä¾‹"""
    settings = RabbitMQSettings(rabbitmq_url="amqp://localhost:5672")
    client = RabbitMQClient(settings)
    await client.connect()
    
    print("å¼€å§‹æ‰¹é‡æäº¤ä»»åŠ¡...")
    
    # æ–¹å¼1: å¹¶å‘æäº¤ä»»åŠ¡ï¼ˆæ¨èï¼‰
    tasks = []
    for i in range(1000):
        task = client.enqueue_job(
            "batch_process_item",
            item_id=i,
            data=f"batch_data_{i}",
            queue_name="batch_queue"
        )
        tasks.append(task)
    
    # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡æäº¤å®Œæˆ
    jobs = await asyncio.gather(*tasks)
    print(f"âœ… æˆåŠŸæäº¤äº† {len(jobs)} ä¸ªä»»åŠ¡")
    
    # æ–¹å¼2: åˆ†æ‰¹æäº¤ï¼ˆé¿å…å†…å­˜å ç”¨è¿‡å¤§ï¼‰
    batch_size = 100
    total_tasks = 1000
    submitted_count = 0
    
    for batch_start in range(0, total_tasks, batch_size):
        batch_tasks = []
        for i in range(batch_start, min(batch_start + batch_size, total_tasks)):
            task = client.enqueue_job(
                "batch_process_item",
                item_id=i + 1000,  # é¿å…IDé‡å¤
                data=f"batch_data_{i + 1000}",
                queue_name="batch_queue"
            )
            batch_tasks.append(task)
        
        # ç­‰å¾…å½“å‰æ‰¹æ¬¡æäº¤å®Œæˆ
        batch_jobs = await asyncio.gather(*batch_tasks)
        submitted_count += len(batch_jobs)
        print(f"ğŸ“¦ å·²æäº¤æ‰¹æ¬¡ {batch_start//batch_size + 1}ï¼Œç´¯è®¡: {submitted_count} ä¸ªä»»åŠ¡")
    
    print(f"ğŸ‰ æ‰¹é‡æäº¤å®Œæˆï¼Œæ€»è®¡: {submitted_count} ä¸ªä»»åŠ¡")
    await client.close()

if __name__ == "__main__":
    asyncio.run(batch_submit_example())
```

## ç›‘æ§å’Œæ—¥å¿—

### ç»“æ„åŒ–æ—¥å¿—å’Œç›‘æ§

```python
import logging
import asyncio
from rabbitmq_arq import JobContext

# é…ç½®ç»“æ„åŒ–æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('rabbitmq_arq.log')
    ]
)

# åˆ›å»ºä¸“é—¨çš„æ—¥å¿—è®°å½•å™¨
task_logger = logging.getLogger('rabbitmq_arq.task')
worker_logger = logging.getLogger('rabbitmq_arq.worker')
stats_logger = logging.getLogger('rabbitmq_arq.stats')

async def logged_task(ctx: JobContext, data: dict):
    """å¸¦æœ‰è¯¦ç»†æ—¥å¿—çš„ä»»åŠ¡"""
    task_logger.info(f"ğŸ“‹ ä»»åŠ¡å¼€å§‹: ID={ctx.job_id}, å°è¯•={ctx.job_try}")
    task_logger.info(f"ğŸ“¥ è¾“å…¥æ•°æ®: {data}")
    
    start_time = asyncio.get_event_loop().time()
    
    try:
        # å¤„ç†é€»è¾‘
        await asyncio.sleep(1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        result = {"processed": True, "data": data, "timestamp": start_time}
        
        end_time = asyncio.get_event_loop().time()
        duration = end_time - start_time
        
        task_logger.info(f"âœ… ä»»åŠ¡å®Œæˆ: è€—æ—¶ {duration:.2f}s")
        task_logger.info(f"ğŸ“¤ è¾“å‡ºç»“æœ: {result}")
        
        return result
        
    except Exception as e:
        end_time = asyncio.get_event_loop().time()
        duration = end_time - start_time
        
        task_logger.error(f"âŒ ä»»åŠ¡å¤±è´¥: {str(e)}, è€—æ—¶ {duration:.2f}s")
        raise

# Worker ç”Ÿå‘½å‘¨æœŸæ—¥å¿—
async def startup_with_logging(ctx: dict):
    """å¸¦æ—¥å¿—çš„å¯åŠ¨é’©å­"""
    worker_logger.info("ğŸš€ Worker å¯åŠ¨ä¸­...")
    worker_logger.info("ğŸ“Š åˆå§‹åŒ–ç›‘æ§æŒ‡æ ‡...")
    
    ctx['stats'] = {
        'start_time': asyncio.get_event_loop().time(),
        'jobs_completed': 0,
        'jobs_failed': 0,
        'total_processing_time': 0.0
    }
    
    worker_logger.info("âœ… Worker å¯åŠ¨å®Œæˆ")

async def shutdown_with_logging(ctx: dict):
    """å¸¦æ—¥å¿—çš„å…³é—­é’©å­"""
    worker_logger.info("ğŸ›‘ Worker æ­£åœ¨å…³é—­...")
    
    stats = ctx.get('stats', {})
    runtime = asyncio.get_event_loop().time() - stats.get('start_time', 0)
    
    stats_logger.info("ğŸ“Š Worker è¿è¡Œç»Ÿè®¡:")
    stats_logger.info(f"   æ€»è¿è¡Œæ—¶é—´: {runtime:.1f}s")
    stats_logger.info(f"   å®Œæˆä»»åŠ¡æ•°: {stats.get('jobs_completed', 0)}")
    stats_logger.info(f"   å¤±è´¥ä»»åŠ¡æ•°: {stats.get('jobs_failed', 0)}")
    stats_logger.info(f"   æ€»å¤„ç†æ—¶é—´: {stats.get('total_processing_time', 0):.1f}s")
    
    worker_logger.info("âœ… Worker å…³é—­å®Œæˆ")
```

### ç›‘æ§æŒ‡æ ‡

RabbitMQ-ARQ è‡ªåŠ¨æ”¶é›†ä»¥ä¸‹ç›‘æ§æŒ‡æ ‡ï¼š

- **ä»»åŠ¡æŒ‡æ ‡**:
  - ä»»åŠ¡æ‰§è¡Œæ—¶é—´å’Œååé‡
  - æˆåŠŸ/å¤±è´¥/é‡è¯•ç‡
  - é˜Ÿåˆ—é•¿åº¦å’Œç§¯å‹æƒ…å†µ
  - ä»»åŠ¡ç±»å‹åˆ†å¸ƒ

- **Worker æŒ‡æ ‡**:
  - Worker çŠ¶æ€å’Œå¥åº·åº¦
  - å¹¶å‘ä»»åŠ¡æ•°é‡
  - å†…å­˜å’ŒCPUä½¿ç”¨æƒ…å†µ
  - è¿æ¥çŠ¶æ€

- **ç³»ç»ŸæŒ‡æ ‡**:
  - RabbitMQ è¿æ¥æ± çŠ¶æ€
  - æ¶ˆæ¯ç¡®è®¤å’Œæ‹’ç»ç‡
  - å»¶è¿Ÿä»»åŠ¡è°ƒåº¦å‡†ç¡®æ€§
  - é”™è¯¯åˆ†ç±»ç»Ÿè®¡

å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå·¥å…·æŸ¥çœ‹å®æ—¶æŒ‡æ ‡ï¼š

```bash
# æŸ¥çœ‹é˜Ÿåˆ—çŠ¶æ€
rabbitmq-arq queue-info --queue default

# ç›‘æ§ Worker æ€§èƒ½ï¼ˆå¦‚æœé…ç½®äº†ç›‘æ§ç«¯ç‚¹ï¼‰
curl http://localhost:8080/metrics
```

## å¼€å‘

### ç¯å¢ƒè®¾ç½®

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/your-username/rabbitmq-arq.git
cd rabbitmq-arq

# åˆ›å»ºå¹¶æ¿€æ´» conda ç¯å¢ƒ
conda create -n rabbitmq_arq python=3.12
conda activate rabbitmq_arq

# å®‰è£…å¼€å‘ä¾èµ–
pip install -e ".[dev]"

# å¯åŠ¨ RabbitMQ (ä½¿ç”¨ Docker)
docker run -d --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:3-management
```

### è¿è¡Œæµ‹è¯•

```bash
# ç¡®ä¿åœ¨æ­£ç¡®çš„ç¯å¢ƒä¸­
conda activate rabbitmq_arq

# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# è¿è¡Œå¸¦è¦†ç›–ç‡çš„æµ‹è¯•
pytest --cov=rabbitmq_arq --cov-report=html --cov-report=term-missing

# è¿è¡Œç‰¹å®šç±»å‹çš„æµ‹è¯•
pytest -m error_handling    # é”™è¯¯å¤„ç†æµ‹è¯•
pytest -m integration       # é›†æˆæµ‹è¯•
pytest -m slow             # é•¿æ—¶é—´è¿è¡Œçš„æµ‹è¯•

# è¿è¡Œå•ä¸ªæµ‹è¯•æ–‡ä»¶
pytest tests/test_error_handling.py
```

### ä»£ç æ ¼å¼åŒ–

```bash
# æ ¼å¼åŒ–ä»£ç 
black src tests examples
isort src tests examples

# ç±»å‹æ£€æŸ¥
mypy src
```

## é…ç½®

### ç¯å¢ƒå˜é‡

æ”¯æŒä»¥ä¸‹ç¯å¢ƒå˜é‡é…ç½®ï¼š

- `RABBITMQ_URL`: RabbitMQ è¿æ¥ URL (é»˜è®¤: `amqp://guest:guest@localhost:5672/`)
- `RABBITMQ_PREFETCH_COUNT`: æ¶ˆæ¯é¢„å–æ•°é‡ (é»˜è®¤: `100`)
- `RABBITMQ_CONNECTION_TIMEOUT`: è¿æ¥è¶…æ—¶æ—¶é—´ç§’æ•° (é»˜è®¤: `30`)
- `ARQ_LOG_LEVEL`: æ—¥å¿—çº§åˆ« (é»˜è®¤: `INFO`)
- `ARQ_MAX_CONCURRENT_JOBS`: æœ€å¤§å¹¶å‘ä»»åŠ¡æ•° (é»˜è®¤: `10`)
- `ARQ_JOB_TIMEOUT`: ä»»åŠ¡è¶…æ—¶æ—¶é—´ç§’æ•° (é»˜è®¤: `300`)
- `ARQ_MAX_RETRIES`: æœ€å¤§é‡è¯•æ¬¡æ•° (é»˜è®¤: `3`)
- `ARQ_RETRY_BACKOFF`: é‡è¯•é€€é¿æ—¶é—´ç§’æ•° (é»˜è®¤: `5.0`)
- `ARQ_WORKER_NAME`: Worker åç§° (é»˜è®¤: è‡ªåŠ¨ç”Ÿæˆ)
- `ARQ_QUEUE_NAME`: é»˜è®¤é˜Ÿåˆ—åç§° (é»˜è®¤: `arq:queue`)
- `ARQ_BURST_MODE`: æ˜¯å¦å¯ç”¨ Burst æ¨¡å¼ (é»˜è®¤: `False`)
- `ARQ_BURST_TIMEOUT`: Burst æ¨¡å¼è¶…æ—¶æ—¶é—´ç§’æ•° (é»˜è®¤: `300`)
- `ARQ_RESULT_STORE_URL`: ä»»åŠ¡ç»“æœå­˜å‚¨URL (é»˜è®¤: `redis://localhost:6379/0`)
- `ARQ_RESULT_STORE_TTL`: ç»“æœå­˜å‚¨TTLç§’æ•° (é»˜è®¤: `86400`)
- `ARQ_ENABLE_RESULT_STORAGE`: æ˜¯å¦å¯ç”¨ç»“æœå­˜å‚¨ (é»˜è®¤: `true`)

### é…ç½®æ–‡ä»¶

```yaml
# config.yaml
rabbitmq:
  url: "amqp://localhost:5672"
  prefetch_count: 5000
  
worker:
  max_workers: 10
  queues: ["default", "high_priority"]
  result_storage:
    enabled: true
    store_url: "redis://localhost:6379/0"
    ttl: 86400  # 24å°æ—¶
  
logging:
  level: "INFO"
  format: "structured"
```

## è®¸å¯è¯

MIT License - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

1. Fork è¿™ä¸ªä»“åº“
2. åˆ›å»ºä½ çš„ç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤ä½ çš„æ›´æ”¹ (`git commit -m 'æ·»åŠ ä¸€äº›å¾ˆæ£’çš„ç‰¹æ€§'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. æ‰“å¼€ä¸€ä¸ª Pull Request

## æ›´æ–°æ—¥å¿—

### v0.2.0 (æœ€æ–°ç‰ˆæœ¬)

**é‡å¤§æ›´æ–°**:
- ğŸ”„ **ä»»åŠ¡ç»“æœå­˜å‚¨é‡æ„**: ç®€åŒ–é…ç½®æ–¹å¼ï¼Œä»å¤šå‚æ•°é…ç½®æ”¹ä¸ºURLé…ç½®
- ğŸš€ **URLè‡ªåŠ¨è¯†åˆ«**: é€šè¿‡URLè‡ªåŠ¨è¯†åˆ«Redisé…ç½®ï¼ˆredis://ã€rediss://ï¼‰
- ğŸ—‘ï¸ **ç§»é™¤å†…å­˜å­˜å‚¨**: å»é™¤åˆ†å¸ƒå¼ç¯å¢ƒä¸‹æ— ç”¨çš„å†…å­˜å­˜å‚¨é€‰é¡¹
- ğŸ”§ **æ¶æ„ä¼˜åŒ–**: é‡æ„Workerç±»ç»§æ‰¿ç»“æ„ï¼Œè§£å†³å±æ€§ä¾èµ–é—®é¢˜

**é…ç½®å˜æ›´**:
```python
# æ—§æ–¹å¼ï¼ˆå·²åºŸå¼ƒï¼‰
worker_settings = WorkerSettings(
    job_result_store_type='redis',
    job_result_store_config={'redis_url': 'redis://localhost:6379/0'}
)

# æ–°æ–¹å¼ï¼ˆæ¨èï¼‰
worker_settings = WorkerSettings(
    job_result_store_url='redis://localhost:6379/0'  # è‡ªåŠ¨è¯†åˆ«ä¸ºRedis
)
```

**ç ´åæ€§å˜æ›´**:
- ç§»é™¤äº† `job_result_store_type` é…ç½®å‚æ•°
- ç§»é™¤äº† `job_result_store_config` é…ç½®å‚æ•°
- ç§»é™¤äº†å†…å­˜å­˜å‚¨åç«¯æ”¯æŒ
- `create_client` å‡½æ•°ç­¾åå˜æ›´ä¸ºURLé…ç½®

**è¿ç§»æŒ‡å—**:
```python
# å¦‚æœä½ ä¹‹å‰ä½¿ç”¨äº†ç»“æœå­˜å‚¨ï¼Œè¯·æŒ‰ä»¥ä¸‹æ–¹å¼æ›´æ–°é…ç½®ï¼š

# æ—§é…ç½®
worker_settings = WorkerSettings(
    job_result_store_type='redis',
    job_result_store_config={
        'redis_url': 'redis://localhost:6379/0',
        'key_prefix': 'my_app'
    }
)

# æ–°é…ç½®
worker_settings = WorkerSettings(
    job_result_store_url='redis://localhost:6379/0'
    # æ³¨æ„ï¼škey_prefix ç­‰é«˜çº§é…ç½®ç°åœ¨é€šè¿‡URLå‚æ•°ä¼ é€’
)
```

### v0.1.0

**æ ¸å¿ƒåŠŸèƒ½**:
- âœ… åŸºäº RabbitMQ çš„å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—å®ç°
- âœ… ç±»ä¼¼ ARQ çš„ç®€æ´ API è®¾è®¡
- âœ… æ”¯æŒå³æ—¶ä»»åŠ¡ã€å»¶è¿Ÿä»»åŠ¡å’Œå®šæ—¶ä»»åŠ¡
- âœ… æ™ºèƒ½é”™è¯¯åˆ†ç±»å’Œè‡ªåŠ¨é‡è¯•æœºåˆ¶
- âœ… é«˜æ€§èƒ½å·¥ä½œå™¨å®ç° (â‰¥5000 æ¶ˆæ¯/ç§’)

**é«˜çº§ç‰¹æ€§**:
- âœ… JobContext ä¸Šä¸‹æ–‡æ”¯æŒï¼Œæä¾›ä»»åŠ¡å…ƒä¿¡æ¯
- âœ… Burst æ¨¡å¼æ”¯æŒï¼ˆå¤„ç†å®Œé˜Ÿåˆ—åè‡ªåŠ¨é€€å‡ºï¼‰
- âœ… ç”Ÿå‘½å‘¨æœŸé’©å­å‡½æ•°ï¼ˆstartup, shutdown, job_start, job_endï¼‰
- âœ… æ­»ä¿¡é˜Ÿåˆ— (DLQ) æ”¯æŒ
- âœ… å®Œæ•´çš„å‘½ä»¤è¡Œå·¥å…·é›†

**å¼€å‘ä½“éªŒ**:
- âœ… ä¸­æ–‡å‹å¥½çš„æ—¥å¿—å’Œé”™è¯¯ä¿¡æ¯
- âœ… è¯¦ç»†çš„ç±»å‹æ³¨è§£å’Œæ–‡æ¡£
- âœ… å®Œæ•´çš„æµ‹è¯•è¦†ç›–
- âœ… çµæ´»çš„é…ç½®ç³»ç»Ÿ
- âœ… ç›‘æ§å’Œå¥åº·æ£€æŸ¥æ”¯æŒ 
