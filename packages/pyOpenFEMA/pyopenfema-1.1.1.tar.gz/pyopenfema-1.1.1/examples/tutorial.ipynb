{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "942be33d-87bd-4baf-99cb-df59338805ea",
   "metadata": {},
   "source": [
    "# pyOpenFEMA Tutorial\n",
    "\n",
    "This notebook provides a general overview of how to use `pyOpenFEMA` to read datasets from [OpenFEMA](https://www.fema.gov/about/reports-and-data/openfema).\n",
    "The package acts as a wrapper around the OpenFEMA API to simplify the data reading process and allow for easier exploration of the OpenFEMA datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c08f1fb-3493-4045-b6e6-f8767dbb7873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyOpenFEMA import OpenFEMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782f3248-71d7-45bf-8648-02bfc9f8350f",
   "metadata": {},
   "source": [
    "Before reading any data, we first need to create an `OpenFEMA` object class, which gets the OpenFEMA API metadata.\n",
    "This metadata is then used to see what datasets exist and the metadata they contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a887c420-ee02-47eb-b92b-3bff0c497c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "openfema = OpenFEMA()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bebd2a-332e-4235-924d-ef52e607a8c5",
   "metadata": {},
   "source": [
    "Now, let's see what all the methods are of this class that we can call.\n",
    "We can see this and their docstring by calling `help` on our `OpenFEMA` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec82a58-97f6-44c8-b2ae-90517ecd2d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(openfema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcadb7c-4308-48ad-bd50-eb686ea11606",
   "metadata": {},
   "source": [
    "Okay, so it looks like we have three main method:\n",
    " - `list_datasets`, which lists all datasets available on OpenFEMA;\n",
    " - `dataset_info`, which prints metadata info on a given dataset; and\n",
    " - `read_dataset`, which reads in a given dataset.\n",
    "\n",
    "Well, let's see what our options are for possible datasets to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f20616-a8be-4877-985f-b50b0ef5e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "openfema.list_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff6197d-a1e8-4fb7-bf07-713fbbad0daf",
   "metadata": {},
   "source": [
    "As we can see, there a numerous datasets that we could read.\n",
    "Let's start by picking a simple one, say `'FemaRegions'`.\n",
    "Before reading it in, let's see what the dataset is by getting the info on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af97dcf1-a6fd-4603-912e-f86bfbf9b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "openfema.dataset_info('FemaRegions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f90974e-6ea5-4553-9bfc-c673a9a4ae22",
   "metadata": {},
   "source": [
    "As seen in the `'description'` key, the dataset provides a list of FEMA Regions including the address for each region's headquarters as well as a point that identifies the headquarters geographic location and a geometry shape for the region.\n",
    "Seems like a simple dataset.\n",
    "Let's go ahead and read it in then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c582b89-5d2d-4acb-9b82-26cb66540b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fema_regions = openfema.read_dataset('FemaRegions')\n",
    "fema_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480637c2-a453-46bf-91ce-4fcc9518aafd",
   "metadata": {},
   "source": [
    "As expected there are ten regions and one additional one giving the location of FEMA Headquarters.\n",
    "So, this read in as expected.\n",
    "There does appear to be missing data in the `loc` and `regionGeometry` columns.\n",
    "However, this is due to how OpenFEMA groups those columns into the `geometry` column.\n",
    "Let's go ahead and correct them, since `pyOpenFEMA` does not as it is simply accessing the data from OpenFEMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c5e75a-b18e-47ae-80ee-8d95438bce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry.collection import GeometryCollection\n",
    "\n",
    "fema_regions['loc'] = fema_regions['geometry'].apply(\n",
    "    lambda x: x.geoms[0] if isinstance(x, GeometryCollection) else x\n",
    ")\n",
    "fema_regions['regionGeometry'] = fema_regions['geometry'].apply(\n",
    "    lambda x: x.geoms[1] if isinstance(x, GeometryCollection) else None\n",
    ")\n",
    "fema_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6024e31c-df22-4fd0-8b5c-abb1dd40fde5",
   "metadata": {},
   "source": [
    "Nice! This now looks as expected.\n",
    "From here, we could easily plot the regions or each region's headquarters or an other analysis we would want to apply.\n",
    "\n",
    "Finally, let's do a more specific data read for a larger dataset.\n",
    "To see how to do this, let's double check the `read_dataset` method's docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a58ca-4aed-4fa4-a74f-905d24b65ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(openfema.read_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16cfdb1-3fc6-48bd-a8cc-cb9e964c6192",
   "metadata": {},
   "source": [
    "As we can see, besides specifying the dataset and getting the whole dataset back, we can request specific columns and potentially filter and sort them to get us a subset of the dataset.\n",
    "This is beneficial if the full dataset is large and the subset we want is a small subset of the full dataset.\n",
    "By specifying the subset, we are minimizing the data we need to get from OpenFEMA, which will decrease read times.\n",
    "Let's try subsetting the `'FimaNfipPolicies'` dataset, which is an extra large dataset.\n",
    "First, let's double check the dataset's info.\n",
    "\n",
    "> NOTE:\n",
    "> Currently, `pyOpenFEMA` reads all datasets using `pandas`.\n",
    "> This will read all data requested from OpenFEMA from the `read_dataset` call into memory.\n",
    "> As most datasets on OpenFEMA are relatively small (like the FEMA Regions dataset), reading the full dataset will not be a problem.\n",
    "> However, for large datasets that are not filtered, this may exceed memory and become problematic.\n",
    "> Future updates to the package should include the ability to read in larger-than-memory using [dask](https://docs.dask.org/en/stable/dataframe.html) and [pyspark](https://spark.apache.org/docs/latest/api/python/index.html), which allow for distributed computing of larger-than-memory datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc10215-356a-4995-8779-829539fee1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "openfema.dataset_info(\"FimaNfipPolicies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617dad27-18e0-49e6-b557-760c437fcfab",
   "metadata": {},
   "source": [
    "Looking at the dataset size, we can see under the `'distribution'` key that the dataset is >10 GB in size, which is more data than we want to get from OpenFEMA.\n",
    "To subset this dataset, let's first filter it to get only data within FEMA Region 1 and are state owned buildings.\n",
    "Next, we only want to look at the policy cost, how much coverage there is, and when the policy expires.\n",
    "So, let's limit the columns to those along with the state and location of the building (i.e., latitude and longitude)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21d22d8-504f-4244-8520-7d17303ed25b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "region1_stateowned_policies = openfema.read_dataset(\n",
    "    'FimaNfipPolicies',\n",
    "    filters=[[('femaRegion', 'eq', 1), ('stateOwnedIndicator', 'eq', True)]],\n",
    "    columns=['policyCost', 'totalBuildingInsuranceCoverage',\n",
    "             'policyTerminationDate', 'propertyState',\n",
    "             'latitude', 'longitude'],\n",
    ")\n",
    "region1_stateowned_policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990c0d21-102b-4f66-ac77-7bd0c910a947",
   "metadata": {},
   "source": [
    "As we can see, our subdataset only contains <1000 rows with the six columns we requested.\n",
    "Therefore, subsetting the full dataset saved us a ton on the required data read."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
