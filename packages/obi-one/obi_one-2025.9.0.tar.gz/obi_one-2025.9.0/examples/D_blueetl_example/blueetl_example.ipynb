{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process simulation campaign with blueetl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 09:06:44,067 INFO blueetl.analysis: MultiAnalyzer configuration: analysis_config_01_relative_with_soma.yaml\n",
      "2025-04-11 09:06:44,091 INFO blueetl.cache: Initialize cache\n",
      "2025-04-11 09:06:44,091 INFO blueetl.cache: Invalid cache: ['simulations', 'neurons', 'neuron_classes', 'windows', 'report', 'features']\n",
      "2025-04-11 09:06:44,091 INFO blueetl.cache: Deleting cached repo neurons\n",
      "2025-04-11 09:06:44,092 INFO blueetl.cache: Deleting cached repo simulations\n",
      "2025-04-11 09:06:44,092 INFO blueetl.cache: Deleting cached repo neuron_classes\n",
      "2025-04-11 09:06:44,092 INFO blueetl.cache: Deleting cached repo windows\n",
      "2025-04-11 09:06:44,093 INFO blueetl.cache: Deleting cached repo report\n",
      "2025-04-11 09:06:44,097 INFO blueetl.cache: Initialize cache\n",
      "2025-04-11 09:06:44,097 INFO blueetl.cache: Invalid cache: ['simulations', 'neurons', 'neuron_classes', 'windows', 'report', 'features']\n",
      "2025-04-11 09:06:44,097 INFO blueetl.cache: Deleting cached repo neurons\n",
      "2025-04-11 09:06:44,097 INFO blueetl.cache: Deleting cached repo simulations\n",
      "2025-04-11 09:06:44,098 INFO blueetl.cache: Deleting cached repo neuron_classes\n",
      "2025-04-11 09:06:44,098 INFO blueetl.cache: Deleting cached repo windows\n",
      "2025-04-11 09:06:44,098 INFO blueetl.cache: Deleting cached repo report\n",
      "2025-04-11 09:06:44,125 INFO blueetl.extract.simulations: Simulations ignored because missing: 1\n",
      "2025-04-11 09:06:44,125 INFO blueetl.extract.simulations: Simulations filtered out: 0, with query: {'seed': [334630, 174404]}\n",
      "2025-04-11 09:06:44,126 INFO blueetl.extract.simulations: Simulations extracted: 1/2, ids: [0]\n",
      "2025-04-11 09:06:44,126 INFO blueetl.repository: Writing cached simulations...\n",
      "2025-04-11 09:06:44,130 INFO blueetl.repository: Writing cached simulations [DONE in 0.00 seconds]\n",
      "2025-04-11 09:06:44,131 INFO blueetl.extract.neurons: Loading nodes using population='default', node_set=None, node_sets_file=None...\n",
      "2025-04-11 09:06:44,141 INFO blueetl.extract.neurons: Loading nodes using population='default', node_set=None, node_sets_file=None [DONE in 0.01 seconds]\n",
      "2025-04-11 09:06:44,141 INFO blueetl.extract.neurons: Selected gids for All: 3/3 (limit=1000, population=default, node_set=None)\n",
      "2025-04-11 09:06:44,142 INFO blueetl.extract.neurons: Selected gids for L2_X: 1/1 (limit=1000, population=default, node_set=None)\n",
      "2025-04-11 09:06:44,142 INFO blueetl.extract.neurons: Selected gids for L6_Y: 2/2 (limit=1000, population=default, node_set=None)\n",
      "2025-04-11 09:06:44,143 INFO blueetl.repository: Writing cached neurons...\n",
      "2025-04-11 09:06:44,145 INFO blueetl.repository: Writing cached neurons [DONE in 0.00 seconds]\n",
      "2025-04-11 09:06:44,147 INFO blueetl.repository: Writing cached neuron_classes...\n",
      "2025-04-11 09:06:44,149 INFO blueetl.repository: Writing cached neuron_classes [DONE in 0.00 seconds]\n",
      "2025-04-11 09:06:44,149 INFO blueetl.extract.windows: Processing simulation_id=0, circuit_id=0, window=w1\n",
      "2025-04-11 09:06:44,149 INFO blueetl.extract.windows: Using window=w1, initial_offset=0.0, dynamic_offset=0.0, step_offsets=[0.0], t_start=0.0, t_stop=1.0, t_step=0.0, duration=1.0\n",
      "2025-04-11 09:06:44,151 INFO blueetl.repository: Writing cached windows...\n",
      "2025-04-11 09:06:44,154 INFO blueetl.repository: Writing cached windows [DONE in 0.00 seconds]\n",
      "2025-04-11 09:06:44,154 WARNING blueetl.utils: SHMDIR should be set to the shared memory directory, or the process may be slower, or even fail because of insufficient space. The variable is automatically set when running on an allocated node, but it's not set when connecting via SSH to a pre-allocated node.\n",
      "2025-04-11 09:06:44,155 INFO blueetl.extract.report: Executing merge_filter ...\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "2025-04-11 09:06:44,165 INFO blueetl.parallel: Considering 1 rows for columns ['simulation_id', 'circuit_id']\n",
      "2025-04-11 09:06:44,167 INFO blueetl.parallel: Tasks to be executed: 1\n",
      "[Parallel(n_jobs=7)]: Done   1 tasks      | elapsed:    0.7s\n",
      "2025-04-11 09:06:44,952 INFO blueetl.extract.report: Executing merge_filter  [DONE in 0.80 seconds]\n",
      "2025-04-11 09:06:44,952 INFO blueetl.extract.report: Executing concatenation...\n",
      "2025-04-11 09:06:44,995 INFO blueetl.extract.report: Executing concatenation [DONE in 0.04 seconds]\n",
      "2025-04-11 09:06:44,996 INFO blueetl.repository: Writing cached report...\n",
      "2025-04-11 09:06:44,998 INFO blueetl.repository: Writing cached report [DONE in 0.00 seconds]\n",
      "2025-04-11 09:06:45,001 INFO blueetl.extract.simulations: Simulations ignored because missing: 1\n",
      "2025-04-11 09:06:45,001 INFO blueetl.extract.simulations: Simulations filtered out: 0, with query: {'seed': [334630, 174404]}\n",
      "2025-04-11 09:06:45,001 INFO blueetl.extract.simulations: Simulations extracted: 1/2, ids: [0]\n",
      "2025-04-11 09:06:45,002 INFO blueetl.repository: Writing cached simulations...\n",
      "2025-04-11 09:06:45,004 INFO blueetl.repository: Writing cached simulations [DONE in 0.00 seconds]\n",
      "2025-04-11 09:06:45,004 INFO blueetl.extract.neurons: Loading nodes using population='default', node_set=None, node_sets_file=None...\n",
      "2025-04-11 09:06:45,005 INFO blueetl.extract.neurons: Loading nodes using population='default', node_set=None, node_sets_file=None [DONE in 0.00 seconds]\n",
      "2025-04-11 09:06:45,006 INFO blueetl.extract.neurons: Selected gids for L2_X: 1/1 (limit=1000, population=default, node_set=None)\n",
      "2025-04-11 09:06:45,007 INFO blueetl.repository: Writing cached neurons...\n",
      "2025-04-11 09:06:45,009 INFO blueetl.repository: Writing cached neurons [DONE in 0.00 seconds]\n",
      "2025-04-11 09:06:45,010 INFO blueetl.repository: Writing cached neuron_classes...\n",
      "2025-04-11 09:06:45,012 INFO blueetl.repository: Writing cached neuron_classes [DONE in 0.00 seconds]\n",
      "2025-04-11 09:06:45,012 INFO blueetl.extract.windows: Processing simulation_id=0, circuit_id=0, window=w1\n",
      "2025-04-11 09:06:45,016 INFO blueetl.repository: Writing cached windows...\n",
      "2025-04-11 09:06:45,018 INFO blueetl.repository: Writing cached windows [DONE in 0.00 seconds]\n",
      "2025-04-11 09:06:45,018 WARNING blueetl.utils: SHMDIR should be set to the shared memory directory, or the process may be slower, or even fail because of insufficient space. The variable is automatically set when running on an allocated node, but it's not set when connecting via SSH to a pre-allocated node.\n",
      "2025-04-11 09:06:45,018 INFO blueetl.extract.report: Executing merge_filter ...\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "2025-04-11 09:06:45,020 INFO blueetl.parallel: Considering 1 rows for columns ['simulation_id', 'circuit_id']\n",
      "2025-04-11 09:06:45,020 INFO blueetl.parallel: Tasks to be executed: 1\n",
      "[Parallel(n_jobs=7)]: Done   1 tasks      | elapsed:    0.7s\n",
      "2025-04-11 09:06:45,775 INFO blueetl.extract.report: Executing merge_filter  [DONE in 0.76 seconds]\n",
      "2025-04-11 09:06:45,775 INFO blueetl.extract.report: Executing concatenation...\n",
      "2025-04-11 09:06:45,778 INFO blueetl.extract.report: Executing concatenation [DONE in 0.00 seconds]\n",
      "2025-04-11 09:06:45,779 INFO blueetl.repository: Writing cached report...\n",
      "2025-04-11 09:06:45,781 INFO blueetl.repository: Writing cached report [DONE in 0.00 seconds]\n",
      "2025-04-11 09:06:45,782 INFO blueetl.features: Step 1: grouping features by attributes...\n",
      "2025-04-11 09:06:45,782 INFO blueetl.features: Preprocessing features 1/1 [id=0]\n",
      "2025-04-11 09:06:45,782 INFO blueetl.features: Step 1: grouping features by attributes [DONE in 0.00 seconds]\n",
      "2025-04-11 09:06:45,782 INFO blueetl.features: Step 2: processing cached features...\n",
      "2025-04-11 09:06:45,782 INFO blueetl.features: Step 2: processing cached features [DONE in 0.00 seconds]\n",
      "2025-04-11 09:06:45,783 INFO blueetl.features: Step 3: processing new features...\n",
      "2025-04-11 09:06:45,783 INFO blueetl.features: Considering group: 1/1, key: FeaturesConfigKey(groupby=['simulation_id', 'circuit_id', 'neuron_class', 'window'], neuron_classes=[], windows=[])\n",
      "2025-04-11 09:06:45,783 WARNING blueetl.utils: SHMDIR should be set to the shared memory directory, or the process may be slower, or even fail because of insufficient space. The variable is automatically set when running on an allocated node, but it's not set when connecting via SSH to a pre-allocated node.\n",
      "2025-04-11 09:06:45,783 INFO blueetl.features: Executing merge_filter...\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "2025-04-11 09:06:46,382 INFO blueetl.parallel [task=0]: Considering 3 rows for columns ['circuit_id', 'neuron_class']\n",
      "2025-04-11 09:06:46,382 INFO blueetl.parallel [task=0]: Considering 1 rows for columns ['simulation_id', 'circuit_id', 'window']\n",
      "2025-04-11 09:06:46,383 INFO blueetl.parallel [task=0]: Tasks to be executed: 3\n",
      "2025-04-11 09:06:47,073 INFO blueetl.features [task=0]: Calculating features for Values(simulation_id=0, circuit_id=0, neuron_class='All', window='w1')\n",
      "2025-04-11 09:06:47,073 INFO blueetl.features [task=1]: Calculating features for Values(simulation_id=0, circuit_id=0, neuron_class='L2_X', window='w1')\n",
      "2025-04-11 09:06:47,089 INFO blueetl.features [task=2]: Calculating features for Values(simulation_id=0, circuit_id=0, neuron_class='L6_Y', window='w1')\n",
      "[Parallel(n_jobs=7)]: Done   3 out of   3 | elapsed:    1.0s finished\n",
      "2025-04-11 09:06:47,492 INFO blueetl.features: Executing merge_filter [DONE in 1.71 seconds]\n",
      "2025-04-11 09:06:47,493 INFO blueetl.features: Executing concatenation...\n",
      "2025-04-11 09:06:47,502 INFO blueetl.features: Executing concatenation [DONE in 0.01 seconds]\n",
      "2025-04-11 09:06:47,504 INFO blueetl.features: Writing cached features...\n",
      "2025-04-11 09:06:47,510 INFO blueetl.features: Writing cached features [DONE in 0.01 seconds]\n",
      "2025-04-11 09:06:47,511 INFO blueetl.features: Calculated features 1/1 [id=0]\n",
      "- by_gid: cached=False, filtered=False\n",
      "- by_gid_and_trial: cached=False, filtered=False\n",
      "- by_neuron_class: cached=False, filtered=False\n",
      "- by_neuron_class_and_trial: cached=False, filtered=False\n",
      "- histograms: cached=False, filtered=False\n",
      "2025-04-11 09:06:47,511 INFO blueetl.features: Step 3: processing new features [DONE in 1.73 seconds]\n",
      "2025-04-11 09:06:47,511 INFO blueetl.features: Features calculation completed\n",
      "2025-04-11 09:06:47,532 INFO blueetl.features: Step 1: grouping features by attributes...\n",
      "2025-04-11 09:06:47,533 INFO blueetl.features: Preprocessing features 1/1 [id=0]\n",
      "2025-04-11 09:06:47,533 INFO blueetl.features: Step 1: grouping features by attributes [DONE in 0.00 seconds]\n",
      "2025-04-11 09:06:47,533 INFO blueetl.features: Step 2: processing cached features...\n",
      "2025-04-11 09:06:47,533 INFO blueetl.features: Step 2: processing cached features [DONE in 0.00 seconds]\n",
      "2025-04-11 09:06:47,533 INFO blueetl.features: Step 3: processing new features...\n",
      "2025-04-11 09:06:47,534 INFO blueetl.features: Considering group: 1/1, key: FeaturesConfigKey(groupby=['simulation_id', 'circuit_id'], neuron_classes=[], windows=[])\n",
      "2025-04-11 09:06:47,534 WARNING blueetl.utils: SHMDIR should be set to the shared memory directory, or the process may be slower, or even fail because of insufficient space. The variable is automatically set when running on an allocated node, but it's not set when connecting via SSH to a pre-allocated node.\n",
      "2025-04-11 09:06:47,536 INFO blueetl.features: Executing merge_filter...\n",
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "2025-04-11 09:06:48,125 INFO blueetl.parallel [task=0]: Considering 1 rows for columns ['circuit_id']\n",
      "2025-04-11 09:06:48,125 INFO blueetl.parallel [task=0]: Considering 1 rows for columns ['simulation_id', 'circuit_id']\n",
      "2025-04-11 09:06:48,126 INFO blueetl.parallel [task=0]: Tasks to be executed: 1\n",
      "2025-04-11 09:06:48,785 INFO blueetl.features [task=0]: Calculating features for Values(simulation_id=0, circuit_id=0)\n",
      "[Parallel(n_jobs=7)]: Done   1 tasks      | elapsed:    0.7s\n",
      "2025-04-11 09:06:48,917 INFO blueetl.features: Executing merge_filter [DONE in 1.38 seconds]\n",
      "2025-04-11 09:06:48,917 INFO blueetl.features: Executing concatenation...\n",
      "2025-04-11 09:06:48,920 INFO blueetl.features: Executing concatenation [DONE in 0.00 seconds]\n",
      "2025-04-11 09:06:48,921 INFO blueetl.features: Writing cached features...\n",
      "2025-04-11 09:06:48,924 INFO blueetl.features: Writing cached features [DONE in 0.00 seconds]\n",
      "2025-04-11 09:06:48,924 INFO blueetl.features: Calculated features 1/1 [id=0]\n",
      "- by_neuron_class: cached=False, filtered=False\n",
      "2025-04-11 09:06:48,924 INFO blueetl.features: Step 3: processing new features [DONE in 1.39 seconds]\n",
      "2025-04-11 09:06:48,924 INFO blueetl.features: Features calculation completed\n"
     ]
    }
   ],
   "source": [
    "from blueetl.analysis import run_from_file\n",
    "analysis_config_file = \"analysis_config_01_relative_with_soma.yaml\"\n",
    "loglevel = \"INFO\"\n",
    "ma = run_from_file(analysis_config_file, loglevel=loglevel)\n",
    "# ma = ma.apply_filter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blueetl has created two analyzer objects for the spikes and soma blocks in the configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ma.analyzers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View the dataframes created for the spikes analyzer\n",
    "- These are divided into \"repo\" and \"features\" dataframes.\n",
    "\n",
    "- Repo dataframes are standard dataframes which organize the basic simualtion information and data.\n",
    "\n",
    "- Features dataframes are calculated from the initial repo dataframes by code provided by the user, and typically store calcualted metrics or vectors such as PSTHs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_analyzer = ma.analyzers[\"spikes\"]\n",
    "\n",
    "print(spikes_analyzer.repo.report.df)\n",
    "print(spikes_analyzer.repo.neuron_classes.df)\n",
    "print(spikes_analyzer.repo.simulations.df)\n",
    "print(spikes_analyzer.repo.neurons.df)\n",
    "print(spikes_analyzer.repo.windows.df)\n",
    "\n",
    "print(spikes_analyzer.features.names)\n",
    "print(spikes_analyzer.features.by_gid.df)\n",
    "print(spikes_analyzer.features.by_gid_and_trial.df)\n",
    "print(spikes_analyzer.features.by_neuron_class.df)\n",
    "print(spikes_analyzer.features.by_neuron_class_and_trial.df)\n",
    "print(spikes_analyzer.features.histograms.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example blueetl filtering of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_analyzer.repo.report.df.etl.q(neuron_class='L2_X', window='w2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View the dataframes created for the soma analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_report_analyzer = ma.analyzers[\"soma\"]\n",
    "\n",
    "print(soma_report_analyzer.repo.report.df)\n",
    "print(soma_report_analyzer.repo.neuron_classes.df)\n",
    "print(soma_report_analyzer.repo.simulations.df)\n",
    "print(soma_report_analyzer.repo.neurons.df)\n",
    "print(soma_report_analyzer.repo.windows.df)\n",
    "\n",
    "print(soma_report_analyzer.features.names)\n",
    "print(soma_report_analyzer.features.by_neuron_class.df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature_name in soma_report_analyzer.features.names:\n",
    "#     print(feature_name)\n",
    "#     print(soma_report_analyzer.features._data[feature_name].df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
