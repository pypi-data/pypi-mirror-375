{"status": ["Incremental status will be shown here during execution.", "Until you get a line that matches '  ]\n', you can convert the partial", "output to a json document by appending '\"\"]}' to the partial output.", "", "T+   0.00: Server version aryn-partitioner-0.20250313.150237 Model version 1.4", "T+   0.00: Received request with aryn_call_id=aryn:call-nggmyw5zx4trtht512u0fbi", "T+   0.00: Waiting for scheduling", "T+   0.00: Preprocessing document", "T+   0.01: Done preprocessing document", "T+   0.22: Completed work on page 1", ""], "status_code": 200, "elements": [{"type": "Section-header", "bbox": [0.25689955767463235, 0.1467815468528054, 0.7434609805836397, 0.1676641845703125], "properties": {"score": 0.5140351057052612, "page_number": 1}, "text_representation": "SPsort: How to Sort a Terabyte Quickly\n"}, {"type": "Text", "bbox": [0.3219701789407169, 0.19040098710493608, 0.6775980152803309, 0.20599090576171875], "properties": {"score": 0.5014269351959229, "page_number": 1}, "text_representation": "Jim Wyllie (wyllie@almaden.ibm.com)\n"}, {"type": "Section-header", "bbox": [0.43467701631433825, 0.22169459949840198, 0.5652485926011029, 0.23513566450639203], "properties": {"score": 0.5708352327346802, "page_number": 1}, "text_representation": "February 4, 1999\n"}, {"type": "Section-header", "bbox": [0.14650893267463236, 0.2675329867276278, 0.22036436193129597, 0.2822614080255682], "properties": {"score": 0.8746362328529358, "page_number": 1}, "text_representation": "Abstract\n"}, {"type": "Text", "bbox": [0.14678237017463236, 0.3018602683327415, 0.8496717026654412, 0.41719549005681816], "properties": {"score": 0.9294416904449463, "page_number": 1}, "text_representation": "In December 1998, a 488 node IBM RS/6000 SP* sorted a terabyte of data (10 billion 100 byte records) in\n17 minutes, 37 seconds.  This is more than 2.5 times faster than the previous record for a problem of this\nmagnitude.  The SPsort program itself was custom-designed for this benchmark, but the cluster, its\ninterconnection hardware, disk subsystem, operating system, file system, communication library, and job\nmanagement software are all IBM products.  The system sustained an aggregate data rate of 2.8 GB/s from\nmore than 6 TB of disks managed by the GPFS global shared file system during the sort.  Simultaneous\nwith these transfers, 1.9 GB/s of local disk I/O and 5.6 GB/s of interprocessor communication were also\nsustained.\n"}, {"type": "Section-header", "bbox": [0.14606854607077205, 0.4558663108132102, 0.25043641931870403, 0.4710761052911932], "properties": {"score": 0.8871477842330933, "page_number": 1}, "text_representation": "Introduction\n"}, {"type": "Text", "bbox": [0.1469545700970818, 0.49119573419744317, 0.8553293026194853, 0.649640780362216], "properties": {"score": 0.9314093589782715, "page_number": 1}, "text_representation": "The speed of sorting has long been used as a measure of computer systems I/O and communication\nperformance.  In 1985, an article in Datamation magazine proposed a sort of one million records of 100\nbytes each, with random 10 bytes keys, as a useful measure of computer systems I/O performance [1].  The\nground rules of that benchmark require that all input must start on disk, all output must end on disk, and\nthat the overhead to start the program and create the output files must be included in the benchmark time.\nInput and output must use operating system files, not raw disk partitions.  The first published time for this\nbenchmark was an hour [12].  With constant improvements in computer hardware and sort algorithms, this\ntime diminished to just a few seconds [7].  At that point, variations on the basic theme evolved [6].\n\u201cMinuteSort\u201d [3, 8] measures how much can be sorted in one minute and \u201cPennySort\u201d [5] measures how\nmuch can be sorted for one cent, assuming a particular depreciation period.  Recently, several groups\nreported sorting one terabyte of data [8, 9, 10].  SPsort improves substantially upon the best of these results.\n"}, {"type": "Section-header", "bbox": [0.14674423217773438, 0.6747373268821023, 0.2335002046472886, 0.6890456875887784], "properties": {"score": 0.8882563710212708, "page_number": 1}, "text_representation": "Hardware\n"}, {"type": "Text", "bbox": [0.14703279383042278, 0.7096358975497159, 0.8548281680836397, 0.8828452370383523], "properties": {"score": 0.9263200759887695, "page_number": 1}, "text_representation": "The benchmark machine is a 488 node IBM RS/6000 SP, located in the IBM SP system test lab in\nPoughkeepsie, New York.  Figure 1 shows the organization of this machine.  Each node contains four\n332MHz PowerPC* 604e processors, 1.5 GB of RAM, at least one 32 bit 33 MHz PCI bus, and a 9 GB\nSCSI disk.  The nodes communicate with one another through the high-speed SP switch with a bi-\ndirectional link bandwidth to each node of 150 megabytes/second.  The switch adapter in each node is\nattached directly to the memory bus, so it does not have to share bandwidth with other devices on the PCI\nbus.  Of the 488 nodes, 432 are compute nodes, while the remaining 56 are configured as storage nodes.\nGlobal storage consists of 1680 4.5 GB Serial Storage Architecture (SSA*) disk drives, organized into 336\ntwin-tailed 4+P RAID-5 arrays, for a total of just over 6 TB of user-accessible space attached to the storage\nnodes.  Compute nodes are packaged 16 to a rack, while the storage nodes, which have 3 PCI busses and\nconsequently are larger, are packaged 8 to a rack.  In total, the CPU and switch hardware occupies 34 racks,\nand the global disks require another 18 racks.\n"}]}